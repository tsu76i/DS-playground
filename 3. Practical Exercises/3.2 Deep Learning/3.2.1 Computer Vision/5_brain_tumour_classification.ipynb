{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6592d9f6",
   "metadata": {},
   "source": [
    "# Brain Tumour Classification\n",
    "***\n",
    "## Table of Contents\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from numpy.typing import NDArray\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader, Subset, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd953f32",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "## 2. Device Agnostic Code\n",
    "Mac GPU acceleration (`mps` backend) delivers significant speed-up over CPU for deep learning tasks, especially for large models and batch sizes. On Windows, `cuda` is used instead of `mps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch.device(device=\"cuda\" if torch.cuda.is_available() else \"cpu\") # For Windows\n",
    "DEVICE = torch.device(\n",
    "    device=\"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")  # For MacOS\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bbd62",
   "metadata": {},
   "source": [
    "## 3. Loading Data\n",
    "Retrieved from [Brain Tumor MRI Dataset](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"_datasets/brain_mri\")\n",
    "\n",
    "if data_path.is_dir():\n",
    "    print(f\"{data_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"{data_path} directory NOT FOUND!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_through_dir(dir_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Prints the number of directories and image files in each subdirectory of a given directory.\n",
    "\n",
    "    Args:\n",
    "        dir_path: Path to the root directory to walk through.\n",
    "\n",
    "    Prints:\n",
    "        Number of directories and files found in each directory path.\n",
    "    \"\"\"\n",
    "    for (\n",
    "        directory_path,\n",
    "        directory_names,\n",
    "        file_names,\n",
    "    ) in os.walk(dir_path):\n",
    "        print(\n",
    "            f\"{len(directory_names)} directories and {len(file_names)} images found in {directory_path}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfd8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222359d0",
   "metadata": {},
   "source": [
    "## 4. Preparing Data\n",
    "### Data Transformation\n",
    "For transfer learning using pretrained models in PyTorch, it is a common and effective practice to normalise the dataset using the standard mean and standard deviation values of the ImageNet dataset, on which many pretrained models were originally trained. This ensures that the input data distribution matches the distribution expected by the pretrained model, leading to better convergence and improved performance during fine-tuning.\n",
    "\n",
    "[Reference - PyTorch Forums](https://discuss.pytorch.org/t/discussion-why-normalise-according-to-imagenet-mean-and-std-dev-for-transfer-learning/115670)\n",
    "\n",
    "In addition to normalisation, various data augmentation techniques (such as random flips and random rotations) are applied to increase data diversity and improve the model's generalisation capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce270b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "IMAGE_NET_MEANS = [0.485, 0.456, 0.406]\n",
    "IMAGE_NET_STDS = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    transforms=[\n",
    "        transforms.Resize(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=IMAGE_NET_MEANS,\n",
    "            std=IMAGE_NET_STDS,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    transforms=[\n",
    "        transforms.Resize(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=IMAGE_NET_MEANS,\n",
    "            std=IMAGE_NET_STDS,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67f111",
   "metadata": {},
   "source": [
    "## Preparing DataLoaders\n",
    "The downloaded dataset contains only training and testing subsets; therefore, I split the original test subset into separate validation and test datasets in a 50:50 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_DIR = \"_datasets/brain_mri/Training\"\n",
    "TEST_DIR = \"_datasets/brain_mri/Testing\"\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transform)\n",
    "subset = datasets.ImageFolder(root=TEST_DIR, transform=test_transform)\n",
    "\n",
    "# Get all indices\n",
    "indices = list(range(len(subset)))\n",
    "\n",
    "# Stratified split based on targets\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.5, stratify=subset.targets, random_state=42\n",
    ")\n",
    "\n",
    "# Create proper Subset datasets\n",
    "val_dataset = Subset(dataset=subset, indices=train_idx)\n",
    "test_dataset = Subset(dataset=subset, indices=test_idx)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4cf0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- train_dataset: {len(train_dataset)} -> train_loader: {len(train_loader)}\")\n",
    "print(f\"- val_dataset: {len(val_dataset)} -> val_loader: {len(val_loader)}\")\n",
    "print(f\"- test_dataset: {len(test_dataset)} -> test_loader: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd695168",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Classes: {train_dataset.classes}\")\n",
    "print(f\"Classes with indices: {train_dataset.class_to_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29d573",
   "metadata": {},
   "source": [
    "## 5. Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33cd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(dataset: Dataset, class_names: list[str], num_images: int | None = 9):\n",
    "    \"\"\"\n",
    "    Display a grid of images from a dataset with their corresponding class names as titles.\n",
    "\n",
    "    Args:\n",
    "        dataset: Dataset (image, label). Images assumed to be tensors.\n",
    "        class_names: List of class names indexed by label.\n",
    "        num_images: Number of images to display. Defaults to 9.\n",
    "\n",
    "    Prints:\n",
    "        A matplotlib plot grid of images with titles.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    cols, rows = 3, 3\n",
    "    indices = random.sample(population=range(len(dataset)), k=num_images)\n",
    "    for i, index in enumerate(indices):\n",
    "        image, label = dataset[index]\n",
    "        image = image.numpy().transpose((1, 2, 0))  # Convert from CHW to HWC\n",
    "        mean = np.array(IMAGE_NET_MEANS)\n",
    "        std = np.array(IMAGE_NET_STDS)\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(class_names[label])\n",
    "        plt.tight_layout()\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0840df",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = train_dataset.classes\n",
    "show_images(dataset=test_dataset, class_names=CLASS_NAMES)\n",
    "N_CLASSES = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81722f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = [CLASS_NAMES[label_idx] for _, label_idx in train_dataset]\n",
    "unique_vals, counts = np.unique(train_classes, return_counts=True)\n",
    "df_dist = pd.DataFrame({\"Class Label\": unique_vals, \"Count\": counts})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_dist, x=\"Class Label\", y=\"Count\", hue=\"Class Label\", palette=\"Set2\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Class Labels (Train Dataset)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e668a5",
   "metadata": {},
   "source": [
    "## 6. Transfer Learning\n",
    "Transfer learning is a powerful technique in deep learning where a model pretrained on a large, general dataset is adapted for a related task. This practice improves performance while reducing the amount of training data and training time required.\n",
    "\n",
    "Setting `param.requires_grad = False` in PyTorch freezes the model parameters (weights and biases), preventing gradient computations and updates during training. This allows parts of the model to remain unchanged while selectively training other layers.\n",
    "\n",
    "### ResNet-18\n",
    "ResNet-18 is a convolutional neural network known for its residual connections, which help training deeper networks by mitigating the vanishing gradient problem. It consists of 18 layers structured into four sequential blocks (layer1 to layer4), each containing two residual blocks. In our setup, we freeze all parameters except for the final block (layer4), which is unfrozen to allow the model to adapt deeper, more complex features specific to the image data while keeping most of the pretrained features intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-18 model adapted for classification with optional layer freezing.\n",
    "\n",
    "    Attributes:\n",
    "        device: The device to which the model is moved.\n",
    "        model: The ResNet-18 backbone model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        freeze: bool | None = True,\n",
    "        device: torch.device | str = \"cpu\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialise ResNet18 model with transfer learning layers.\n",
    "\n",
    "        Args:\n",
    "            num_classes: Number of output classes.\n",
    "            freeze: Whether to freeze early layers. Defaults to True.\n",
    "            device: Device for the model (e.g., 'cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.model.fc = nn.Linear(\n",
    "            in_features=self.model.fc.in_features, out_features=num_classes\n",
    "        )\n",
    "\n",
    "        if freeze:\n",
    "            # Freeze all layers initially\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Unfreeze only the 4th layer by default\n",
    "            for param in self.model.layer4.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.to(device=self.device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the ResNet18 model.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            Output logits tensor of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72428844",
   "metadata": {},
   "source": [
    "### EfficientNet B0\n",
    "EfficientNet B0 is a convolutional neural network architecture optimised for both accuracy and efficiency using a compound scaling method that uniformly scales network depth, width, and resolution. Its feature extractor consists of multiple blocks arranged sequentially. In our setup, we freeze all layers except for the deepest two feature blocks (indices 6 and 7) and the final classifier head. This approach allows fine-tuning of the most specialised, high-level features as well as the classification layer, enabling the model to better capture domain-specific patterns while retaining pretrained knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetB0(nn.Module):\n",
    "    \"\"\"\n",
    "    EfficientNet-B0 model adapted for classification with optional layer freezing.\n",
    "\n",
    "    Attributes:\n",
    "        device: The device to which the model is moved.\n",
    "        model: The EfficientNet-B0 backbone model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, num_classes: int, freeze: bool = True, device: torch.device | None = \"cpu\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialise EfficientNetB0 model with customized classifier and freezing options.\n",
    "\n",
    "        Args:\n",
    "            num_classes: Number of output classes.\n",
    "            freeze: Whether to freeze early layers. Defaults to True.\n",
    "            device: Device for the model (e.g., 'cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = models.efficientnet_b0(\n",
    "            weights=models.EfficientNet_B0_Weights.DEFAULT\n",
    "        )\n",
    "        n_features = self.model.classifier[1].in_features\n",
    "\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=n_features, out_features=num_classes),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.to(device=device)\n",
    "\n",
    "        if freeze:\n",
    "            # Freeze all layers initially\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Unfreeze only the 2 last layers and classifier by default\n",
    "            for param in self.model.features[7].parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in self.model.features[6].parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in self.model.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the EfficientNetB0 model.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            Output logits tensor of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = ResNet18(num_classes=N_CLASSES, device=DEVICE)\n",
    "enb0 = EfficientNetB0(num_classes=N_CLASSES, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [resnet18, enb0]:\n",
    "    print(\n",
    "        summary(\n",
    "            model=model,\n",
    "            input_size=(\n",
    "                BATCH_SIZE,\n",
    "                3,\n",
    "                IMAGE_SIZE,\n",
    "                IMAGE_SIZE,\n",
    "            ),  # (batch_size, colour channels, height, width)\n",
    "            verbose=0,\n",
    "            col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "            col_width=20,\n",
    "            row_settings=[\"var_names\"],\n",
    "        )\n",
    "    )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f84438",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics\n",
    "We will use the following evaluation metrics:\n",
    "- `torchmetrics.Accuracy`\n",
    "- `torchmetrics.F1Score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ca494",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Accuracy(task=\"multiclass\", num_classes=N_CLASSES).to(device=DEVICE)\n",
    "f1 = F1Score(task=\"multiclass\", num_classes=N_CLASSES, average=\"macro\").to(\n",
    "    device=DEVICE\n",
    ")\n",
    "metrics = [accuracy, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd05f02",
   "metadata": {},
   "source": [
    "## 8. Loss Function\n",
    "### Cross-Entropy Loss\n",
    "Cross-Entropy Loss is a loss function used for classification problems, particularly when the model outputs probabilities using a softmax activation in the final layer. It measures the difference between the true labels and the predicted probability distribution.\n",
    "\n",
    "For a single data point, the cross-entropy loss is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "    L = - \\sum^{k}_{i=1}y_{i}\\log{(\\hat y_{i})}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $y_i$: True label for the $i$-th class. If one-hot encoded, $y_{i} = 1$ for the corrected class, $y_{i} = 0$ otherwise.\n",
    "- $\\hat y_i$: Predicted probability for the $i$-th class.\n",
    "- $k$: Number of classes.\n",
    "\n",
    "For a batch of $m$ data point:\n",
    "\n",
    "\\begin{align*}\n",
    "    C = \\dfrac{1}{m} \\sum^{m}_{j=1} \\left (- \\sum^{k}_{i=1}y_{j, i}\\log{(\\hat y_{j, i})} \\right)\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $C$: Average cross-entropy loss over the batch.\n",
    "- $m$: Number of training examples (batch size).\n",
    "- $k$: Number of classes.\n",
    "- $y_{j, i} \\in { 0, 1}$: Indicator that true class for sample $j$ corresponds to class $i$.\n",
    "- $\\hat y_{j, i} \\in { 0, 1}$: Predicted probability for sample $j$ belonging to class $i$.\n",
    "\n",
    "In PyTorch:\n",
    "- Use `nn.CrossEntropyLoss()` directly with raw logits.\n",
    "- Do not apply `Softmax()` or `LogSoftmax()` manually before the loss.\n",
    "- Internally, `nn.CrossEntropyLoss() = LogSoftmax() + NegativeLogLikelihoodLoss()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6d999",
   "metadata": {},
   "source": [
    "## 9. Optimiser\n",
    "An optimiser in neural networks is used to adjust the parameters (weights and biases) of a model during training to minimise the loss. Optimisers are essential for enabling neural networks to learn from data: without them, the model would not improve over time.\n",
    "\n",
    "**AdamW** (a variant of the Adam optimiser) separates weight decay (L2 regularisation) from the gradient updates. This decoupling often improves a model's generalisation performance compared to the original Adam optimiser, reducing the risk of overfitting, especially in large-scale models.\n",
    "\n",
    "**ReduceLROnPlateau** is a learning rate scheduler that monitors a specified metric (usually validation loss) and reduces the learning rate by a given factor if the metric stops improving for a certain number of epochs (`patience`). This allows the optimiser to take smaller, more precise steps when progress plateaus, often leading to better final model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec740e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "DECAY_RATE = 1e-4\n",
    "\n",
    "# ! ===== ResNet18 =====\n",
    "resnet18_optimiser = optim.AdamW(\n",
    "    params=filter(lambda p: p.requires_grad, resnet18.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=DECAY_RATE,\n",
    ")\n",
    "resnet18_scheduler = ReduceLROnPlateau(\n",
    "    optimizer=resnet18_optimiser, mode=\"min\", patience=3, factor=0.5\n",
    ")\n",
    "\n",
    "# ! ===== EfficientNet B0 =====\n",
    "enb0_optimiser = optim.AdamW(\n",
    "    params=filter(lambda p: p.requires_grad, enb0.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=DECAY_RATE,\n",
    ")\n",
    "enb0_scheduler = ReduceLROnPlateau(\n",
    "    optimizer=enb0_optimiser, mode=\"min\", patience=3, factor=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465293c3",
   "metadata": {},
   "source": [
    "## 10. Training and Evaluation\n",
    "1. Iterate through epochs\n",
    "1. For each epoch, iterate through training batches, perform training steps, calculate the train loss and evaluation metrics per batch.\n",
    "1. For each epoch, iterate through validation batches, perform validation steps, calculate the validation loss and evaluation metrics per batch.\n",
    "\n",
    "\n",
    "### Training Steps\n",
    "1. Zero the gradients\n",
    "    - Clear the gradients from the previous iteration to prevent accumulation across batches.\n",
    "1. Forward pass\n",
    "    - Pass inputs through the model to obtain predictions.\n",
    "1. Calculate loss and evaluation metrics per batch\n",
    "    - Measure how far the predictions deviate from the true labels using a loss function.\n",
    "    - Compute evaluation metrics (e.g., accuracy, F1 Score) for the current batch.\n",
    "1. Backward pass\n",
    "    - Compute gradients of the loss with respect to the model's parameters via backpropagation.\n",
    "    - Update the parameter $\\theta$ using the computed gradients, typically following:\n",
    "    \n",
    "    $$\n",
    "        \\theta \\leftarrow \\theta - \\eta \\dfrac{\\partial \\mathcal{L}}{\\partial \\theta}\n",
    "    $$\n",
    "    where $\\eta$ is the learning rate.\n",
    "1. Average training loss and evaluation metrics\n",
    "    - Calculate the mean loss and metric values across all batches in the epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimiser: optim.Optimizer,\n",
    "    metrics: list[nn.Module],\n",
    "    device: torch.device,\n",
    ") -> tuple[float, list[float]]:\n",
    "    \"\"\"\n",
    "    Perform a single epoch training step.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model to train.\n",
    "        data_loader: DataLoader providing training data batches.\n",
    "        criterion: Loss function.\n",
    "        optimiser: Optimiser for updating model parameters.\n",
    "        metrics: List of metric modules to update and compute.\n",
    "        device: Device on which to perform calculations.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing average training loss and list of metric values (in %).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for metric in metrics:\n",
    "        metric.reset()\n",
    "    n_total_samples = len(data_loader.dataset)\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "\n",
    "        # Optimiser zero grad without intervening forward pass\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_logits = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(y_logits, labels)\n",
    "        train_loss += loss.item() * batch_size\n",
    "\n",
    "        # Calculate metrics\n",
    "        y_probs = torch.softmax(y_logits, dim=1)\n",
    "        y_preds = torch.argmax(y_probs, dim=1)\n",
    "\n",
    "        for metric in metrics:\n",
    "            metric.update(y_preds, labels)\n",
    "\n",
    "        # Loss backward for backpropagation (computing gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimiser step to apply gradients and update parameters\n",
    "        optimiser.step()\n",
    "\n",
    "    avg_train_loss = train_loss / n_total_samples  # Average (number of samples)\n",
    "    train_metric_scores = [metric.compute().item() * 100 for metric in metrics]\n",
    "    return avg_train_loss, train_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bc85f",
   "metadata": {},
   "source": [
    "### Validation Steps\n",
    "1. Forward pass\n",
    "    - Set the model to evaluation mode (which disables dropout and batch normalisation and desactivates gradient tracking for safety).\n",
    "    - Pass inputs through the model to obtain predictions.\n",
    "1. Calculate loss and evaluation metrics per batch\n",
    "    - Measure how far the predictions deviate from the true labels using a loss function.\n",
    "    - Compute evaluation metrics (e.g., accuracy, F1-Score) for the current batch.\n",
    "1. Average test loss and evaluation metrics\n",
    "    - Calculate the mean loss and metric values across all batches in the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    metrics: list[nn.Module],\n",
    "    device: torch.device,\n",
    ") -> tuple[float, list[float]]:\n",
    "    \"\"\"\n",
    "    Perform a single epoch validation step.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model to validate.\n",
    "        data_loader: DataLoader providing validation data batches.\n",
    "        criterion: Loss function.\n",
    "        metrics: List of metric modules to update and compute.\n",
    "        device: Device on which to perform calculations.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing average validation loss and list of metric values (in %).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    validation_loss = 0.0\n",
    "    n_total_samples = len(data_loader.dataset)\n",
    "    for metric in metrics:\n",
    "        metric.reset()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in data_loader:\n",
    "            batch_size = inputs.size(0)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            y_logits = model(inputs)\n",
    "\n",
    "            # 2. Calculate loss\n",
    "            loss = criterion(y_logits, labels)\n",
    "            validation_loss += loss.item() * batch_size\n",
    "\n",
    "            # 3. Calculate metrics\n",
    "            y_probs = torch.softmax(input=y_logits, dim=1)\n",
    "            y_preds = torch.argmax(y_probs, dim=1)\n",
    "\n",
    "            for metric in metrics:\n",
    "                metric.update(y_preds, labels)\n",
    "\n",
    "    avg_val_loss = validation_loss / n_total_samples\n",
    "    val_metric_scores = [metric.compute().item() * 100 for metric in metrics]\n",
    "    return avg_val_loss, val_metric_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimiser: optim.Optimizer,\n",
    "    scheduler: optim.lr_scheduler,\n",
    "    metrics: list[nn.Module],\n",
    "    device: torch.device,\n",
    "    total_epochs: int,\n",
    ") -> dict[str, list[float]]:\n",
    "    \"\"\"\n",
    "    Run training and validation over specified epochs and tracks metrics.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model.\n",
    "        train_loader: DataLoader for training data.\n",
    "        val_loader: DataLoader for validation data.\n",
    "        criterion: Loss function.\n",
    "        optimiser: Optimiser for training.\n",
    "        scheduler: Learning rate scheduler.\n",
    "        metrics: Metric modules to evaluate.\n",
    "        device: Computation device.\n",
    "        total_epochs: Number of epochs to train.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary recording training and validation loss and metrics.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    epochs_range = range(1, total_epochs + 1)\n",
    "    best_loss = float(\"inf\")\n",
    "    # patience_counter = 0\n",
    "    best_epoch = 0\n",
    "    model_name = model.__class__.__name__.lower()\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_f1\": [],\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in epochs_range:\n",
    "        train_loss, train_metrics = train_step(\n",
    "            model=model,\n",
    "            data_loader=train_loader,\n",
    "            criterion=criterion,\n",
    "            optimiser=optimiser,\n",
    "            metrics=metrics,\n",
    "            device=device,\n",
    "        )\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_metrics[0])\n",
    "        history[\"train_f1\"].append(train_metrics[1])\n",
    "\n",
    "        val_loss, val_metrics = validation_step(\n",
    "            model=model,\n",
    "            data_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            metrics=metrics,\n",
    "            device=device,\n",
    "        )\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_metrics[0])\n",
    "        history[\"val_f1\"].append(val_metrics[1])\n",
    "\n",
    "        scheduler.step(val_loss)  # Update learning rate based on validation loss\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(obj=model.state_dict(), f=f\"{model_name}_best.pth\")\n",
    "            # patience_counter = 0\n",
    "            best_epoch = epoch\n",
    "        # else: # Early Stopping\n",
    "        #     patience_counter += 1\n",
    "        #     if patience_counter >= 5:\n",
    "        #         print(f\"Early stopping at epoch {epoch}\")\n",
    "        #         break\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{total_epochs}]\\n{'=' * 60}\")\n",
    "        print(\n",
    "            f\"{'Train Loss:':<12}{train_loss:>6.4f} | {'Train Accuracy:':<15}{train_metrics[0]:>6.2f}% | {'Train F1:':<10}{train_metrics[1]:>6.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{'Val Loss:':<12}{val_loss:>6.4f} | {'Val Accuracy:':<15}{val_metrics[0]:>6.2f}% | {'Val F1:':<10}{val_metrics[1]:>6.2f}%\\n\"\n",
    "        )\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Training and validation completed in {elapsed_time:.2f} seconds.\\n\")\n",
    "    print(f\"The best-performing was saved at epoch: {best_epoch}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff19202",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "EPOCH_RANGE = range(1, EPOCHS + 1)\n",
    "MODEL_NAME_RESNET18 = \"ResNet18\"\n",
    "MODEL_NAME_ENB0 = \"EfficientNet B0\"\n",
    "\n",
    "print(\"Training ResNet18...\")\n",
    "resnet18_history = train_and_validate(\n",
    "    model=resnet18,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimiser=resnet18_optimiser,\n",
    "    scheduler=resnet18_scheduler,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    total_epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "print(\"Training EfficientNet B0...\")\n",
    "enb0_history = train_and_validate(\n",
    "    model=enb0,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimiser=enb0_optimiser,\n",
    "    scheduler=enb0_scheduler,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    total_epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22cc444",
   "metadata": {},
   "source": [
    "## 11. Results\n",
    "### Overall Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99650e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_train_metrics = {\n",
    "    \"Loss\": resnet18_history[\"train_loss\"],\n",
    "    \"Accuracy\": resnet18_history[\"train_acc\"],\n",
    "    \"F1 Score\": resnet18_history[\"train_f1\"],\n",
    "}\n",
    "\n",
    "resnet18_val_metrics = {\n",
    "    \"Loss\": resnet18_history[\"val_loss\"],\n",
    "    \"Accuracy\": resnet18_history[\"val_acc\"],\n",
    "    \"F1 Score\": resnet18_history[\"val_f1\"],\n",
    "}\n",
    "\n",
    "enb0_train_metrics = {\n",
    "    \"Loss\": resnet18_history[\"train_loss\"],\n",
    "    \"Accuracy\": resnet18_history[\"train_acc\"],\n",
    "    \"F1 Score\": resnet18_history[\"train_f1\"],\n",
    "}\n",
    "\n",
    "enb0_val_metrics = {\n",
    "    \"Loss\": enb0_history[\"val_loss\"],\n",
    "    \"Accuracy\": enb0_history[\"val_acc\"],\n",
    "    \"F1 Score\": enb0_history[\"val_f1\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(\n",
    "    epochs_range: range,\n",
    "    model_name: str,\n",
    "    train_metrics: dict[str, list[float]],\n",
    "    val_metrics: dict[str, list[float]],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots training and validation metrics per epoch for comparison.\n",
    "\n",
    "    Args:\n",
    "        epochs_range: Range of epoch numbers.\n",
    "        model_name: Name of the model for title annotation.\n",
    "        train_metrics: Training metric values.\n",
    "        val_metrics: Validation metric values.\n",
    "    \"\"\"\n",
    "    metric_names = list(train_metrics.keys())\n",
    "    n_metrics = len(metric_names)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=n_metrics, figsize=(16, 6))\n",
    "    axes = axes.flatten()\n",
    "    for i, metric_name in enumerate(metric_names):\n",
    "        ax = axes[i]\n",
    "        ax.plot(\n",
    "            epochs_range,\n",
    "            train_metrics[metric_name],\n",
    "            label=f\"Train {metric_name}\",\n",
    "        )  # Train metric\n",
    "        ax.plot(\n",
    "            epochs_range,\n",
    "            val_metrics[metric_name],\n",
    "            label=f\"Validation {metric_name}\",\n",
    "        )  # Validation metric\n",
    "        ax.set_title(f\"{model_name}: {metric_name} Over Epochs\", fontsize=12)\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        if metric_name == \"Loss\":\n",
    "            ax.set_ylabel(\"Loss\")\n",
    "        else:\n",
    "            ax.set_ylabel(f\"f{metric_name} (%)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a61dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(\n",
    "    epochs_range=EPOCH_RANGE,\n",
    "    model_name=MODEL_NAME_RESNET18,\n",
    "    train_metrics=resnet18_train_metrics,\n",
    "    val_metrics=resnet18_val_metrics,\n",
    ")\n",
    "plot_results(\n",
    "    epochs_range=EPOCH_RANGE,\n",
    "    model_name=MODEL_NAME_ENB0,\n",
    "    train_metrics=enb0_train_metrics,\n",
    "    val_metrics=enb0_val_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a233fca",
   "metadata": {},
   "source": [
    "### Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_predictions(\n",
    "    model: nn.Module,\n",
    "    model_name: str,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    metrics: list[nn.Module],\n",
    "    device: torch.device,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Make predictions over an entire dataset and calculates metrics.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model to use for predictions.\n",
    "        model_name: Model name for printing outputs.\n",
    "        data_loader: DataLoader for dataset to predict on.\n",
    "        criterion: Loss function to compute loss.\n",
    "        metrics: Metric modules to compute during prediction.\n",
    "        device: Device for computation.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing concatenated predicted labels and true labels.\n",
    "    \"\"\"\n",
    "    model_file_name = model.__class__.__name__.lower()\n",
    "    model.load_state_dict(\n",
    "        state_dict=torch.load(f=f\"{model_file_name}_best.pth\", map_location=device),\n",
    "    )\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    test_loss = 0.0\n",
    "    n_total_samples = len(data_loader.dataset)\n",
    "    for metric in metrics:\n",
    "        metric.reset()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in data_loader:\n",
    "            batch_size = inputs.size(0)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            y_logits = model(inputs)\n",
    "            y_probs = torch.softmax(y_logits, dim=1)\n",
    "            y_preds = torch.argmax(y_probs, dim=1)\n",
    "\n",
    "            all_preds.append(y_preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "            # 2. Calculate test loss\n",
    "            test_loss += criterion(y_logits, labels).item() * batch_size\n",
    "\n",
    "            # 3. Calculate test metrics\n",
    "            for metric in metrics:\n",
    "                metric.update(y_preds, labels)\n",
    "\n",
    "    test_loss /= n_total_samples\n",
    "    test_acc = metrics[0].compute().item() * 100\n",
    "    test_f1 = metrics[1].compute().item() * 100\n",
    "\n",
    "    print(f\"{model_name}\\n{'=' * 60}\")\n",
    "    print(\n",
    "        f\"{'Test Loss:':<12}{test_loss:>6.4f} | {'Test Accuracy:':<15}{test_acc:>6.2f}% | {'Test F1:':<10}{test_f1:>6.2f}%\\n\"\n",
    "    )\n",
    "    all_preds_tensor = torch.cat(all_preds)\n",
    "    all_labels_tensor = torch.cat(all_labels)\n",
    "    return all_preds_tensor, all_labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a690dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = ResNet18(num_classes=N_CLASSES, freeze=False, device=DEVICE)\n",
    "\n",
    "all_preds_resnet18, all_labels_resnet18 = make_all_predictions(\n",
    "    model=resnet18,\n",
    "    model_name=MODEL_NAME_RESNET18,\n",
    "    data_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "\n",
    "enb0 = EfficientNetB0(num_classes=N_CLASSES, freeze=False, device=DEVICE)\n",
    "\n",
    "all_preds_enb0, all_labels_enb0 = make_all_predictions(\n",
    "    model=enb0,\n",
    "    model_name=MODEL_NAME_ENB0,\n",
    "    data_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f676ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{MODEL_NAME_RESNET18}\\n{'=' * 60}\")\n",
    "print(classification_report(y_true=all_labels_resnet18, y_pred=all_preds_resnet18))\n",
    "\n",
    "print(f\"\\n{MODEL_NAME_ENB0}\\n{'=' * 60}\")\n",
    "print(classification_report(y_true=all_labels_enb0, y_pred=all_preds_enb0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26116ac1",
   "metadata": {},
   "source": [
    "### Missclassifiations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be92ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missclassifications(\n",
    "    all_preds: torch.Tensor,\n",
    "    all_labels: torch.Tensor,\n",
    "    model_name: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Prints the count and rate of misclassified samples.\n",
    "\n",
    "    Args:\n",
    "        all_preds: Tensor of predicted labels.\n",
    "        all_labels: Tensor of true labels.\n",
    "        model_name: Model name for printing context.\n",
    "    \"\"\"\n",
    "    missclassified = all_preds != all_labels\n",
    "    n_missclassified = int(missclassified.sum())\n",
    "    missclassified_rate = 100 * n_missclassified / len(all_labels)\n",
    "    print(f\"{model_name}\\n{'=' * 60}\")\n",
    "    print(\n",
    "        f\"Number of failed predictions: {n_missclassified}/{len(all_labels)} ({missclassified_rate:.2f}%)\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cdc43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_missclassifications(\n",
    "    all_preds=all_preds_resnet18,\n",
    "    all_labels=all_labels_resnet18,\n",
    "    model_name=MODEL_NAME_RESNET18,\n",
    ")\n",
    "\n",
    "print_missclassifications(\n",
    "    all_preds=all_preds_enb0,\n",
    "    all_labels=all_labels_enb0,\n",
    "    model_name=MODEL_NAME_ENB0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf8328",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f64a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    cm: NDArray[np.int64] | torch.Tensor,\n",
    "    class_names: list[str],\n",
    "    model_name: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot a confusion matrix using seaborn heatmap.\n",
    "\n",
    "    Args:\n",
    "        cm: Confusion matrix data.\n",
    "        class_names: List of class names for axes.\n",
    "        model_name: Model name for plot title.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        data=cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(f\"{model_name}: Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777df45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_resnet18 = confusion_matrix(\n",
    "    y_true=all_labels_resnet18,\n",
    "    y_pred=all_preds_resnet18,\n",
    ")\n",
    "\n",
    "cm_enb0 = confusion_matrix(\n",
    "    y_true=all_labels_enb0,\n",
    "    y_pred=all_preds_enb0,\n",
    ")\n",
    "\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    cm=cm_resnet18,\n",
    "    class_names=CLASS_NAMES,\n",
    "    model_name=MODEL_NAME_RESNET18,\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    cm=cm_enb0,\n",
    "    class_names=CLASS_NAMES,\n",
    "    model_name=MODEL_NAME_ENB0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc75eb2",
   "metadata": {},
   "source": [
    "## 12. Vision Transformer (ViT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907dc30",
   "metadata": {},
   "source": [
    "### Converting Image Data for Transformers\n",
    "The Hugging Face `Trainer` excepts datasets to return dictionaries rather than tuples. For image classification, it needs to be:\n",
    "```\n",
    "{\n",
    "    'pixel_values': tensor_of_image,\n",
    "    'labels: label_integer\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf0308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\", message=\"'pin_memory' argument is set as true but not supported on MPS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53a1479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDatasetWrapper(Dataset):\n",
    "    \"\"\"\n",
    "    Wrapper around a dataset to output inputs as dictionary with 'pixel_values' and 'labels',\n",
    "    compatible with Hugging Face Trainer.\n",
    "\n",
    "    Attributes:\n",
    "        dataset: Original dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: Dataset) -> None:\n",
    "        \"\"\"\n",
    "        Initialise with original dataset.\n",
    "\n",
    "        Args:\n",
    "            dataset: The dataset to wrap.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Return the number of samples.\n",
    "\n",
    "        Returns:\n",
    "            int: Dataset length.\n",
    "        \"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index: int) -> dict[str, torch.Tensor | int]:\n",
    "        \"\"\"\n",
    "        Return a sample as a dictionary with keys 'pixel_values' and 'labels'.\n",
    "\n",
    "        Args:\n",
    "            index: Sample index.\n",
    "\n",
    "        Returns:\n",
    "            Sample dictionary.\n",
    "        \"\"\"\n",
    "        image, label = self.dataset[index]\n",
    "        return {\n",
    "            \"pixel_values\": image,\n",
    "            \"labels\": label,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_vit = TransformerDatasetWrapper(dataset=train_dataset)\n",
    "val_dataset_vit = TransformerDatasetWrapper(dataset=val_dataset)\n",
    "test_dataset_vit = TransformerDatasetWrapper(dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87815e",
   "metadata": {},
   "source": [
    "train_dataset.class_to_idx = {'glioma': 0, 'meningioma': 1, 'notumor': 2, 'pituitary': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_MODEL_PATH = \"./my_finetuned_model\"\n",
    "RANDOM_SEED = 42\n",
    "N_EPOCHS_VIT = 5\n",
    "LABEL_2_ID = {\"GLIOMA\": 0, \"MENINGIOMA\": 1, \"NO TUMOUR\": 2, \"PITUITARY\": 3}\n",
    "ID_2_LABEL = {0: \"GLIOMA\", 1: \"MENINGIOMA\", 2: \"NO TUMOUR\", 3: \"PITUITARY\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e94422",
   "metadata": {},
   "source": [
    "### Loading Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e17511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "\n",
    "VIT_MODEL_NAME = \"google/vit-base-patch16-224-in21k\"\n",
    "VIT_MODEL = ViTForImageClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=VIT_MODEL_NAME,\n",
    "    id2label=ID_2_LABEL,\n",
    "    label2id=LABEL_2_ID,\n",
    ")\n",
    "VIT_PROCESSOR = ViTImageProcessor.from_pretrained(VIT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    report_to=\"none\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    logging_steps=100,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=N_EPOCHS_VIT,\n",
    "    weight_decay=0.01,\n",
    "    seed=RANDOM_SEED,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8907db",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d60d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(\n",
    "    eval_pred: tuple[NDArray[np.float32], NDArray[np.int64]],\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute accuracy and weighted F1 score metrics suitable for Hugging Face Trainer evaluation.\n",
    "\n",
    "    Args:\n",
    "        eval_pred: Tuple with model logits and true labels.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with \"accuracy\" and \"f1\" metric scores.\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(\n",
    "        predictions=predictions, references=labels, average=\"weighted\"\n",
    "    )\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1[\"f1\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=VIT_MODEL,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_vit,\n",
    "    eval_dataset=val_dataset_vit,\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=VIT_PROCESSOR,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir=MY_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d740619",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = trainer.evaluate(test_dataset_vit)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
