{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3769f437",
   "metadata": {},
   "source": [
    "# Respiratory Disease Classification\n",
    "***\n",
    "## Table of Contents\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.typing import NDArray\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader, Subset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288b6945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for reproducibility.\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9e02d",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "\n",
    "## 2. Device Agnostic Code\n",
    "Mac GPU acceleration (`mps` backend) delivers significant speed-up over CPU for deep learning tasks, especially for large models and batch sizes. On Windows, `cuda` is used instead of `mps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch.device(\n",
    "#     device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# )  # For Windows\n",
    "DEVICE = torch.device(\n",
    "    device=\"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")  # For MacOS\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a6332",
   "metadata": {},
   "source": [
    "## 3. Loading Data\n",
    "Retrieved from [COVID-19 Radiography Database](https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"_datasets/Radiography_Dataset\")\n",
    "\n",
    "if DATA_PATH.is_dir():\n",
    "    print(f\"{DATA_PATH} directory exists.\")\n",
    "else:\n",
    "    print(f\"{DATA_PATH} directory NOT FOUND!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_through_dir(dir_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Print the number of directories and image files in each subdirectory of a given directory.\n",
    "\n",
    "    Args:\n",
    "        dir_path: Path to the root directory to walk through.\n",
    "    \"\"\"\n",
    "\n",
    "    for (\n",
    "        directory_path,\n",
    "        directory_names,\n",
    "        file_names,\n",
    "    ) in os.walk(top=dir_path):\n",
    "        print(\n",
    "            f\"{len(directory_names)} directories and {len(file_names)} images found in {directory_path}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d5768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f88685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    img_folder: str\n",
    "    transform: transforms.Compose\n",
    "    extensions: set[str]\n",
    "    all_paths: list[str]\n",
    "    all_labels: list[str]\n",
    "    categories = set[str]\n",
    "    label2id = dict[str, int]\n",
    "    id2label = dict[int, str]\n",
    "    all_labels_indices = list[int]\n",
    "\n",
    "    def __init__(\n",
    "        self, img_path, transform=None, extensions={\".png\", \".jpg\", \".jpeg\"}\n",
    "    ) -> None:\n",
    "        img_folder = \"*/images/*\"\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        self.all_paths = [\n",
    "            path\n",
    "            for path in img_path.glob(img_folder)\n",
    "            if path.suffix.lower() in extensions\n",
    "        ]\n",
    "        # All labels (2 folder levels above)\n",
    "        self.all_labels = [path.parent.parent.name for path in self.all_paths]\n",
    "        self.categories = sorted(set(self.all_labels))  # Unique labels\n",
    "        self.label2id = {label: index for index, label in enumerate(self.categories)}\n",
    "        self.id2label = {index: label for label, index in self.label2id.items()}\n",
    "        self.encoded_labels = [self.label2id[label] for label in self.all_labels]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.all_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_file_path = self.all_paths[index]\n",
    "        try:\n",
    "            img = Image.open(fp=single_file_path).convert(mode=\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {single_file_path}: {e}\")\n",
    "        label_index = self.encoded_labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(img_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3430019",
   "metadata": {},
   "source": [
    "## 4. Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_images(dataset: Dataset) -> None:\n",
    "    cols, rows = 3, 3\n",
    "    figure = plt.figure(figsize=(rows * 3, cols * 3))\n",
    "    for i in range(1, cols * rows + 1):\n",
    "        sample_index = random.randint(a=0, b=len(dataset))\n",
    "        img, label = dataset[sample_index]\n",
    "        figure.add_subplot(rows, cols, i)\n",
    "        plt.title(dataset.id2label[label])\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_images(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b329f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals, counts = np.unique(dataset.all_labels, return_counts=True)\n",
    "df_dist = pd.DataFrame({\"Class Label\": unique_vals, \"Count\": counts})\n",
    "print(df_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(dataset: Dataset) -> None:\n",
    "    unique_vals, counts = np.unique(dataset.all_labels, return_counts=True)\n",
    "    df_dist = pd.DataFrame({\"Class Label\": unique_vals, \"Count\": counts})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(\n",
    "        data=df_dist, x=\"Class Label\", y=\"Count\", hue=\"Class Label\", palette=\"Set2\"\n",
    "    )\n",
    "    plt.xlabel(\"Class Label\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Distribution of Class Labels\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_distribution(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da906baf",
   "metadata": {},
   "source": [
    "## 5. Preparing Data\n",
    "### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad3a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, random_seed):\n",
    "    all_indices = range(len(dataset))\n",
    "    all_labels = dataset.encoded_labels\n",
    "\n",
    "    train_indices, sub_indices = train_test_split(\n",
    "        all_indices, test_size=0.2, stratify=all_labels, random_state=random_seed\n",
    "    )  # 80% train, 20% sub\n",
    "\n",
    "    val_indices, test_indices = train_test_split(\n",
    "        sub_indices,\n",
    "        test_size=0.5,\n",
    "        stratify=[all_labels[i] for i in sub_indices],\n",
    "        random_state=random_seed,\n",
    "    )  # sub -> 50% validation, 50% test\n",
    "\n",
    "    train_data = Subset(dataset=dataset, indices=train_indices)\n",
    "    val_data = Subset(dataset=dataset, indices=val_indices)\n",
    "    test_data = Subset(dataset=dataset, indices=test_indices)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1d57a",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "For transfer learning using pretrained models in PyTorch, it is a common and effective practice to normalise the dataset using the standard mean and standard deviation values of the ImageNet dataset, on which many pretrained models were originally trained. This ensures that the input data distribution matches the distribution expected by the pretrained model, leading to better convergence and improved performance during fine-tuning.\n",
    "\n",
    "[Reference - PyTorch Forums](https://discuss.pytorch.org/t/discussion-why-normalise-according-to-imagenet-mean-and-std-dev-for-transfer-learning/115670)\n",
    "\n",
    "In addition to normalisation, various data augmentation techniques (such as random flips and random rotations) are applied to increase data diversity and improve the model's generalisation capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "RANDOM_SEED = 42\n",
    "IMAGE_NET_MEANS = [0.485, 0.456, 0.406]\n",
    "IMAGE_NET_STDS = [0.229, 0.224, 0.225]\n",
    "N_CLASSES = len(unique_vals)\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    transforms=[\n",
    "        transforms.Resize(size=IMG_SIZE),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=IMAGE_NET_MEANS, std=IMAGE_NET_STDS),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    transforms=[\n",
    "        transforms.Resize(size=IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=IMAGE_NET_MEANS, std=IMAGE_NET_STDS),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ca684",
   "metadata": {},
   "source": [
    "### Preparing DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd0714",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = split_dataset(dataset, RANDOM_SEED)\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = test_transform\n",
    "test_dataset.dataset.transform = test_transform\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"train_dataset: {len(train_dataset)} -> train_loader: {len(train_loader)}\")\n",
    "print(f\"val_dataset: {len(val_dataset)} -> val_loader: {len(val_loader)}\")\n",
    "print(f\"test_dataset: {len(test_dataset)} -> test_loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf6c6a",
   "metadata": {},
   "source": [
    "## 6. Transfer Learning\n",
    "Transfer learning is a powerful technique in deep learning where a model pretrained on a large, general dataset is adapted for a related task. This practice improves performance while reducing the amount of training data and training time required.\n",
    "\n",
    "Setting `param.requires_grad = False` in PyTorch freezes the model parameters (weights and biases), preventing gradient computations and updates during training. This allows parts of the model to remain unchanged while selectively training other layers.\n",
    "\n",
    "### ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        is_frozen: bool | None = True,\n",
    "        device: torch.device | str = \"cpu\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=self.model.fc.in_features, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "        if is_frozen:\n",
    "            # Freeze all layers initially\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.model.layer4.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in self.model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.to(device=device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3662480",
   "metadata": {},
   "source": [
    "### DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99437ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        is_frozen: bool | None = True,\n",
    "        device: torch.device | None = \"cpu\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=n_features, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "        if is_frozen:\n",
    "            for param in self.model.parameters():  # all layers\n",
    "                param.requires_grad = False\n",
    "            # Unfreeze only the last dense block, final batch norm and classifier by default\n",
    "            for param in self.model.features[10].parameters():  # denseblock4\n",
    "                param.requires_grad = True\n",
    "            for param in self.model.features[11].parameters():  # norm5\n",
    "                param.requires_grad = True\n",
    "            for param in self.model.classifier.parameters():  # classifier\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.to(device=device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = ResNet50(num_classes=N_CLASSES, device=DEVICE)\n",
    "densenet121 = DenseNet121(num_classes=N_CLASSES, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23502123",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [resnet50, densenet121]:\n",
    "    print(\n",
    "        summary(\n",
    "            model=model,\n",
    "            input_size=(\n",
    "                BATCH_SIZE,\n",
    "                3,\n",
    "                IMG_SIZE,\n",
    "                IMG_SIZE,\n",
    "            ),\n",
    "            verbose=0,\n",
    "            col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "            col_width=20,\n",
    "            row_settings=[\"var_names\"],\n",
    "        ),\n",
    "    )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9133ab",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics\n",
    "We will use the following evaluation metrics:\n",
    "- `torchmetrics.Accuracy`\n",
    "- `torchmetrics.F1Score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07711801",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Accuracy(task=\"multiclass\", num_classes=N_CLASSES).to(device=DEVICE)\n",
    "f1 = F1Score(task=\"multiclass\", num_classes=N_CLASSES).to(device=DEVICE)\n",
    "\n",
    "metrics = [accuracy, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7faa7ad",
   "metadata": {},
   "source": [
    "## 8. Loss Function\n",
    "### Cross-Entropy Loss\n",
    "Cross-Entropy Loss is a loss function used for classification problems, particularly when the model outputs probabilities using a softmax activation in the final layer. It measures the difference between the true labels and the predicted probability distribution.\n",
    "\n",
    "For a single data point, the cross-entropy loss is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "    L = - \\sum^{k}_{i=1}y_{i}\\log{(\\hat y_{i})}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $y_i$: True label for the $i$-th class. If one-hot encoded, $y_{i} = 1$ for the corrected class, $y_{i} = 0$ otherwise.\n",
    "- $\\hat y_i$: Predicted probability for the $i$-th class.\n",
    "- $k$: Number of classes.\n",
    "\n",
    "For a batch of $m$ data point:\n",
    "\n",
    "\\begin{align*}\n",
    "    C = \\dfrac{1}{m} \\sum^{m}_{j=1} \\left (- \\sum^{k}_{i=1}y_{j, i}\\log{(\\hat y_{j, i})} \\right)\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $C$: Average cross-entropy loss over the batch.\n",
    "- $m$: Number of training examples (batch size).\n",
    "- $k$: Number of classes.\n",
    "- $y_{j, i} \\in { 0, 1}$: Indicator that true class for sample $j$ corresponds to class $i$.\n",
    "- $\\hat y_{j, i} \\in { 0, 1}$: Predicted probability for sample $j$ belonging to class $i$.\n",
    "\n",
    "In PyTorch:\n",
    "- Use `nn.CrossEntropyLoss()` directly with raw logits.\n",
    "- Do not apply `Softmax()` or `LogSoftmax()` manually before the loss.\n",
    "- Internally, `nn.CrossEntropyLoss() = LogSoftmax() + NegativeLogLikelihoodLoss()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d091a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inversed frequency weights\n",
    "class_weights = 1.0 / torch.tensor(counts, dtype=torch.float)\n",
    "class_weights = (class_weights / class_weights.sum()).to(DEVICE)  # Normalised\n",
    "for val, weight in zip(unique_vals, class_weights):\n",
    "    print(f\"Weight for {val}: {weight:.5f}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044a58d",
   "metadata": {},
   "source": [
    "## 9. Optimiser\n",
    "An optimiser in neural networks is used to adjust the parameters (weights and biases) of a model during training to minimise the loss. Optimisers are essential for enabling neural networks to learn from data: without them, the model would not improve over time.\n",
    "\n",
    "**AdamW** (a variant of the Adam optimiser) separates weight decay (L2 regularisation) from the gradient updates. This decoupling often improves a model's generalisation performance compared to the original Adam optimiser, reducing the risk of overfitting, especially in large-scale models.\n",
    "\n",
    "**ReduceLROnPlateau** is a learning rate scheduler that monitors a specified metric (usually validation loss) and reduces the learning rate by a given factor if the metric stops improving for a certain number of epochs (`patience`). This allows the optimiser to take smaller, more precise steps when progress plateaus, often leading to better final model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a21980",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "DECAY_RATE = 1e-4\n",
    "\n",
    "# ! === ResNet50 ===\n",
    "resnet50_optimiser = optim.AdamW(\n",
    "    params=filter(lambda p: p.requires_grad, resnet50.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=DECAY_RATE,\n",
    ")\n",
    "resnet50_scheduler = ReduceLROnPlateau(\n",
    "    optimizer=resnet50_optimiser,\n",
    "    mode=\"min\",\n",
    "    patience=3,\n",
    "    factor=0.5,\n",
    ")\n",
    "\n",
    "# ! === DenseNet121 ===\n",
    "densenet121_optimiser = optim.AdamW(\n",
    "    params=filter(lambda p: p.requires_grad, densenet121.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=DECAY_RATE,\n",
    ")\n",
    "densenet121_scheduler = ReduceLROnPlateau(\n",
    "    optimizer=densenet121_optimiser,\n",
    "    mode=\"min\",\n",
    "    patience=3,\n",
    "    factor=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1a43ec",
   "metadata": {},
   "source": [
    "## 10. Training and Evaluation\n",
    "1. Iterate through epochs\n",
    "1. For each epoch, iterate through training batches, perform training steps, calculate the train loss and evaluation metrics per batch.\n",
    "1. For each epoch, iterate through validation batches, perform validation steps, calculate the validation loss and evaluation metrics per batch.\n",
    "\n",
    "\n",
    "### Training Steps\n",
    "1. Zero the gradients\n",
    "    - Clear the gradients from the previous iteration to prevent accumulation across batches.\n",
    "1. Forward pass\n",
    "    - Pass inputs through the model to obtain predictions.\n",
    "1. Calculate loss and evaluation metrics per batch\n",
    "    - Measure how far the predictions deviate from the true labels using a loss function.\n",
    "    - Compute evaluation metrics (e.g., accuracy, F1 Score) for the current batch.\n",
    "1. Backward pass\n",
    "    - Compute gradients of the loss with respect to the model's parameters via backpropagation.\n",
    "    - Update the parameter $\\theta$ using the computed gradients, typically following:\n",
    "    \n",
    "    $$\n",
    "        \\theta \\leftarrow \\theta - \\eta \\dfrac{\\partial \\mathcal{L}}{\\partial \\theta}\n",
    "    $$\n",
    "    where $\\eta$ is the learning rate.\n",
    "1. Average training loss and evaluation metrics\n",
    "    - Calculate the mean loss and metric values across all batches in the epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61517717",
   "metadata": {},
   "source": [
    "## 10. Training and Evaluation\n",
    "1. Iterate through epochs\n",
    "1. For each epoch, iterate through training batches, perform training steps, calculate the train loss and evaluation metrics per batch.\n",
    "1. For each epoch, iterate through validation batches, perform validation steps, calculate the validation loss and evaluation metrics per batch.\n",
    "\n",
    "\n",
    "### Training Steps\n",
    "1. Zero the gradients\n",
    "    - Clear the gradients from the previous iteration to prevent accumulation across batches.\n",
    "1. Forward pass\n",
    "    - Pass inputs through the model to obtain predictions.\n",
    "1. Calculate loss and evaluation metrics per batch\n",
    "    - Measure how far the predictions deviate from the true labels using a loss function.\n",
    "    - Compute evaluation metrics (e.g., accuracy, F1 Score) for the current batch.\n",
    "1. Backward pass\n",
    "    - Compute gradients of the loss with respect to the model's parameters via backpropagation.\n",
    "    - Update the parameter $\\theta$ using the computed gradients, typically following:\n",
    "    \n",
    "    $$\n",
    "        \\theta \\leftarrow \\theta - \\eta \\dfrac{\\partial \\mathcal{L}}{\\partial \\theta}\n",
    "    $$\n",
    "    where $\\eta$ is the learning rate.\n",
    "1. Average training loss and evaluation metrics\n",
    "    - Calculate the mean loss and metric values across all batches in the epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimiser: optim.Optimizer,\n",
    "    metrics: list[nn.Module],\n",
    "    device: torch.device,\n",
    ") -> tuple[float, list[float]]:\n",
    "    model.train()\n",
    "    for metric in metrics:\n",
    "        metric.reset()\n",
    "    n_total_samples = len(data_loader.dataset)\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "\n",
    "        # Optimiser zero grad without intervening forward pass\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_logits = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(y_logits, labels)\n",
    "        train_loss += loss.item() * batch_size\n",
    "\n",
    "        # Calculate metrics\n",
    "        y_probs = torch.softmax(input=y_logits, dim=1)\n",
    "        y_preds = torch.argmax(input=y_probs, dim=1)\n",
    "\n",
    "        for metric in metrics:\n",
    "            metric.update(y_preds, labels)\n",
    "\n",
    "        # Loss backward for backpropagation (computing gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimiser step to apply gradients and update parameters\n",
    "        optimiser.step()\n",
    "\n",
    "    avg_train_loss = train_loss / n_total_samples\n",
    "    train_metric_scores = [metric.compute().item() * 100 for metric in metrics]\n",
    "    return avg_train_loss, train_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03946ef0",
   "metadata": {},
   "source": [
    "### Validation Steps\n",
    "1. Forward pass\n",
    "    - Set the model to evaluation mode (which disables dropout and batch normalisation and desactivates gradient tracking for safety).\n",
    "    - Pass inputs through the model to obtain predictions.\n",
    "1. Calculate loss and evaluation metrics per batch\n",
    "    - Measure how far the predictions deviate from the true labels using a loss function.\n",
    "    - Compute evaluation metrics (e.g., accuracy, F1-Score) for the current batch.\n",
    "1. Average test loss and evaluation metrics\n",
    "    - Calculate the mean loss and metric values across all batches in the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    metrics: list[nn.Module],\n",
    "    device: torch.device,\n",
    ") -> tuple[float, list[float]]:\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    n_total_samples = len(data_loader.dataset)\n",
    "    for metric in metrics:\n",
    "        metric.reset()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            batch_size = inputs.size(0)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            y_logits = model(inputs)\n",
    "\n",
    "            # 2. Calculate loss\n",
    "            loss = criterion(y_logits, labels)\n",
    "            val_loss += loss.item() * batch_size\n",
    "\n",
    "            # 3. Calculate metrics\n",
    "            y_probs = torch.softmax(input=y_logits, dim=1)\n",
    "            y_preds = torch.argmax(input=y_probs, dim=1)\n",
    "\n",
    "            for metric in metrics:\n",
    "                metric.update(y_preds, labels)\n",
    "\n",
    "    avg_val_loss = val_loss / n_total_samples\n",
    "    val_metric_scores = [metric.compute().item() * 100 for metric in metrics]\n",
    "    return avg_val_loss, val_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e434916e",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimiser: optim.Optimizer,\n",
    "    scheduler: optim.lr_scheduler,\n",
    "    metrics: list[nn.Module],\n",
    "    device: torch.device,\n",
    "    total_epochs: int,\n",
    ") -> dict[str, list[float]]:\n",
    "    model.to(device=device)\n",
    "    epochs_range = range(1, total_epochs + 1)\n",
    "    best_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_epoch = 0\n",
    "    model_name = model.__class__.__name__.lower()\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_f1\": [],\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in epochs_range:\n",
    "        train_loss, train_metrics = train_step(\n",
    "            model=model,\n",
    "            data_loader=train_loader,\n",
    "            criterion=criterion,\n",
    "            optimiser=optimiser,\n",
    "            metrics=metrics,\n",
    "            device=device,\n",
    "        )\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_metrics[0])\n",
    "        history[\"train_f1\"].append(train_metrics[1])\n",
    "\n",
    "        val_loss, val_metrics = validation_step(\n",
    "            model=model,\n",
    "            data_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            metrics=metrics,\n",
    "            device=device,\n",
    "        )\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_metrics[0])\n",
    "        history[\"val_f1\"].append(val_metrics[1])\n",
    "\n",
    "        scheduler.step(val_loss)  # Update learning rate based on validation loss\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(obj=model.state_dict(), f=f\"{model_name}_best.pth\")\n",
    "            patience_counter = 0\n",
    "            best_epoch = epoch\n",
    "        else:  # Early Stopping\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 5:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        print(f\"Epoch [{epoch}/{total_epochs}]\\n{'=' * 60}\")\n",
    "        print(\n",
    "            f\"{'Train Loss:':<12}{train_loss:>6.4f} | {'Train Accuracy:':<15}{train_metrics[0]:>6.2f}% | {'Train F1:':<10}{train_metrics[1]:>6.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{'Val Loss:':<12}{val_loss:>6.4f} | {'Val Accuracy:':<15}{val_metrics[0]:>6.2f}% | {'Val F1:':<10}{val_metrics[1]:>6.2f}\"\n",
    "        )\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Training and validation completed in {elapsed_time:.2f} seconds.\\n\")\n",
    "    print(f\"The best-performing model was saved at epoch: {best_epoch}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f02d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "EPOCH_RANGE = range(1, EPOCHS + 1)\n",
    "MODEL_NAME_RESNET50 = \"ResNet50\"\n",
    "MODEL_NAME_DENSENET121 = \"DenseNet121\"\n",
    "\n",
    "print(f\"Training {MODEL_NAME_RESNET50}...\")\n",
    "resnet50_history = train_and_validate(\n",
    "    model=resnet50,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimiser=resnet50_optimiser,\n",
    "    scheduler=resnet50_scheduler,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    total_epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "print(f\"Training {MODEL_NAME_DENSENET121}...\")\n",
    "densenet121_history = train_and_validate(\n",
    "    model=densenet121,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimiser=densenet121_optimiser,\n",
    "    scheduler=densenet121_scheduler,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    total_epochs=EPOCHS,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
