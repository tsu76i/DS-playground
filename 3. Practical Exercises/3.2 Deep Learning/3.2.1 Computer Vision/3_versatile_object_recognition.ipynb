{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e4a978",
   "metadata": {},
   "source": [
    "# Versatile Object Recognition\n",
    "***\n",
    "## Table of Contents\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d9b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12552a",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e42335",
   "metadata": {},
   "source": [
    "## 2. Preparing Data\n",
    "For simple models (shallow networks, logistic regression, etc.), `ToTensor()` is often sufficient as it rescales image pixel values to the range from 0 to 1. However, for state-of-the-art architectures, it is strongly recommended to re-normalise (standardise) inputs so that each colour channel has zero mean and unit variance. Many pretrained models are trained on such normalised inputs, therefore this approach tends to yield better results than basic normalisation. Furthermore, centring inputs around zero generally results in more stable training and faster convergence, particularly for architectures with activation functions such as tanh or certain weight initialisation schemes.\n",
    "\n",
    "Let:\n",
    "- $X_{n, c, h, w}$: Pixel value for image $n$, channel $c$, height $h$, and width $w$.\n",
    "- $N$: Total number of images.\n",
    "- $C$: Number of channels (RGB = 3).\n",
    "- $H, W$: Height and width of an image.\n",
    "\n",
    "For each batch of images ($\\left[B, 3, 32, 32\\right]$), \n",
    "- Mean per channel:\n",
    "$$\n",
    "\\mu_{\\text{batch, c}} = \\dfrac{1}{B \\cdot H \\cdot W}\\sum^{B}_{n=1} \\sum^{H}_{h=1} \\sum^{W}_{w=1} X_{n, c, h, w}\n",
    "$$\n",
    "\n",
    "- Squared mean per channel:\n",
    "\n",
    "$$\n",
    "s_{\\text{batch, c}} = \\dfrac{1}{B \\cdot H \\cdot W}\\sum^{B}_{n=1} \\sum^{H}_{h=1} \\sum^{W}_{w=1} X^2_{n, c, h, w}\n",
    "$$\n",
    "\n",
    "- Mean:\n",
    "$$\n",
    "\\mu = \\dfrac{\\sum_{\\text{batches}} \\mu_{\\text{batch, c}}}{n_{\\text{batches}}}\n",
    "$$\n",
    "\n",
    "Using the identity $\\text{Var}(X) = E\\left[(X - \\mu \\right)^2]$ :\n",
    "- Standard deviation:\n",
    "\n",
    "\\begin{align*}\n",
    "\n",
    "\\sigma &= \\sqrt{E\\left[X^2\\right] - (E\\left[X\\right])^2} \\\\\n",
    " &= \\sqrt{\\dfrac{\\sum_{\\text{batches}} s_{\\text{batch, c}}}{n_{\\text{batches}}} - \\mu^2}\n",
    "\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937bff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(train_data):\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=False)\n",
    "\n",
    "    c_sum, c_squared_sum, n_batches = 0, 0, 0\n",
    "    for data, _ in train_loader:\n",
    "        # Shape: [batch_size, channel=3, height=32, width=32]\n",
    "        c_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        c_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
    "        n_batches += 1\n",
    "    mean = c_sum / n_batches\n",
    "    std = (c_squared_sum / n_batches - mean**2) ** 0.5\n",
    "\n",
    "    return mean.tolist(), std.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5082a48",
   "metadata": {},
   "source": [
    "Or, alternatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb01503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std_simple(train_data):\n",
    "    # .data -> [n_images, height, width, colour channels]\n",
    "    data = train_data.data / 255\n",
    "\n",
    "    mean = data.mean(axis=(0, 1, 2))  # Mean with respect to colour channels\n",
    "    std = data.std(axis=(0, 1, 2))  # Std with respect to colour channels\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18b668a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.4914625287055969, 0.48222312331199646, 0.44661077857017517]\n",
      "Standard Deviation: [0.24703028798103333, 0.24348397552967072, 0.26159432530403137]\n"
     ]
    }
   ],
   "source": [
    "raw_train_data = datasets.CIFAR10(\n",
    "    root=\"_datasets\", train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "mean, std = get_mean_and_std(raw_train_data)\n",
    "print(f\"Mean: {mean}\\nStandard Deviation: {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c93625",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation\n",
    "This transform pipeline contains the following data augmentation processes:\n",
    "- **Resize(size=(32, 32))**:\n",
    "    - Ensures all input images are reshaped to $32 \\times 32$ pixels. \n",
    "- **RandomCrop(32, padding=4)**:\n",
    "    - Pads each side of the $32 \\times 32$ images by $4$ pixels, making it $40 \\times 40$, then randomly crops back to $32 \\times 32$.\n",
    "    - Introduces local translations and slight spatial variations.\n",
    "    - Helps the model learn translation-invariant features.\n",
    "- **RandomHorizontalFlip(p=0.5)**:\n",
    "    - Each image is horizontally flipped with probability $0.5$ ($= 50$%).\n",
    "    - Increases data diversity and is appropriate for natural images.\n",
    "- **ToTensor()**:\n",
    "    - Converts PIL Images or NumPy arrays to PyTorch tensors, scaling pixel values ranging from $0$ to $1$.\n",
    "- **Normalize(mean=mean, std=std)**:\n",
    "    - Standardises each channel by subtracting the dataset mean and dividing by its standard deviation.\n",
    "    - Ensures input features for the neural network are zero-centred and scale-invariant, enhancing training dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(32, 32)),\n",
    "        transforms.transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ea7db",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Aladdin Persson. (2020). *Pytorch Quick Tip: Calculate Mean and Standard Deviation of Data*. <br>\n",
    "https://youtu.be/y6IEcEBRZks?si=JmHfPQWezR1ooX5F\n",
    "\n",
    "1. stackoverflow. (2021). *How to calculate the mean and the std of cifar10 data*. <br>\n",
    "https://stackoverflow.com/questions/66678052/how-to-calculate-the-mean-and-the-std-of-cifar10-data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
