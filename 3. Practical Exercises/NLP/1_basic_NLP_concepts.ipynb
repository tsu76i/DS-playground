{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a94967",
   "metadata": {},
   "source": [
    "# Basic NLP Concepts\n",
    "***\n",
    "## Table of Contents\n",
    "1. Introduction to NLP\n",
    "    - Types of NLP\n",
    "    - NLP Tasks\n",
    "    - Popular NLP Libraries\n",
    "2. Text Preprocessing\n",
    "    - Lowercasing\n",
    "    - Regular Expression\n",
    "    - Removing Punctuation and Special Characters\n",
    "    - Tokenisation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff8e6565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036a812",
   "metadata": {},
   "source": [
    "## 1. Introduction to NLP\n",
    "\n",
    "Natural Language Processing (NLP) is a multidisciplinary field that combines computer science, linguistics, and artificial intelligence to enable computers to interpret, process, and generate human language naturally and efficiently. NLP bridges the gap between human communication and computer understanding, allowing machines to analyse, understand, and even respond to text and speech just as humans do.\n",
    "\n",
    "\n",
    "### Types of NLP\n",
    "There are several types and approaches within NLP, each with its own focus and methodology:\n",
    "\n",
    "- **Symbolic NLP**: Relies on hand-crafted rules and linguistic knowledge to process language. This traditional approach uses grammar rules and dictionaries to interpret text.\n",
    "\n",
    "- **Statistical NLP**: Uses statistical methods and machine learning to analyze large volumes of language data, identifying patterns and making predictions based on probabilities.\n",
    "\n",
    "- **Neural NLP**: Employs deep learning and neural networks to model and understand language, enabling advanced applications like language generation and large language models.\n",
    "\n",
    "\n",
    "### NLP Tasks\n",
    "NLP can be divided into several overlapping subfields and tasks, including:\n",
    "\n",
    "- **Natural Language Understanding (NLU)**: Focuses on interpreting and extracting meaning from human language (semantics and syntax).\n",
    "- **Natural Language Generation (NLG)**: Involved in generating human-like text or speech from structured data or input.\n",
    "- **Speech Recognition**: Converts spoken language into text.\n",
    "- **Text Classification**: Assigns categories or labels to text data (e.g., spam detection, topic classification).\n",
    "- **Named Entity Recognition (NER)**: Identifies and classifies entities such as names, locations, and organisations in text.\n",
    "- **Sentiment Analysis**: Determines the emotional tone behind a body of text.\n",
    "- **Machine Translation**: Automatically translates text or speech from one language to another.\n",
    "- **Part-of-Speech Tagging**: Labels words with their grammatical roles (noun, verb, etc.).\n",
    "\n",
    "### Popular NLP Libraries\n",
    "The main Python libraries used in NLP are:\n",
    "- **NLTK (Natural Language Toolkit)**: One of the oldest and most compherensive libraries for NLP tasks such as tokenisation, stemming, tagging, parsing, and semantic reasoning. Widely used for teaching, research, and foundational NLP projects, though it may be slower for large-scale production.\n",
    "- **spaCy**: Designed for fast, efficient, and production-ready NLP applications. It offered pre-trained models for multiple languages, supports tokenisation, part-of-speech tagging, named entity recognition, dependency parsing, and integrates well with deep learning frameworks.\n",
    "- **Gensim**: Specialised in topic modelling, document similarity analysis, and word embeddings (e.g. Word2Vec, FastText, LDA). It's optimised for processing large text corpora efficiently and is popular for unsupervised NLP tasks.\n",
    "- **TextBlob**: Build on top of NLTK and Pattern. TextBlob provides a simple API for common NLP tasks like sentiment analysis, part-of-speech tagging, and noun phrase extraction. It's user-friendly and great for beginners or rapid prototyping.\n",
    "- **Pattern**: Offers tools for text processing, web mining, machine learning, and network analysis. Known for its easy use and is suitable for tasks like sentiment analysis, part-of-speech tagging, and web scraping.\n",
    "- **PyNLPl(Pineapple)**: A versatile library for both basic and advanced NLP tasks, including n-gram analysis, frequency lists, and linguistic annotation. It supports various file formats and is useful for more specialised NLP workflows.\n",
    "- **Stanza** Developed by Stanford, Stanza provides deep learning-based models for tasks such as named entity recognition and part-of-speech tagging, supporting over 70 languages and integrating well with other libraries (e.g., spaCy, Hugging Face Transformers).\n",
    "- **Polyglot**: Known for its extensive multilingual support. Polyglot offers tokenisation, sentimental analysis, named entity recognition, and word embeddings across 130+ languages.\n",
    "- **CoreNLP**: A robust Java-based library from Stanford, accessible in Python via wrappers, used for tasks such as named entity recognition and coreference resolution. Often integrated with other Python NLP libraries.\n",
    "- **Hugging Face Transformers**: While primarily for large language models, this library is widely used in modern NLP for tasks (e.g., text classification, question answering, text generation using transformer-based models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26efc9b",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing\n",
    "Text preprocessing is the foundation of any NLP project. It involves cleaning and transforming raw text into a structured format suitable for analysis.\n",
    "\n",
    "Typical Text Preprocessing Pipeline is:\n",
    "1. **Lowercasing**: Standardises text for comparison.\n",
    "\n",
    "2. **Removing punctuation/special characters**: Cleans up noise.\n",
    "\n",
    "3. **Tokenisation**: Splits text into words, sentences, or subwords.\n",
    "\n",
    "4. **Stopword removal, stemming, lemmatization**: Further normalizes text for analysis\n",
    "\n",
    "Dataset retrieved from [Tweets Dataset](https://www.kaggle.com/datasets/mmmarchetti/tweets-dataset?select=tweets.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3afb410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "content",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "fe09f489-3672-4d65-9dce-e4d3435a9b1d",
       "rows": [
        [
         "0",
         "Is history repeating itself...?#DONTNORMALIZEHATE https://t.co/ngG11quhmK"
        ],
        [
         "1",
         "@barackobama Thank you for your incredible grace in leadership and for being an exceptional‚Ä¶ https://t.co/ZuQLZpt6df"
        ],
        [
         "2",
         "Life goals. https://t.co/XIn1qKMKQl"
        ],
        [
         "3",
         "Me right now üôèüèª https://t.co/gW55C1wrwd"
        ],
        [
         "4",
         "SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è https://t.co/0shuUYUBEv"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@barackobama Thank you for your incredible gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  Is history repeating itself...?#DONTNORMALIZEH...\n",
       "1  @barackobama Thank you for your incredible gra...\n",
       "2                Life goals. https://t.co/XIn1qKMKQl\n",
       "3            Me right now üôèüèª https://t.co/gW55C1wrwd\n",
       "4  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('_datasets/tweets.csv')\n",
    "df = df.drop(columns=['author', 'country', 'date_time', 'id', 'language',\n",
    "             'latitude', 'longitude', 'number_of_likes', 'number_of_shares'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b6fa6f",
   "metadata": {},
   "source": [
    "### Lowercasing\n",
    "Convert all text to lowercase to ensure uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce9b85ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clean_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6c87732a-0cf2-4ede-8232-bb5ddffd8df9",
       "rows": [
        [
         "0",
         "Is history repeating itself...?#DONTNORMALIZEHATE https://t.co/ngG11quhmK",
         "is history repeating itself...?#dontnormalizehate https://t.co/ngg11quhmk"
        ],
        [
         "1",
         "@barackobama Thank you for your incredible grace in leadership and for being an exceptional‚Ä¶ https://t.co/ZuQLZpt6df",
         "@barackobama thank you for your incredible grace in leadership and for being an exceptional‚Ä¶ https://t.co/zuqlzpt6df"
        ],
        [
         "2",
         "Life goals. https://t.co/XIn1qKMKQl",
         "life goals. https://t.co/xin1qkmkql"
        ],
        [
         "3",
         "Me right now üôèüèª https://t.co/gW55C1wrwd",
         "me right now üôèüèª https://t.co/gw55c1wrwd"
        ],
        [
         "4",
         "SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è https://t.co/0shuUYUBEv",
         "sisters are doin' it for themselves! üôåüèªüí™üèª‚ù§Ô∏è https://t.co/0shuuyubev"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
       "      <td>is history repeating itself...?#dontnormalizeh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@barackobama Thank you for your incredible gra...</td>\n",
       "      <td>@barackobama thank you for your incredible gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
       "      <td>life goals. https://t.co/xin1qkmkql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
       "      <td>me right now üôèüèª https://t.co/gw55c1wrwd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
       "      <td>sisters are doin' it for themselves! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Is history repeating itself...?#DONTNORMALIZEH...   \n",
       "1  @barackobama Thank you for your incredible gra...   \n",
       "2                Life goals. https://t.co/XIn1qKMKQl   \n",
       "3            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
       "4  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  is history repeating itself...?#dontnormalizeh...  \n",
       "1  @barackobama thank you for your incredible gra...  \n",
       "2                life goals. https://t.co/xin1qkmkql  \n",
       "3            me right now üôèüèª https://t.co/gw55c1wrwd  \n",
       "4  sisters are doin' it for themselves! üôåüèªüí™üèª‚ù§Ô∏è ht...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df['content'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb602223",
   "metadata": {},
   "source": [
    "### Regular Expressions\n",
    "Regular expressions (also called 'regex or 'regexp') are patterns used to match, search, and manipulate text based on specific sequences of characters. They are extremely useful for extracting information, validating input, finding specific text, and replacing or splitting strings in tasks such as data cleaning, web scraping, and natural language processing.\n",
    "\n",
    "A regular expression is essentially a sequence of characters that defines a search pattern. This pattern can be made up of literal characters or special symbols (metacharacters) that represent sets, repetitions, or positions in the text.\n",
    "\n",
    "For example:\n",
    "- `/cat/` matches the exact sequence 'cat'.\n",
    "- `/c.t/` matches 'cat', 'cot', 'cut', etc. (the dot `.` matches any single character).\n",
    "- `/\\d+/` matches one or more digits (`\\d` means any digit and `+` means 'one or more').\n",
    "\n",
    "\n",
    "#### Common Regex Elements\n",
    "- **Literal Characters**: Match themselves (e.g., a, 1, @)\n",
    "- **Metacharacters**:\n",
    "    - `.` (dot): Any character except newline.\n",
    "    - `\\d`: Any digit(0-9).\n",
    "    - `\\w`: Any word character (letters, digits, underscore).\n",
    "    - `\\s`: Any whitespace character (space, tab, newline).\n",
    "    - `*`: Zero or more of the preceding elements.\n",
    "    - `+`: One or more of the preceding elements.\n",
    "    - `?`: Zero or one of the preceding element.\n",
    "    - `[]`: A set or range of characters (e.g., [a-z])\n",
    "    - `^`: Start of a string.\n",
    "    - `$`: End of a string.\n",
    "    - `|`: OR operator (e.g., `cat|dog` matches 'cat' or 'dog').\n",
    "    - `()`: Grouping for subpatterns.\n",
    "\n",
    "#### Example Use Cases\n",
    "- **Remove punctuation**: `r'[^\\w\\s]` matches anything that is not a word character or whitespace.\n",
    "- **Find email addresses**: `r'\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b'`\n",
    "- **Validate phone numbers**: Patterns like `r'^\\d{3}-\\d{3}-\\d{4}$'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc68997a",
   "metadata": {},
   "source": [
    "### Removing Punctuation and Special Characters\n",
    "Strip out punctuation, symbols, and special characters to reduce noise. Using `string.punctuation` makes the task easy and efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3110036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb60ced",
   "metadata": {},
   "source": [
    "`'[{}]'.format(string.punctuation)` inserts all these punctuation characters inside square brackets, resulting in a string like `'[!\"#$%&\\'()*+,-./:;<=>?@[\\$$^_{|}~]'`. Setting `regex=True` tells pandas to interpret the pattern as a regular expression. In case our data contains regex-special characters (such as `[`, `\\`, `^`), it's safer to escape them using `re.escape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb3262a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clean_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "61ba194c-48fe-4cc0-8aef-bf275e5e62e7",
       "rows": [
        [
         "5",
         "happy 96th gma #fourmoreyears! üéà @ LACMA Los Angeles County Museum of Art https://t.co/M9n7X8xdmA",
         "happy 96th gma fourmoreyears üéà  lacma los angeles county museum of art httpstcom9n7x8xdma"
        ],
        [
         "6",
         "Kyoto, Japan \r\n1. 5. 17. https://t.co/o28M0vw9lR",
         "kyoto japan \r\n1 5 17 httpstcoo28m0vw9lr"
        ],
        [
         "7",
         "üáØüáµ @ Sanrio Puroland https://t.co/eXVev5UMBx",
         "üáØüáµ  sanrio puroland httpstcoexvev5umbx"
        ],
        [
         "8",
         "2017 resolution: to embody authenticity!",
         "2017 resolution to embody authenticity"
        ],
        [
         "9",
         "sisters. https://t.co/5ZE21x2aNk",
         "sisters httpstco5ze21x2ank"
        ],
        [
         "10",
         "Happy Holidays! Sending love and light to every corner of the earth üéÅ",
         "happy holidays sending love and light to every corner of the earth üéÅ"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>happy 96th gma #fourmoreyears! üéà @ LACMA Los A...</td>\n",
       "      <td>happy 96th gma fourmoreyears üéà  lacma los ange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kyoto, Japan \\r\\n1. 5. 17. https://t.co/o28M0v...</td>\n",
       "      <td>kyoto japan \\r\\n1 5 17 httpstcoo28m0vw9lr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>üáØüáµ @ Sanrio Puroland https://t.co/eXVev5UMBx</td>\n",
       "      <td>üáØüáµ  sanrio puroland httpstcoexvev5umbx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017 resolution: to embody authenticity!</td>\n",
       "      <td>2017 resolution to embody authenticity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sisters. https://t.co/5ZE21x2aNk</td>\n",
       "      <td>sisters httpstco5ze21x2ank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Happy Holidays! Sending love and light to ever...</td>\n",
       "      <td>happy holidays sending love and light to every...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "5   happy 96th gma #fourmoreyears! üéà @ LACMA Los A...   \n",
       "6   Kyoto, Japan \\r\\n1. 5. 17. https://t.co/o28M0v...   \n",
       "7        üáØüáµ @ Sanrio Puroland https://t.co/eXVev5UMBx   \n",
       "8            2017 resolution: to embody authenticity!   \n",
       "9                    sisters. https://t.co/5ZE21x2aNk   \n",
       "10  Happy Holidays! Sending love and light to ever...   \n",
       "\n",
       "                                           clean_text  \n",
       "5   happy 96th gma fourmoreyears üéà  lacma los ange...  \n",
       "6           kyoto japan \\r\\n1 5 17 httpstcoo28m0vw9lr  \n",
       "7              üáØüáµ  sanrio puroland httpstcoexvev5umbx  \n",
       "8              2017 resolution to embody authenticity  \n",
       "9                          sisters httpstco5ze21x2ank  \n",
       "10  happy holidays sending love and light to every...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "df['clean_text'] = df['clean_text'].str.replace(\n",
    "    '[{}]'.format(re.escape(string.punctuation)), '', regex=True)\n",
    "df.iloc[5:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b8269",
   "metadata": {},
   "source": [
    "### Tokenisation\n",
    "Tokenisation is the process of splitting text into smaller units called tokens. In NLP, tokens are typically words, subwords, or sentences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
