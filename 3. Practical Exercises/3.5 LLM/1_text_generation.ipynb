{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb3b7d3",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "***\n",
    "## Table of Contents\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f809ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c49ec7",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "\n",
    "## 2. Device Agnostic Code\n",
    "Mac GPU acceleration (`mps` backend) delivers significant speed-up over CPU for deep learning tasks, especially for large models and batch sizes. On Windows, `cuda` is used instead of `mps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9cc87fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEVICE = torch.device(\n",
    "#     device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# )  # For Windows\n",
    "DEVICE = torch.device(\n",
    "    device=\"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")  # For MacOS\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e8ddb7",
   "metadata": {},
   "source": [
    "## 3. Loading Pre-Trained Model\n",
    "### GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e524fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-large\"\n",
    "MAX_TOKENS = 50\n",
    "MODEL = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\")\n",
    "TOKENISER = AutoTokenizer.from_pretrained(MODEL_NAME, padding_side=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ddfada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.generation_config.pad_token_id = MODEL.generation_config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855e8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Hello! Today I am\"\n",
    "\n",
    "model_inputs = TOKENISER(input_text, return_tensors=\"pt\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2f85467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[15496,     0,  6288,   314,   716]], device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1]], device='mps:0')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb9634",
   "metadata": {},
   "source": [
    "## 4. Basic Generation Strategies\n",
    "### Greedy Search\n",
    "Greedy Search is the default setting of decoding strategy used by `.generate()`. At each step, it selects the token with the highest probability as the next token. This method is simple and fast, thus is suitable for generating short text. However, for longer text, it can lead to repetitive and less diverse sequences.\n",
    "\n",
    "By default, greedy search generates up to 20 new tokens unless specified in `GenerationConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1316bc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Today I am going to show you how to make a simple and easy to use, but very useful, tool for\n"
     ]
    }
   ],
   "source": [
    "generated_ids = MODEL.generate(**model_inputs)\n",
    "print(TOKENISER.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386670d6",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "Sampling selects a next token randomly based on the probability distribution over the entire vocabulary of the model. This reduces repetition and can generate more creative, diverse outputs compared to the greedy search strategy.\n",
    "\n",
    "Sampling is enabled by setting the parameters: `do_sample=True` and `num_beams=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27fbac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Today I am pleased to share with you a great article from World Chess that is a great read for anyone who is\n"
     ]
    }
   ],
   "source": [
    "generated_ids = MODEL.generate(**model_inputs, do_sample=True, num_beams=1)\n",
    "print(TOKENISER.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180c8f6",
   "metadata": {},
   "source": [
    "### Beam Search\n",
    "Beam Search maintains multiple candidate sequences (beams) simultaneously. At each step, it expands each beam by selecting tokens, then retains the top $k$ beams based on cumulative (overall) probability score. This strategy is suited for input-grounded tasks such as image captioning or speech recognition.\n",
    "\n",
    "Beam search is enabled by setting `num_beams > 1`, optionally combined with `do_sample = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f65d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Today I am going to show you how to create a simple web application using ASP.NET MVC 4 and ASP.NET Web API.\n",
      "\n",
      "I am going to show you how to create a simple web application using ASP.NET MVC 4 and ASP.NET Web API.\n",
      "\n",
      "I am going to show you how to create a simple web application using ASP.NET MVC 4 and ASP.NET Web API.\n",
      "\n",
      "I am going to show you how to create a simple web application using ASP.NET MVC 4 and ASP.NET Web API.\n",
      "\n",
      "I am going to show you how to create\n"
     ]
    }
   ],
   "source": [
    "generated_ids = MODEL.generate(\n",
    "    **model_inputs, max_new_tokens=MAX_TOKENS, num_beams=5, do_sample=False\n",
    ")\n",
    "print(TOKENISER.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f598d0",
   "metadata": {},
   "source": [
    "### Nucleus Sampling (Top-p Sampling)\n",
    "Instead of selecting from the entire vocabulary, Nucleus Sampling samples from the smallest set of tokens whose cumulative probability exceeds the threshold $p$. This introduces controlled randomness, resulting in more diverse and creative text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc91d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Today I am going to show you how to install a simple but very simple web application in just a few minutes, that's why I call it a simple but very simple application. In this tutorial, we will not get into server-side frameworks or anything like that. It is not that kind of a web application. It is an interactive one and a web framework. It is not that kind of a web application. It is an interactive one and a web framework.\n",
      "\n",
      "Let's start the tutorial with the basics. It is really easy to start with a simple web application, because you don't need any other knowledge to\n"
     ]
    }
   ],
   "source": [
    "generated_ids = MODEL.generate(\n",
    "    **model_inputs, max_new_tokens=MAX_TOKENS, do_sample=True, top_p=0.9\n",
    ")\n",
    "print(TOKENISER.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
