{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3b32c9",
   "metadata": {},
   "source": [
    "# LangChain Fundamentals\n",
    "***\n",
    "## Table of Contents\n",
    "***\n",
    "\n",
    "1. [Introduction](#1-introduction)\n",
    "1. [Environmental Variables](#2-environmental-variables)\n",
    "1. [Using Language Model](#3-using-language-model)\n",
    "    - [Loading Model](#loading-model)\n",
    "    - [Interacting with Language Model](#interacting-with-language-model)\n",
    "    - [Prompt Template](#prompt-template)\n",
    "    - [Formatting with Pydantic](#formatting-with-pydantic)\n",
    "    - [Runnables](#runnables)\n",
    "1. [LangSmith](#4-langsmith)\n",
    "    - [Default Tracing](#default-tracing)\n",
    "    - [Non-LangChain Code Tracing](#non-langchain-code-tracing)\n",
    "1. [Sequential Chain](#5-sequential-chain)\n",
    "1. [Semantic Search](#6-semantic-search)\n",
    "    - [Document Class](#document-class)\n",
    "    - [Splitters](#splitters)\n",
    "    - [Embeddings](#embeddings)\n",
    "    - [Vector Stores](#vector-stores)\n",
    "    - [Retrievers](#retrievers)\n",
    "1. [References](#7-references)\n",
    "\n",
    "***\n",
    "## 1. Introduction\n",
    "For developing modern applications powered by large language models (LLMs), the LangChain ecosystem is the most popular / best practice framework offering thorough simplification and robustness suitable for production-ready deployments.\n",
    "\n",
    "The LangChain ecosystem comprises several key libraries:\n",
    "\n",
    "- **LangChain** for core development of LLM-powered applications, providing abstractions, chains, and retrieval mechanisms.\n",
    "- **LangSmith** for monitoring, evaluating, and debugging LangChain applications.\n",
    "- **LangGraph** for orchestrating stateful, complex multi-agent workflows and building advanced AI pipelines.\n",
    "\n",
    "This project covers the fundamentals of LangChain through practical examples, referencing official tutorials and educational videos from YouTube as learning resources.\n",
    "\n",
    "## 2. Environmental Variables\n",
    "Firstly, environmental variables need to be configured. These variables, especially API keys should never be hardcoded or made visible to others. The [python-dotenv](https://pypi.org/project/python-dotenv/) libray makes it straightforward to securely access variables set in a `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8f59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    raise ImportError(\"Error: 'python-dotenv' not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5285339",
   "metadata": {},
   "source": [
    "`os.environ` is a dictionary-like object representing the environment variables of the current process. It allows users to assign new values using the syntax: `os.environ['some_key'] = 'some_value'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9b7efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\n",
    "    \"Enter OpenAI API key: \"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549a505",
   "metadata": {},
   "source": [
    "## 3. Using Language Model\n",
    "### Loading Model\n",
    "There are multiple approaches to loading language models:\n",
    "1. Use `init_chat_model` from `langchain.chat_models`, with specified model name and provider. \n",
    "2. Specify the model's integration package first, then call the appropriate method to initialise the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b79fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "# 1. Simpler call\n",
    "# model = init_chat_model(model=model_name, model_provider=\"openai\", temperature=0.8)\n",
    "\n",
    "# 2. Directly use of the integration package\n",
    "model = ChatOpenAI(model=model_name, temperature=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd67751",
   "metadata": {},
   "source": [
    "### Interacting with Language Model\n",
    "For a simple call, we can pass `messages` to the `.invoke` method. The list of message objects (`messages`) can be categorised into three parts:\n",
    "- SystemMessage: Text that guides or determines AI's behaviour or actions.\n",
    "- HumanMessage: Input given by a user.\n",
    "- AIMessage: Output generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd53726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Aujourd'hui est une belle journée.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 24, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C7SnZoVQPtQDQmWHqahQWkyPqy9lo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--03b5332e-0983-4a42-b4b9-a34ec2daa615-0', usage_metadata={'input_tokens': 24, 'output_tokens': 7, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following message from English into French\"),\n",
    "    HumanMessage(content=\"Today is a beautiful day\"),\n",
    "]\n",
    "\n",
    "model.invoke(input=messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3a4dd",
   "metadata": {},
   "source": [
    "### Prompt Template\n",
    "A prompt template provides a structured way of creating inputs for language models where parts of the prompt can be dynamically changed based on context or user input.\n",
    "\n",
    "Prompts in LangChain can be split into three components:\n",
    "- System Prompt: Gives instructions or a personality to the LLM model. This prompt determines the behaviour or characteristics of the model.\n",
    "- User Prompt: Input given by a user.\n",
    "- AI Prompt: Output generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59e2fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    template=\"You are an AI translater. Translate text from English to {language}\",\n",
    "    input_variables=[\"language\"],\n",
    ")\n",
    "\n",
    "user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    template=\"\"\"Your task is to translate a text. The text to be translated is:\n",
    "    ---\n",
    "    {text}\n",
    "    ---\n",
    "    Output only the translated text, no other explanation or text should be provided\n",
    "    \"\"\",\n",
    "    input_variables=[\"text\"],  # Define a variable\n",
    ")\n",
    "\n",
    "text_in_english = \"\"\"\n",
    "A croissant is a French Viennoiserie in a crescent shape made from a laminated yeast dough that sits between a bread and a puff pastry.\n",
    "\"\"\"\n",
    "\n",
    "target_language = \"French\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3872501a",
   "metadata": {},
   "source": [
    "Let's display the formatted user prompt after inserting a value into the `text` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f083c60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your task is to translate a text. The text to be translated is:\\n    ---\\n    \\nA croissant is a French Viennoiserie in a crescent shape made from a laminated yeast dough that sits between a bread and a puff pastry.\\n\\n    ---\\n    Output only the translated text, no other explanation or text should be provided\\n    ' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt.format(text=text_in_english))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe6fb3",
   "metadata": {},
   "source": [
    "After defining system and user prompts, we can merge them into a full chat prompt using `ChatPromptTemplate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d843d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([system_prompt, user_prompt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da176b9",
   "metadata": {},
   "source": [
    "ChatPromptTemplate adds a prefix indicating a role of each message (e.g., System:, Human: or AI:)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d96e587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an AI translater. Translate text from English to French\n",
      "Human: Your task is to translate a text. The text to be translated is:\n",
      "    ---\n",
      "    \n",
      "A croissant is a French Viennoiserie in a crescent shape made from a laminated yeast dough that sits between a bread and a puff pastry.\n",
      "\n",
      "    ---\n",
      "    Output only the translated text, no other explanation or text should be provided\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(text=text_in_english, language=target_language))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3289d5",
   "metadata": {},
   "source": [
    "Using **L**ang**C**hain **E**xpression **L**anguage (LCEL), we can construct a chain that links the user input, prompt templates, the model and the output in a sequence:\n",
    "\n",
    "`input | prompt template | model | output`\n",
    "\n",
    "This pipeline enables smooth data flow, where the user input is formatted by the prompt template, passed to the model for inference, and the model's response is captured as the output.\n",
    "\n",
    "Note that lambda expressions are required to access prompt template variables. These variables are stored within input dictionaries or complex objects, thus the lambdas explicity extract or map the necessary fields from these data structures to ensure the correct values are passed to each stage in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d56e224e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translated_text': \"Un croissant est une viennoiserie française en forme de croissant, faite à partir d'une pâte levée feuilletée qui se situe entre le pain et la pâte feuilletée.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"text\": lambda x: x[\"text\"], \"language\": lambda x: x[\"language\"]}\n",
    "    | prompt_template\n",
    "    | model\n",
    "    | {\"translated_text\": lambda x: x.content}\n",
    ")\n",
    "\n",
    "chain.invoke(input={\"text\": text_in_english, \"language\": target_language})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c373cc34",
   "metadata": {},
   "source": [
    "### Formatting with Pydantic\n",
    "Using Pydantic, we can enforce a specific format or data structure on the output generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15fee6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'org_text': 'A croissant is a French Viennoiserie in a crescent shape made from a laminated yeast dough that sits between a bread and a puff pastry.',\n",
       " 'tl_text': \"Un croissant est une viennoiserie française en forme de croissant faite d'une pâte à levure laminée qui se situe entre un pain et une pâte feuilletée.\",\n",
       " 'n_words': 26}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Translation(BaseModel):\n",
    "    org_text: str = Field(description=\"Original text\")\n",
    "    tl_text: str = Field(description=\"Translated text\")\n",
    "    n_words: int = Field(description=\"Number of words in the translated text\")\n",
    "\n",
    "\n",
    "structured_model = model.with_structured_output(Translation)\n",
    "\n",
    "second_system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "You are an AI translator. Translate a text from English to {language}.\n",
    "\"\"\",\n",
    "    input_variables=[\"language\"],\n",
    ")\n",
    "\n",
    "second_user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "    Your task is to translate the following text:\n",
    "    ---\n",
    "    {text}\n",
    "    ---\n",
    "\n",
    "    then count the number of words in the translated text. \n",
    "    Output only the translated text and the word counts, no other explanation or text should be provided.\n",
    "\"\"\",\n",
    "    input_variables=[\"text\"],\n",
    ")\n",
    "\n",
    "second_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [second_system_prompt, second_user_prompt]\n",
    ")\n",
    "\n",
    "second_chain = (\n",
    "    {\n",
    "        \"text\": lambda x: x[\"text\"],\n",
    "        \"language\": lambda x: x[\"language\"],\n",
    "    }\n",
    "    | second_prompt_template\n",
    "    | structured_model\n",
    "    | {\n",
    "        \"org_text\": lambda x: x.org_text,\n",
    "        \"tl_text\": lambda x: x.tl_text,\n",
    "        \"n_words\": lambda x: x.n_words,\n",
    "    }\n",
    ")\n",
    "second_chain.invoke(input={\"text\": text_in_english, \"language\": target_language})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b5ec3",
   "metadata": {},
   "source": [
    "### Runnables\n",
    "In LangChain, runnables are modular, executable building blocks (units of work) that can be invoked, batched, streamed, transformed, and composed across various LangChain components. Chains and their components are all implemented as runnables.\n",
    "\n",
    "- **RunnableSequence**: A class that chains multiple runnable components together.\n",
    "- **RunnableLambda**: A class that turns a Python callable (e.g., function or lambda) into a runnable component.\n",
    "- **RunnablePassthrough**: A class that passes its input through unmodified (as a placeholder) or adds additional keys to the output for flexible integration into runnable sequences.\n",
    "- **RunnableParallel**: A class that runs multiple runnables concurrently.\n",
    "\n",
    "The following example demonstrates the use of `RunnableLambda`. By wrapping a function with `RunnableLambda`, it becomes a runnable and can then be called with the `.invoke` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd21204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Alice!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def greet(name) -> str:\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "\n",
    "greet_runnable = RunnableLambda(\n",
    "    func=lambda x: greet(name=x)\n",
    ")  # Wrap function as Runnable\n",
    "\n",
    "result = greet_runnable.invoke(input=\"Alice\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912f6b1",
   "metadata": {},
   "source": [
    "## 4. LangSmith\n",
    "LangSmith is a comprehensive platform developed by the LangChain team for observability, debugging, testing, and evaluation of large language model (LLM) applications. It helps developers monitor and improve AI-powered apps by capturing detailed traces of interactions, including inputs, outputs, intermediate steps, execution times, and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47472055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project name: lc_fundamentals\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\") or getpass(\n",
    "    \"Enter LangSmith API key: \"\n",
    ")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\") or getpass(\n",
    "    \"Enter project name: \"\n",
    ")\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\") or getpass(\n",
    "    \"Enter LangSmith endpoint: \"\n",
    ")\n",
    "\n",
    "print(f\"Project name: {os.environ['LANGSMITH_PROJECT']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c2e90",
   "metadata": {},
   "source": [
    "### Default Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4babe941",
   "metadata": {},
   "source": [
    "If the API keys and parameters were properly configured in the `.env` file, the executions above should have been traced on [LangSmith UI](https://eu.smith.langchain.com/). LangSmith automatically records logs (e.g., inputs, outputs, errors, and execution time) which greatly facilitates the debugging process.\n",
    "\n",
    "![Default Trace](_images/default_trace.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d4bf3a",
   "metadata": {},
   "source": [
    "### Non-LangChain Code Tracing\n",
    "By adding the `@traceable` decorator, LangSmith will be able to trace non-LangChain functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d56b7e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Odd value. No problem.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "import random\n",
    "\n",
    "\n",
    "@traceable\n",
    "def generate_random_int():\n",
    "    num = random.randint(1, 10)\n",
    "    if num % 2 == 0:\n",
    "        raise ValueError(\"Error: The value has to be odd.\")\n",
    "    else:\n",
    "        return \"Odd value. No problem.\"\n",
    "\n",
    "\n",
    "generate_random_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94358a6b",
   "metadata": {},
   "source": [
    "![Traceable](_images/traceable.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdc6fc5",
   "metadata": {},
   "source": [
    "## 5. Sequential Chain\n",
    "A Sequential Chain is a chain that executes multiple steps (or sub-chains) in a defined order, where the output of one step becomes the input to the next. This allows us to build complex workflows by composing simpler chains sequentially. In the following example, the first chain takes the input `ingredient` and generates a `dish` that uses the ingredient. Then, the second chain takes the `dish` name as input and writes a `description` of the dish, returning the description as the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2b05725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/71/96lm97d97jd1rltw9bhztxc80000gn/T/ipykernel_80058/4130563447.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain_1 = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'ingredient': 'tomato', 'dish': 'Tomato Basil Risotto', 'description': 'Tomato Basil Risotto is a creamy, comforting Italian dish made from Arborio rice simmered slowly in a flavorful broth until tender and velvety. Fresh tomatoes and aromatic basil are stirred in, infusing the risotto with vibrant flavors and a hint of sweetness. This dish is often finished with a sprinkle of Parmesan cheese, adding richness and depth to each bite.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chain_1 = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"ingredient\"],\n",
    "        template=\"Generate a dish that uses {ingredient}. Output only the dish's name.\",\n",
    "    ),\n",
    "    output_key=\"dish\",\n",
    ")\n",
    "\n",
    "chain_2 = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"dish\"],\n",
    "        template=\"Write a simple description of {dish} in 2 - 3 sentences.\",\n",
    "    ),\n",
    "    output_key=\"description\",\n",
    ")\n",
    "\n",
    "sequential_chain = SequentialChain(\n",
    "    chains=[chain_1, chain_2],\n",
    "    input_variables=[\"ingredient\"],\n",
    "    output_variables=[\"dish\", \"description\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result = sequential_chain.invoke({\"ingredient\": \"tomato\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d1447",
   "metadata": {},
   "source": [
    "## 6. Semantic Search\n",
    "### Document Class\n",
    "To handle external data (e.g., websites, PDF files), the Document class stores a piece of text along with its associated metadata. The following are the three attributes of the Document class:\n",
    "\n",
    "- `page_content`: Content in string.\n",
    "- `metadata`: Dictionary including metadata.\n",
    "- `id` (optional): Identifier in string for the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1f85172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "doc = Document(\n",
    "    page_content=\"Page content in string format.\",\n",
    "    metadata={\"source\": \"https://example.com\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce089ae5",
   "metadata": {},
   "source": [
    "`PyPDFLoader` facilitates loading a single Document object per PDF (the `pypdf` package is required), and the `.load()` method returns a list containing the page content and metadata from the PDF file. To access the data, it is necessary to use the index `[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f740c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pages: 107\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"_datasets/nke-10k-2023.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Total number of pages: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb158941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAGE CONTENT:\n",
      "********************\n",
      "Table of Contents\n",
      "UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "FORM 10-K\n",
      "\n",
      "\n",
      "META DATA:\n",
      "********************\n",
      "{'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': '_datasets/nke-10k-2023.pdf', 'total_pages': 107, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"PAGE CONTENT:\\n{'*' * 20}\\n{docs[0].page_content[:100]}\\n\")\n",
    "print(f\"META DATA:\\n{'*' * 20}\\n{docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8607778",
   "metadata": {},
   "source": [
    "### Splitters\n",
    "Splitters are utility classes in LangChain designed to divide large bodies of text or document objects into smaller chunks. The most common example is the `TextSplitter`, such as the `ResursiveCharacterTextSplitter` which splits documents based on character count, overlap, or other configurable criteria.\n",
    "\n",
    "Text splitters ensure that content is broken down into appropriate sized chunks that do not exceed the maximum token limit of LLMs, thereby generating more precise embeddings. This approach also facilitates parallel (batch) processing of document chunks. By setting the `chunk_overlap` parameter, splitters preserve context across adjacent chunks, reducing the loss of important information and improving retrieval accuracy in retrieval-augmented generation (RAG) systems.\n",
    "\n",
    "The following example splits the loaded document into chunks of up to 1000 characters with 200 characters of overlap between chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cb7cd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 516\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Total number of chunks: {len(all_splits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e47f0ab",
   "metadata": {},
   "source": [
    "Here are the details of the parameters:\n",
    "\n",
    "- `chunk_size`: Determines the **maximum number** of characters each chunk can contain.\n",
    "- `chunk_overlap`: Specifies the number of characters to overlap at the end of a chunk, which will be repeated at the start of the next chunk. This helps to preserve context at the boundaries between chunks.\n",
    "- `add_start_index`: When set to `True`, each split `Document` will include metadata indicating the starting character index of that chunk within the original document.\n",
    "\n",
    "The `RecursiveCharacterTextSplitter` prioritises splitting at natural boundaries (e.g., paragraphs, sentences, or newline characters) rather than splitting strictly at the chunk size. This segmentation avoids cutting text in the middle of words or sentences; therefore, setting the `chunk_size` parameter to 1000 can result in chunks containing fewer than 1000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d95ed9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in the 1st chunk: 972\n",
      "\n",
      "Table of Contents\n",
      "UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "FORM 10-K\n",
      "(Mark One)\n",
      "☑  ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "FOR THE FISCAL YEAR ENDED MAY 31, 2023\n",
      "OR\n",
      "☐  TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(D) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "FOR THE TRANSITION PERIOD FROM                         TO                         .\n",
      "Commission File No. 1-10635\n",
      "NIKE, Inc.\n",
      "(Exact name of Registrant as specified in its charter)\n",
      "Oregon 93-0584541\n",
      "(State or other jurisdiction of incorporation) (IRS Employer Identification No.)\n",
      "One Bowerman Drive, Beaverton, Oregon 97005-6453\n",
      "(Address of principal executive offices and zip code)\n",
      "(503) 671-6453\n",
      "(Registrant's telephone number, including area code)\n",
      "SECURITIES REGISTERED PURSUANT TO SECTION 12(B) OF THE ACT:\n",
      "Class B Common Stock NKE New York Stock Exchange\n",
      "(Title of each class) (Trading symbol) (Name of each exchange on which registered)\n",
      "\n",
      "{'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': '_datasets/nke-10k-2023.pdf', 'total_pages': 107, 'page': 0, 'page_label': '1', 'start_index': 0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of characters in the 1st chunk: {len(all_splits[0].page_content)}\\n\")\n",
    "print(f\"{all_splits[0].page_content}\\n\")\n",
    "print(f\"{all_splits[0].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9d20288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in the 2nd chunk: 975\n",
      "\n",
      "SECURITIES REGISTERED PURSUANT TO SECTION 12(B) OF THE ACT:\n",
      "Class B Common Stock NKE New York Stock Exchange\n",
      "(Title of each class) (Trading symbol) (Name of each exchange on which registered)\n",
      "SECURITIES REGISTERED PURSUANT TO SECTION 12(G) OF THE ACT:\n",
      "NONE\n",
      "Indicate by check mark: YES NO\n",
      "• if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act. þ ¨ \n",
      "• if the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act. ¨ þ \n",
      "• whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding\n",
      "12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the\n",
      "past 90 days.\n",
      "þ ¨ \n",
      "• whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T\n",
      "\n",
      "{'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'title': '0000320187-23-000039', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'moddate': '2023-07-20T16:22:08-04:00', 'source': '_datasets/nke-10k-2023.pdf', 'total_pages': 107, 'page': 0, 'page_label': '1', 'start_index': 781}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of characters in the 2nd chunk: {len(all_splits[1].page_content)}\\n\")\n",
    "print(f\"{all_splits[1].page_content}\\n\")\n",
    "print(f\"{all_splits[1].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d4f898",
   "metadata": {},
   "source": [
    "As described above, the first chunk (`start_index=0`) contains the first 972 (< 1000) characters with indices 0–971, and the second chunk (`start_index=781`) includes 975 (< 1000) characters starting from index 781. Each chunk is split at natural boundaries, with up to 200 characters overlapping between chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95972caa",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "Embeddings are numerical representations that map words, sentences, or documents into vectors within a high-dimensional space. These vectors capture the semantic meaning of the text, such that texts with similar meanings have vectors located close to each other. Each piece of text is converted into a vector using machine learning models trained to understand language semantics. Similarity between texts is then measured using vector similarity metrics (e.g., cosine similarity, Euclidean distance, inner product), which quantify the geometric closeness of their corresponding vectors.\n",
    "\n",
    "This technique forms the basis of **vector search** to find the most similar data to a given query by comparing their vector representations.\n",
    "\n",
    "The following example uses the `text-embedding-3-large` model from OpenAI to encode the semantic meaning of the first two text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0421f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of length: 3072\n",
      "\n",
      "[0.00932583399116993, -0.01603718101978302, 0.0003375610976945609, 0.006354826968163252, 0.020478054881095886]\n",
      "[0.01703420653939247, -0.018381766974925995, -0.006770508363842964, 0.030064981430768967, 0.020579729229211807]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "print(f\"Generated vectors of length: {len(vector_1)}\\n\")\n",
    "print(vector_1[:5])\n",
    "print(vector_2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f34d0",
   "metadata": {},
   "source": [
    "Note that each value in an embedding vector represents a coordinate in a high-dimensional space encoding latent semantic features of the entire input text. In the example above, the entire texts in the first and second chunks are projected as a whole and encoded as single vectors in the same vector space. However, these individual values do not have explicit, human-interpretable meanings on their own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09bfb47",
   "metadata": {},
   "source": [
    "### Vector Stores\n",
    "**Vector Stores** (also called **Vector Databases** or **Vector Search Engines**) are specialised data storage systems designed to store, index, and retrieve vector embeddings based on the similarity of the data. Unlike traditional databases, which handle structured data in tables and rows, vector stores are optimised to manage unstructured or semi-structured data that has been converted into high-dimensional vectors.\n",
    "\n",
    "LangChain offers integrations with a variety of vector store technologies, some of which are hosted by providers and require specific credentials to use.\n",
    "\n",
    "The following is the basic in-memory vector store implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8a590b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b8f3b",
   "metadata": {},
   "source": [
    "Or, using a Chroma vector database using LangChain's Chroma integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "109f084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"lc_fundamentals\",  # Set local db name\n",
    "    embedding_function=embeddings,  # Embedding function to use\n",
    "    persist_directory=\"./chroma_lc_db\",  # Directory to save\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faeebe8",
   "metadata": {},
   "source": [
    "This implementation defines the local directory path where the Chroma vector data and index will be persisted on disk. It enables the data to be saved in a local database and reloaded across sessions.\n",
    "\n",
    "After instantiating the vector store, we will be able to index the documents. These IDs are unique identifiers (UUIDs) automatically generated for each document or embedding entry stored in the vector database. They serve as references to the specific records for internal management and retrieval purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "511f5ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e73711ee-4e1a-4952-95b4-e6ee5783ec14', 'fa2727d0-3ed3-4477-baa5-9bbfacfc2f2f', '531cc7ae-158c-4663-a87f-3cfc2c7e6489', '99565c7c-319e-4240-9b50-588b410b86a4', 'fad2c9f6-01de-4d0b-8b3a-af9b49700890']\n"
     ]
    }
   ],
   "source": [
    "ids = vector_store.add_documents(documents=all_splits)\n",
    "print(ids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fbeb08",
   "metadata": {},
   "source": [
    "The `.similarity_search()` method takes a string query as input and returns information relevant to that query. The query can also be processed asynchronously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "566ca634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='operations. We also lease an office complex in Shanghai, China, our headquarters for our Greater China geography, occupied by employees focused on implementing our\n",
      "wholesale, NIKE Direct and merchandising strategies in the region, among other functions.\n",
      "In the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of which are owned and three of which are\n",
      "leased. Two other distribution centers, one located in Indianapolis, Indiana and one located in Dayton, Tennessee, are leased and operated by third-party logistics\n",
      "providers. One distribution center for Converse is located in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States,\n",
      "some of which are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United States are located in Laakdal,' metadata={'page_label': '27', 'page': 26, 'title': '0000320187-23-000039', 'moddate': '2023-07-20T16:22:08-04:00', 'keywords': '0000320187-23-000039; ; 10-K', 'creator': 'EDGAR Filing HTML Converter', 'start_index': 804, 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'total_pages': 107, 'creationdate': '2023-07-20T16:22:00-04:00', 'source': '_datasets/nke-10k-2023.pdf', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31'}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    query=\"How many distribution centres does Nike have in the US?\"\n",
    ")\n",
    "\n",
    "# results = await vector_store.asimilarity_search(\n",
    "#     query=\"How many distribution centres does Nike have in the US?\"\n",
    "# )\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c14398",
   "metadata": {},
   "source": [
    "The `.similarity_search_with_score()` method performs the same search as `.similarity_search()` but also returns the similarity score for each result. The specific similarity metric used can vary depending on the vector store provider and implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37bd8a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6236852407455444\n",
      "\n",
      "page_content='Table of Contents\n",
      "FISCAL 2023 NIKE BRAND REVENUE HIGHLIGHTSThe following tables present NIKE Brand revenues disaggregated by reportable operating segment, distribution channel and major product line:\n",
      "FISCAL 2023 COMPARED TO FISCAL 2022\n",
      "• NIKE, Inc. Revenues were $51.2 billion in fiscal 2023, which increased 10% and 16% compared to fiscal 2022 on a reported and currency-neutral basis, respectively.\n",
      "The increase was due to higher revenues in North America, Europe, Middle East & Africa (\"EMEA\"), APLA and Greater China, which contributed approximately 7, 6,\n",
      "2 and 1 percentage points to NIKE, Inc. Revenues, respectively.\n",
      "• NIKE Brand revenues, which represented over 90% of NIKE, Inc. Revenues, increased 10% and 16% on a reported and currency-neutral basis, respectively. This\n",
      "increase was primarily due to higher revenues in Men's, the Jordan Brand, Women's and Kids' which grew 17%, 35%,11% and 10%, respectively, on a wholesale\n",
      "equivalent basis.' metadata={'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'creationdate': '2023-07-20T16:22:00-04:00', 'keywords': '0000320187-23-000039; ; 10-K', 'total_pages': 107, 'source': '_datasets/nke-10k-2023.pdf', 'page': 35, 'moddate': '2023-07-20T16:22:08-04:00', 'title': '0000320187-23-000039', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'page_label': '36', 'creator': 'EDGAR Filing HTML Converter', 'start_index': 0, 'author': 'EDGAR Online, a division of Donnelley Financial Solutions'}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    query=\"What was Nike's revenue in 2023?\"\n",
    ")\n",
    "doc, score = results[0]\n",
    "print(f\"Score: {score}\\n\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beebc14",
   "metadata": {},
   "source": [
    "### Retrievers\n",
    "Retrievers in LangChain are components responsible for fetching relevant information based on a query. They serve as an interface between the user's query and a data storage or search system (e.g., vector stores or external APIs). Retrievers are runnable components, meaning they support standard runnable operations such as `.invoke()` and `.batch()`.\n",
    "\n",
    "By wrapping the `.similarity_search()` method with a function and adding the `@chain` decorator, the non-runnable similarity search method can be effectively transformed into a runnable retriever.\n",
    "Finally, the `.batch()` method allows querying multiple questions at once, making retrieval efficient for bulk queries or parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d381327d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='ca49aae5-2196-4bf5-8cf2-65006bc5ca05', metadata={'keywords': '0000320187-23-000039; ; 10-K', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'moddate': '2023-07-20T16:22:08-04:00', 'start_index': 804, 'page_label': '27', 'source': '_datasets/nke-10k-2023.pdf', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'total_pages': 107, 'creator': 'EDGAR Filing HTML Converter', 'creationdate': '2023-07-20T16:22:00-04:00', 'page': 26, 'title': '0000320187-23-000039', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31'}, page_content='operations. We also lease an office complex in Shanghai, China, our headquarters for our Greater China geography, occupied by employees focused on implementing our\\nwholesale, NIKE Direct and merchandising strategies in the region, among other functions.\\nIn the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of which are owned and three of which are\\nleased. Two other distribution centers, one located in Indianapolis, Indiana and one located in Dayton, Tennessee, are leased and operated by third-party logistics\\nproviders. One distribution center for Converse is located in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States,\\nsome of which are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United States are located in Laakdal,')],\n",
       " [Document(id='47be67c6-0200-48ca-bfa6-47f2b1b1250e', metadata={'moddate': '2023-07-20T16:22:08-04:00', 'total_pages': 107, 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'page_label': '4', 'creationdate': '2023-07-20T16:22:00-04:00', 'source': '_datasets/nke-10k-2023.pdf', 'creator': 'EDGAR Filing HTML Converter', 'page': 3, 'start_index': 0, 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'title': '0000320187-23-000039'}, page_content='Table of Contents\\nPART I\\nITEM 1. BUSINESS\\nGENERAL\\nNIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \"Annual Report\"), the terms \"we,\" \"us,\" \"our,\"\\n\"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries and affiliates, collectively, unless the context indicates otherwise.\\nOur principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, equipment, accessories and services. NIKE is\\nthe largest seller of athletic footwear and apparel in the world. We sell our products through NIKE Direct operations, which are comprised of both NIKE-owned retail stores\\nand sales through our digital platforms (also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales')]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> list[Document]:\n",
    "    return vector_store.similarity_search(query=query, k=1)\n",
    "\n",
    "\n",
    "retriever.batch(\n",
    "    inputs=[\n",
    "        \"How many distribution centres does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae1400",
   "metadata": {},
   "source": [
    "Otherwise, we can also use the `.as_retriever()` method implemented in vector stores to convert them into a `VectorStoreRetriever`. It accepts keyword arguments to customise the retrieval, such as:\n",
    "\n",
    "- `search_type`: Defines the type of search, e.g., `similarity` (default), `mmr` for maximum marginal relevance, or `similarity_score_threshold`.\n",
    "- search_kwargs: Additional parameters passed to the underlying search method, e.g., number of documents to return (`k`), score thresholds,filters, etc.\n",
    "\n",
    "The returned retriever can then be used with standard retriever methods such as `.invoke()` and `.batch()` to fetch relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbb46bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='ca49aae5-2196-4bf5-8cf2-65006bc5ca05', metadata={'title': '0000320187-23-000039', 'page': 26, 'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'total_pages': 107, 'source': '_datasets/nke-10k-2023.pdf', 'creationdate': '2023-07-20T16:22:00-04:00', 'creator': 'EDGAR Filing HTML Converter', 'moddate': '2023-07-20T16:22:08-04:00', 'start_index': 804, 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'page_label': '27', 'keywords': '0000320187-23-000039; ; 10-K'}, page_content='operations. We also lease an office complex in Shanghai, China, our headquarters for our Greater China geography, occupied by employees focused on implementing our\\nwholesale, NIKE Direct and merchandising strategies in the region, among other functions.\\nIn the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of which are owned and three of which are\\nleased. Two other distribution centers, one located in Indianapolis, Indiana and one located in Dayton, Tennessee, are leased and operated by third-party logistics\\nproviders. One distribution center for Converse is located in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States,\\nsome of which are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United States are located in Laakdal,')],\n",
       " [Document(id='47be67c6-0200-48ca-bfa6-47f2b1b1250e', metadata={'author': 'EDGAR Online, a division of Donnelley Financial Solutions', 'page_label': '4', 'page': 3, 'moddate': '2023-07-20T16:22:08-04:00', 'subject': 'Form 10-K filed on 2023-07-20 for the period ending 2023-05-31', 'keywords': '0000320187-23-000039; ; 10-K', 'creationdate': '2023-07-20T16:22:00-04:00', 'producer': 'EDGRpdf Service w/ EO.Pdf 22.0.40.0', 'title': '0000320187-23-000039', 'creator': 'EDGAR Filing HTML Converter', 'start_index': 0, 'total_pages': 107, 'source': '_datasets/nke-10k-2023.pdf'}, page_content='Table of Contents\\nPART I\\nITEM 1. BUSINESS\\nGENERAL\\nNIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \"Annual Report\"), the terms \"we,\" \"us,\" \"our,\"\\n\"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries and affiliates, collectively, unless the context indicates otherwise.\\nOur principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, equipment, accessories and services. NIKE is\\nthe largest seller of athletic footwear and apparel in the world. We sell our products through NIKE Direct operations, which are comprised of both NIKE-owned retail stores\\nand sales through our digital platforms (also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales')]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "\n",
    "retriever.batch(\n",
    "    inputs=[\n",
    "        \"How many distribution centres does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0464042",
   "metadata": {},
   "source": [
    "## 7. References\n",
    "\n",
    "1. aiwithbrandon. (2024). *LangChain master class for beginners 2024 [+20 examples, LangChain V0.2]* [Video]. YouTube.<br>\n",
    "https://www.youtube.com/watch?v=yF9kGESAi3M\n",
    "\n",
    "1. Rabbitmetrics. (2024). *Learn LangChain in 7 Easy Steps - Full Interactive Beginner Tutorial* [Video]. Youtube. <br>\n",
    "https://www.youtube.com/watch?v=8BV9TW490nQ\n",
    "\n",
    "1. GeeksforGeeks. (2025). *Python | os.environ object*<br>\n",
    "https://www.geeksforgeeks.org/python/python-os-environ-object\n",
    "\n",
    "1. Briggs, J. (2025). *LangChain Mastery in 2025 | Full 5 Hour Course [LangChain v0.3]* [Video]. Youtube.<br>\n",
    "https://www.youtube.com/watch?v=Cyv-dgv80kE\n",
    "\n",
    "1. LangChain. (n.d.). *Build a semantic search engine* [Tutorial].<br>\n",
    "https://python.langchain.com/docs/tutorials/retrievers/\n",
    "\n",
    "1. LangChain. (n.d.). *Build a simple LLM application with chat models and prompt templates* [Tutorial].<br>\n",
    "https://python.langchain.com/docs/tutorials/llm_chain/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
