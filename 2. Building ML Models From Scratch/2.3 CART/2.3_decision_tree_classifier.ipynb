{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1b6610",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier from Scratch\n",
    "***\n",
    "## Table of Contents\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f86ef6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71260664",
   "metadata": {},
   "source": [
    "Decision trees and regression trees are collectively referred to as **CART**, which stands for **Classification and Regression Trees**.\n",
    "\n",
    "- **Decision Trees** are used for classification tasks, where the target variable is *categorical*.\n",
    "\n",
    "- **Regression Trees** are used for regression tasks, where the target variable is *continuous*.\n",
    "\n",
    "CART is a popular algorithm that can handle both types of tasks by optimising for different criteria:\n",
    "\n",
    "- For classification, CART minimises classification error, Gini impurity, or entropy.\n",
    "\n",
    "- For regression, CART minimises the mean squared error (MSE) or mean absolute error (MAE).\n",
    "\n",
    "Both types of trees follow the same core idea of splitting the data based on conditions to create homogeneous subsets, but their objectives differ depending on the problem type.\n",
    "In this notebook, we will build a predictive model using Decision Trees on the breast cancer dataset from the scikit-learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4981d62",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "15b3cafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (569, 30)\n",
      "Target shape: (569,)\n",
      "Features: \n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = datasets.load_breast_cancer()\n",
    "# data = datasets.load_iris()\n",
    "X, y = data.data, data.target\n",
    "feature_names = data.feature_names\n",
    "\n",
    "# Check the shape of the data\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Features: \\n{feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a2c4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean radius",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean texture",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean perimeter",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean area",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean smoothness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean compactness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean concavity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean concave points",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean symmetry",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean fractal dimension",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "radius error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "texture error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "perimeter error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "area error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smoothness error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "compactness error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "concavity error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "concave points error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "symmetry error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fractal dimension error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst radius",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst texture",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst perimeter",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst area",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst smoothness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst compactness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst concavity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst concave points",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst symmetry",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "worst fractal dimension",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diagnosis",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "941e6895-908b-4f5e-b217-27fa376a0854",
       "rows": [
        [
         "0",
         "17.99",
         "10.38",
         "122.8",
         "1001.0",
         "0.1184",
         "0.2776",
         "0.3001",
         "0.1471",
         "0.2419",
         "0.07871",
         "1.095",
         "0.9053",
         "8.589",
         "153.4",
         "0.006399",
         "0.04904",
         "0.05373",
         "0.01587",
         "0.03003",
         "0.006193",
         "25.38",
         "17.33",
         "184.6",
         "2019.0",
         "0.1622",
         "0.6656",
         "0.7119",
         "0.2654",
         "0.4601",
         "0.1189",
         "0"
        ],
        [
         "1",
         "20.57",
         "17.77",
         "132.9",
         "1326.0",
         "0.08474",
         "0.07864",
         "0.0869",
         "0.07017",
         "0.1812",
         "0.05667",
         "0.5435",
         "0.7339",
         "3.398",
         "74.08",
         "0.005225",
         "0.01308",
         "0.0186",
         "0.0134",
         "0.01389",
         "0.003532",
         "24.99",
         "23.41",
         "158.8",
         "1956.0",
         "0.1238",
         "0.1866",
         "0.2416",
         "0.186",
         "0.275",
         "0.08902",
         "0"
        ],
        [
         "2",
         "19.69",
         "21.25",
         "130.0",
         "1203.0",
         "0.1096",
         "0.1599",
         "0.1974",
         "0.1279",
         "0.2069",
         "0.05999",
         "0.7456",
         "0.7869",
         "4.585",
         "94.03",
         "0.00615",
         "0.04006",
         "0.03832",
         "0.02058",
         "0.0225",
         "0.004571",
         "23.57",
         "25.53",
         "152.5",
         "1709.0",
         "0.1444",
         "0.4245",
         "0.4504",
         "0.243",
         "0.3613",
         "0.08758",
         "0"
        ],
        [
         "3",
         "11.42",
         "20.38",
         "77.58",
         "386.1",
         "0.1425",
         "0.2839",
         "0.2414",
         "0.1052",
         "0.2597",
         "0.09744",
         "0.4956",
         "1.156",
         "3.445",
         "27.23",
         "0.00911",
         "0.07458",
         "0.05661",
         "0.01867",
         "0.05963",
         "0.009208",
         "14.91",
         "26.5",
         "98.87",
         "567.7",
         "0.2098",
         "0.8663",
         "0.6869",
         "0.2575",
         "0.6638",
         "0.173",
         "0"
        ],
        [
         "4",
         "20.29",
         "14.34",
         "135.1",
         "1297.0",
         "0.1003",
         "0.1328",
         "0.198",
         "0.1043",
         "0.1809",
         "0.05883",
         "0.7572",
         "0.7813",
         "5.438",
         "94.44",
         "0.01149",
         "0.02461",
         "0.05688",
         "0.01885",
         "0.01756",
         "0.005115",
         "22.54",
         "16.67",
         "152.2",
         "1575.0",
         "0.1374",
         "0.205",
         "0.4",
         "0.1625",
         "0.2364",
         "0.07678",
         "0"
        ]
       ],
       "shape": {
        "columns": 31,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  diagnosis  \n",
       "0          0.4601                  0.11890          0  \n",
       "1          0.2750                  0.08902          0  \n",
       "2          0.3613                  0.08758          0  \n",
       "3          0.6638                  0.17300          0  \n",
       "4          0.2364                  0.07678          0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=X, columns=feature_names)\n",
    "df['diagnosis'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ddcbee40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "99d8e36e-79ff-4189-b4fc-3ea93a151e24",
       "rows": [
        [
         "1",
         "357"
        ],
        [
         "0",
         "212"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "target\n",
       "1    357\n",
       "0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ba008",
   "metadata": {},
   "source": [
    "In this dataset, the features represent the characteristics of breast cancer (e.g., radius, texture, etc.), while the target is a boolean value indicating whether the tumour is benign (0) or malignant (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3a784a",
   "metadata": {},
   "source": [
    "## 2. Train Test Split\n",
    "Train test split is a fundamental model validation technique in machine learning. It divides a dataset into two separate portions: a **training set** used to train a model, and a **testing set** used to evaluate how well the model can perform on unseen data. \n",
    "\n",
    "The typical split ratio is 80% for training and 20% for testing, though this can vary (70/30 or 90/10 are also common). The key principle is that the test set must remain completely separated during model training process, and should never be used to make decisions about the model or tune parameters. \n",
    "\n",
    "The split is usually done randomly to ensure both sets are representative of the overall dataset, and many libraries (such as scikit-learn) provide build-in functions that handle this process automatically while maintaining proper randomisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ec7e5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X: np.array, y: np.array, test_size: float = 0.2,\n",
    "                     random_state: int = None) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split arrays or matrices into random train and test subsets.\n",
    "\n",
    "    Parameters:\n",
    "        X (np.array): Input features, a 2D array with rows (samples) and columns (features).\n",
    "        y (np.array): Target values/labels, a 1D array with rows (samples).\n",
    "        test_size (float): Proportion of the dataset to include in the test split. Must be between 0.0 and 1.0. default = 0.2\n",
    "        random_state (int): Seed for the random number generator to ensure reproducible results. default = None\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        A tuple containing:\n",
    "            - X_train (np.ndarray): Training set features.\n",
    "            - X_test (np.ndarray): Testing set features.\n",
    "            - y_train (np.ndarray): Training set target values.\n",
    "            - y_test (np.ndarray): Testing set target values.\n",
    "    \"\"\"\n",
    "    # Set a random seed if it exists\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Create a list of numbers from 0 to len(X)\n",
    "    indices = np.arange(len(X))\n",
    "\n",
    "    # Shuffle the indices\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Define the size of our test data from len(X)\n",
    "    test_size = int(test_size * len(X))\n",
    "\n",
    "    # Generate indices for test and train data\n",
    "    test_indices: list[int] = indices[:test_size]\n",
    "    train_indices: list[int] = indices[test_size:]\n",
    "\n",
    "    # Return: X_train, X_test, y_train, y_test\n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a0681",
   "metadata": {},
   "source": [
    "## 3. Gini Impurity and Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "06703f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y):\n",
    "    proportions = np.bincount(y) / len(y)\n",
    "    return 1 - np.sum(proportions**2)\n",
    "\n",
    "def entropy(y):\n",
    "    proportions = np.bincount(y) / len(y)\n",
    "    proportions = proportions[proportions > 0]  # Avoid log(0)\n",
    "    return -np.sum(proportions * np.log2(proportions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b348c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Impurity: 0.4675300607546925\n",
      "Entropy: 0.9526351224018599\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini Impurity:\", gini(y))\n",
    "print(\"Entropy:\", entropy(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57153d6a",
   "metadata": {},
   "source": [
    "## 4. Information Gain\n",
    "The information_gain function calculates the difference between the metric for the parent node and the weighted average of the metrics for the child nodes (left and right splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f306b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(y, y_left, y_right, metric=\"gini\"):\n",
    "    \"\"\"\n",
    "    Calculate the information gain for a split.\n",
    "    Args:\n",
    "    - y: Target values of the parent node.\n",
    "    - y_left: Target values of the left child node.\n",
    "    - y_right: Target values of the right child node.\n",
    "    - metric: The metric to use ('gini' or 'entropy').\n",
    "    \n",
    "    Returns:\n",
    "    - Information gain (float).\n",
    "    \"\"\"\n",
    "    if metric == \"gini\":\n",
    "        parent_metric = gini(y)\n",
    "        left_metric = gini(y_left)\n",
    "        right_metric = gini(y_right)\n",
    "    else:  # metric == \"entropy\"\n",
    "        parent_metric = entropy(y)\n",
    "        left_metric = entropy(y_left)\n",
    "        right_metric = entropy(y_right)\n",
    "\n",
    "    weighted_metric = (\n",
    "        len(y_left) / len(y) * left_metric\n",
    "        + len(y_right) / len(y) * right_metric\n",
    "    )\n",
    "    return parent_metric - weighted_metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcc2d61",
   "metadata": {},
   "source": [
    "## 5. Find the best split\n",
    "This function identifies the best feature and threshold to split the data using the specified metric (Gini or Entropy).\n",
    "Steps:\n",
    "\n",
    "1. Loop through all features.\n",
    "\n",
    "2. For each feature, iterate over all unique thresholds.\n",
    "\n",
    "3. Split the data into left and right subsets based on the threshold.\n",
    "\n",
    "4. Compute the Gini/Entropy for both subsets and calculate the weighted average.\n",
    "\n",
    "5. Keep track of the split with the lowest metric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "59caece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, metric=\"gini\", feature_names=None):\n",
    "    best_info_gain = float(\"-inf\")\n",
    "    best_split = None\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    for feature in range(n_features):\n",
    "        thresholds = np.unique(X[:, feature])\n",
    "        for threshold in thresholds:\n",
    "            left_mask = X[:, feature] <= threshold\n",
    "            right_mask = X[:, feature] > threshold\n",
    "\n",
    "            if sum(left_mask) == 0 or sum(right_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            info_gain = information_gain(y, y[left_mask], y[right_mask], metric)\n",
    "\n",
    "            if info_gain > best_info_gain:\n",
    "                best_info_gain = info_gain\n",
    "                best_split = {\n",
    "                    \"feature_index\": feature,\n",
    "                    \"feature_name\": feature_names[feature] if feature_names is not None else feature,\n",
    "                    \"threshold\": threshold,\n",
    "                }\n",
    "\n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0163ec30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Split: {'feature_index': 20, 'feature_name': np.str_('worst radius'), 'threshold': np.float64(16.77)}\n"
     ]
    }
   ],
   "source": [
    "split = best_split(X, y, metric=\"gini\", feature_names=feature_names)\n",
    "print(\"Best Split:\", split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a73cf2",
   "metadata": {},
   "source": [
    "## 6. Build Tree\n",
    "This function recursively builds the decision tree.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Stop the recursion if all labels are identical or the maximum depth is reached.\n",
    "\n",
    "2. Find the best split using best_split.\n",
    "\n",
    "3. Split the data into left and right subsets.\n",
    "\n",
    "4. Recursively build the left and right subtrees.\n",
    "\n",
    "5. Return the tree structure as a nested dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0dcfceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X, y, max_depth=None, depth=0, metric=\"gini\", feature_names=None):\n",
    "    if len(set(y)) == 1 or (max_depth is not None and depth == max_depth):\n",
    "        return {\"type\": \"leaf\", \"value\": np.argmax(np.bincount(y))}\n",
    "\n",
    "    split = best_split(X, y, metric, feature_names)\n",
    "    if not split:\n",
    "        return {\"type\": \"leaf\", \"value\": np.argmax(np.bincount(y))}\n",
    "\n",
    "    # Use feature_index for calculations\n",
    "    left_mask = X[:, split[\"feature_index\"]] <= split[\"threshold\"]\n",
    "    right_mask = X[:, split[\"feature_index\"]] > split[\"threshold\"]\n",
    "\n",
    "    left_tree = build_tree(X[left_mask], y[left_mask], max_depth, depth + 1, metric, feature_names)\n",
    "    right_tree = build_tree(X[right_mask], y[right_mask], max_depth, depth + 1, metric, feature_names)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"node\",\n",
    "        \"feature\": split[\"feature_name\"],\n",
    "        \"threshold\": split[\"threshold\"],\n",
    "        \"left\": left_tree,\n",
    "        \"right\": right_tree,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d23418a",
   "metadata": {},
   "source": [
    "## 7. Traverse the Tree For Prediction\n",
    "This function traverses the tree to make predictions for a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7c11d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_tree(x, tree, feature_names=None):\n",
    "    \"\"\"\n",
    "    Traverse the decision tree to make a prediction for a single sample.\n",
    "    Args:\n",
    "    - x: Single sample (1D array).\n",
    "    - tree: Decision tree structure.\n",
    "    - feature_names: List of feature names (optional, needed for name-to-index mapping).\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted label (int).\n",
    "    \"\"\"\n",
    "    if tree[\"type\"] == \"leaf\":\n",
    "        return tree[\"value\"]\n",
    "\n",
    "    # Resolve feature index if feature_names is provided\n",
    "    feature_index = feature_names.index(tree[\"feature\"]) if feature_names is not None else tree[\"feature\"]\n",
    "\n",
    "    if x[feature_index] <= tree[\"threshold\"]:\n",
    "        return traverse_tree(x, tree[\"left\"], feature_names)\n",
    "    else:\n",
    "        return traverse_tree(x, tree[\"right\"], feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6b89f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb2cef",
   "metadata": {},
   "source": [
    "## 8. Prediction\n",
    "This function predicts labels for all samples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "2cbdf5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, tree, feature_names=None):\n",
    "    \"\"\"\n",
    "    Predict the label(s) for the given data.\n",
    "    Args:\n",
    "    - X: Input features (2D array or 1D array for single sample).\n",
    "    - tree: Decision tree structure.\n",
    "    - feature_names: List of feature names (optional).\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted labels (1D array or single label).\n",
    "    \"\"\"\n",
    "    if len(X.shape) == 1:  # If a single sample is provided\n",
    "        return traverse_tree(X, tree, feature_names)\n",
    "    return np.array([traverse_tree(x, tree, feature_names) for x in X])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e3c1e5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature': 'worst radius',\n",
      " 'left': {'feature': 'worst concave points',\n",
      "          'left': {'feature': 'radius error',\n",
      "                   'left': {'type': 'leaf', 'value': np.int64(1)},\n",
      "                   'right': {'type': 'leaf', 'value': np.int64(0)},\n",
      "                   'threshold': np.float64(0.8811),\n",
      "                   'type': 'node'},\n",
      "          'right': {'feature': 'worst texture',\n",
      "                    'left': {'type': 'leaf', 'value': np.int64(1)},\n",
      "                    'right': {'type': 'leaf', 'value': np.int64(0)},\n",
      "                    'threshold': np.float64(25.5),\n",
      "                    'type': 'node'},\n",
      "          'threshold': np.float64(0.1357),\n",
      "          'type': 'node'},\n",
      " 'right': {'feature': 'mean texture',\n",
      "           'left': {'feature': 'mean concave points',\n",
      "                    'left': {'type': 'leaf', 'value': np.int64(1)},\n",
      "                    'right': {'type': 'leaf', 'value': np.int64(0)},\n",
      "                    'threshold': np.float64(0.06211),\n",
      "                    'type': 'node'},\n",
      "           'right': {'feature': 'worst smoothness',\n",
      "                     'left': {'type': 'leaf', 'value': np.int64(1)},\n",
      "                     'right': {'type': 'leaf', 'value': np.int64(0)},\n",
      "                     'threshold': np.float64(0.08774),\n",
      "                     'type': 'node'},\n",
      "           'threshold': np.float64(16.07),\n",
      "           'type': 'node'},\n",
      " 'threshold': np.float64(16.77),\n",
      " 'type': 'node'}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# data = datasets.load_iris()\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "feature_names = data.feature_names.tolist()\n",
    "\n",
    "# Build the tree using Gini impurity\n",
    "tree_gini = build_tree(X, y, max_depth=3, metric=\"gini\", feature_names=feature_names)\n",
    "\n",
    "# Display the tree\n",
    "import pprint\n",
    "pprint.pprint(tree_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182341be",
   "metadata": {},
   "source": [
    "## 9. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c0dd028a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9647058823529412\n",
      "Predicted label for single sample: 1\n",
      "Actual label for single sample: 1\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Build the tree on training data\n",
    "tree_gini = build_tree(X_train, y_train, max_depth=3, metric=\"gini\", feature_names=feature_names)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = predict(X_test, tree_gini, feature_names=feature_names)\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Predict a single sample\n",
    "single_sample = X_test[0]\n",
    "single_prediction = predict(single_sample, tree_gini, feature_names=feature_names)\n",
    "print(\"Predicted label for single sample:\", single_prediction)\n",
    "print(\"Actual label for single sample:\", y_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd49d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
