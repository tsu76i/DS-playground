{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f5a705",
   "metadata": {},
   "source": [
    "# Random Forest Regressor from Scratch\n",
    "***\n",
    "## Table of Contents\n",
    "1. [Introduction](#1-introduction)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac53a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e555617",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "This notebook is an extension of [Decision Tree Regressor from Scratch](https://github.com/tsu76i/DS-playground/blob/main/2.%20Building%20ML%20Models%20From%20Scratch/2.3%20CART/decision_tree_regressor.ipynb).\n",
    "\n",
    "Random forests are an ensemble learning technique that combines multiple decision trees, each trained on a random subset of the data (with replacement) and a random subset of features at each split. The final prediction is made by aggregating the results of all trees(**majority vote** for classification, **average** for regression). Compared to decision trees, this approach provides better accuracy, reduced overfitting and more stable predictions, though at the cost of increased computational complexity and reduced interpretability. This method introduces two key randomisation techniques during the training process:\n",
    "\n",
    "1. **Bootstrap Sampling**: Each tree is trained on a bootstrapped dataset, which is a random sample of the original dataset created *with replacement*. This ensures diversity among the trees.\n",
    "2. **Feature Randomisation**: At each split in a tree, a random subset of features is considered rather than evaluating all features. This prevents dominant features from appearing in every tree and further promotes diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f53cde",
   "metadata": {},
   "source": [
    "## 2. Loading Data\n",
    "Retrieved from [GitHub - YBI Foundation](https://github.com/YBI-Foundation/Dataset/blob/main/Admission%20Chance.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "094c43aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Serial No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GRE Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TOEFL Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "University Rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": " SOP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LOR ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CGPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Chance of Admit ",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9d1caab5-7e78-4fb7-9e1e-dc3e2d0d2d7d",
       "rows": [
        [
         "0",
         "1",
         "337",
         "118",
         "4",
         "4.5",
         "4.5",
         "9.65",
         "1",
         "0.92"
        ],
        [
         "1",
         "2",
         "324",
         "107",
         "4",
         "4.0",
         "4.5",
         "8.87",
         "1",
         "0.76"
        ],
        [
         "2",
         "3",
         "316",
         "104",
         "3",
         "3.0",
         "3.5",
         "8.0",
         "1",
         "0.72"
        ],
        [
         "3",
         "4",
         "322",
         "110",
         "3",
         "3.5",
         "2.5",
         "8.67",
         "1",
         "0.8"
        ],
        [
         "4",
         "5",
         "314",
         "103",
         "2",
         "2.0",
         "3.0",
         "8.21",
         "0",
         "0.65"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No  GRE Score  TOEFL Score  University Rating   SOP  LOR   CGPA  \\\n",
       "0          1        337          118                  4   4.5   4.5  9.65   \n",
       "1          2        324          107                  4   4.0   4.5  8.87   \n",
       "2          3        316          104                  3   3.0   3.5  8.00   \n",
       "3          4        322          110                  3   3.5   2.5  8.67   \n",
       "4          5        314          103                  2   2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/YBI-Foundation/Dataset/refs/heads/main/Admission%20Chance.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e86b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (400, 8)\n",
      "Target shape: (400,)\n",
      "Features: \n",
      "['Serial No', 'GRE Score', 'TOEFL Score', 'University Rating', ' SOP', 'LOR ', 'CGPA', 'Research']\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "feature_names = df.columns[:-1].tolist()  # All columns except the last one\n",
    "\n",
    "# Check the shape of the data\n",
    "print(f'Features shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')\n",
    "print(f'Features: \\n{feature_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d3128",
   "metadata": {},
   "source": [
    "## 3. Train Test Split\n",
    "Train test split is a fundamental model validation technique in machine learning. It divides a dataset into two separate portions: a **training set** used to train a model, and a **testing set** used to evaluate how well the model can perform on unseen data. \n",
    "\n",
    "The typical split ratio is 80% for training and 20% for testing, though this can vary (70/30 or 90/10 are also common). The key principle is that the test set must remain completely separated during model training process, and should never be used to make decisions about the model or tune parameters. \n",
    "\n",
    "The split is usually done randomly to ensure both sets are representative of the overall dataset, and many libraries (such as scikit-learn) provide build-in functions that handle this process automatically while maintaining proper randomisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f086f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X: pd.DataFrame, y: pd.Series, test_size: float = 0.2,\n",
    "                     random_state: int = None) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Split arrays or matrices into random train and test subsets.\n",
    "\n",
    "    Args:\n",
    "        X: Input features, a 2D array with rows (samples) and columns (features).\n",
    "        y: Target values/labels, a 1D array with rows (samples).\n",
    "        test_size: Proportion of the dataset to include in the test split. Must be between 0.0 and 1.0. default = 0.2\n",
    "        random_state: Seed for the random number generator to ensure reproducible results. default = None\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - X_train: Training set features.\n",
    "            - X_test: Testing set features.\n",
    "            - y_train: Training set target values.\n",
    "            - y_test: Testing set target values.\n",
    "    \"\"\"\n",
    "    # Set a random seed if it exists\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Create a list of numbers from 0 to len(X)\n",
    "    indices = np.arange(len(X))\n",
    "\n",
    "    # Shuffle the indices\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Define the size of our test data from len(X)\n",
    "    test_size = int(test_size * len(X))\n",
    "\n",
    "    # Generate indices for test and train data\n",
    "    test_indices: NDArray[np.int64] = indices[:test_size]\n",
    "    train_indices: NDArray[np.int64] = indices[test_size:]\n",
    "\n",
    "    # Return: X_train, X_test, y_train, y_test\n",
    "    return X.iloc[train_indices], X.iloc[test_indices], y.iloc[train_indices], y.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50bd02",
   "metadata": {},
   "source": [
    "## 4. Loss Functions for Regression\n",
    "### Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31955702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(y: pd.Series) -> float:\n",
    "    return np.var(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765129d5",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE) For LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d13cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y: pd.Series) -> float:\n",
    "    mean = np.mean(y)\n",
    "    return np.mean((y - mean) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b18b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance: 0.02029\n",
      "MSE: 0.02029\n"
     ]
    }
   ],
   "source": [
    "print(f\"Variance: {variance(y):.5f}\")\n",
    "print(f\"MSE: {mse(y):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca55ad1",
   "metadata": {},
   "source": [
    "## 5. Information Gain\n",
    "Information Gain is a metric used to measure the effectiveness of a feature in splitting a dataset into subsets that are more pure concerning the target variable. It quantifies the reduction in variance or MSE, and a higher information gain indicates a better feature for making splits.\n",
    "\n",
    "\\begin{align*}\n",
    "IG(S, A) = H(S) - \\sum_{i=1}^{n} \\dfrac{|S_i|}{|S|}H(S_{i})\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $H(S)$: Variance (or MSE) of the original dataset $S$.\n",
    "- $S_{i}$: Subset of $S$ created by splitting on feature $A$ for the $i_{th}$ value or range of the feature.\n",
    "- $\\dfrac{|S_i|}{|S|}$: Proportion of samples in subset $S_{i}$.\n",
    "- $H(S_{i})$: Variance (or MSE) of subset $S_{i}$.\n",
    "\n",
    "\n",
    "\n",
    "The following `information_gain` function calculates the difference between the metric for the parent node and the weighted average of the metrics for the child nodes (left and right splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "017fbecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(y: pd.Series, y_left: pd.Series, y_right: pd.Series,\n",
    "                     metric: str = 'variance') -> float:\n",
    "    \"\"\"\n",
    "    Calculate the information gain for regression.\n",
    "\n",
    "    Args:\n",
    "        y: Target variables of the parent node.\n",
    "        y_left: Target variables of the left child node after the split.\n",
    "        y_right: Target variables of the right child node after the split.\n",
    "        metric: Splitting criterion, either 'variance' or 'mse'. Defaults to 'variance'.\n",
    "\n",
    "    Returns:\n",
    "        Information gain resulting from the split.\n",
    "    \"\"\"\n",
    "    if metric == 'variance':\n",
    "        parent_metric = variance(y)\n",
    "        left_metric = variance(y_left)\n",
    "        right_metric = variance(y_right)\n",
    "    else:  # metric == \"mse\"\n",
    "        parent_metric = mse(y)\n",
    "        left_metric = mse(y_left)\n",
    "        right_metric = mse(y_right)\n",
    "\n",
    "    weighted_metric = (\n",
    "        len(y_left) / len(y) * left_metric\n",
    "        + len(y_right) / len(y) * right_metric\n",
    "    )\n",
    "    return parent_metric - weighted_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cc087",
   "metadata": {},
   "source": [
    "## 6. Bootstrapping\n",
    "Bootstrapping is a statistical resampling method that involves sampling data points with replacement. In creating a new dataset (**bootstrap sample**) from the original dataset, some data points may appear multiple times, while others may be excluded. Though individual data points may repeat, the size of bootstrap sample $n$ is typically the same as the original dataset. This method ensures variability among datasets, which helps reduce overfitting when used in ensemble learning.\n",
    "\n",
    "For a dataset with $n$ examples, each sample has a $1 - \\left( 1 - \\dfrac{1}{n} \\right)^{n}$ chance of being selected at least once in the bootstrap sample. As $n$ becomes large, this value approaches $1-\\text{e}^{-1} \\approx 0.632$. Hence, about 63.2% of the original dataset is expected to appear in any given bootstrap sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(X: pd.DataFrame, y: pd.Series, n_samples: Optional[int] = None,\n",
    "                     random_state: Optional[int] = None) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Generate a bootstrap sample from the dataset.\n",
    "\n",
    "    Args:\n",
    "        X: Input features.\n",
    "        y: Target labels.\n",
    "        n_samples: Samples to draw (default: dataset size).\n",
    "        random_state: Random seed.\n",
    "\n",
    "    Returns:\n",
    "        Bootstrapped (X, y) tuple.\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    if n_samples is None:\n",
    "        n_samples = len(X)\n",
    "    indices = np.random.randint(0, len(X), size=n_samples)\n",
    "    return X.iloc[indices], y.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f9e89da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Serial No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GRE Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TOEFL Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "University Rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": " SOP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LOR ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CGPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "28ad1ef4-d99e-4f3c-861c-d9363ff87528",
       "rows": [
        [
         "102",
         "103",
         "314",
         "106",
         "2",
         "4.0",
         "3.5",
         "8.25",
         "0"
        ],
        [
         "348",
         "349",
         "302",
         "99",
         "1",
         "2.0",
         "2.0",
         "7.25",
         "0"
        ],
        [
         "270",
         "271",
         "306",
         "105",
         "2",
         "2.5",
         "3.0",
         "8.22",
         "1"
        ],
        [
         "106",
         "107",
         "329",
         "111",
         "4",
         "4.5",
         "4.5",
         "9.18",
         "1"
        ],
        [
         "71",
         "72",
         "336",
         "112",
         "5",
         "5.0",
         "5.0",
         "9.76",
         "1"
        ],
        [
         "188",
         "189",
         "331",
         "115",
         "5",
         "4.5",
         "3.5",
         "9.36",
         "1"
        ],
        [
         "20",
         "21",
         "312",
         "107",
         "3",
         "3.0",
         "2.0",
         "7.9",
         "1"
        ],
        [
         "102",
         "103",
         "314",
         "106",
         "2",
         "4.0",
         "3.5",
         "8.25",
         "0"
        ],
        [
         "121",
         "122",
         "334",
         "119",
         "5",
         "4.5",
         "4.5",
         "9.48",
         "1"
        ],
        [
         "214",
         "215",
         "331",
         "117",
         "4",
         "4.5",
         "5.0",
         "9.42",
         "1"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>349</td>\n",
       "      <td>302</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>271</td>\n",
       "      <td>306</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>329</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>336</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>189</td>\n",
       "      <td>331</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>312</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>122</td>\n",
       "      <td>334</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215</td>\n",
       "      <td>331</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No  GRE Score  TOEFL Score  University Rating   SOP  LOR   CGPA  \\\n",
       "102        103        314          106                  2   4.0   3.5  8.25   \n",
       "348        349        302           99                  1   2.0   2.0  7.25   \n",
       "270        271        306          105                  2   2.5   3.0  8.22   \n",
       "106        107        329          111                  4   4.5   4.5  9.18   \n",
       "71          72        336          112                  5   5.0   5.0  9.76   \n",
       "188        189        331          115                  5   4.5   3.5  9.36   \n",
       "20          21        312          107                  3   3.0   2.0  7.90   \n",
       "102        103        314          106                  2   4.0   3.5  8.25   \n",
       "121        122        334          119                  5   4.5   4.5  9.48   \n",
       "214        215        331          117                  4   4.5   5.0  9.42   \n",
       "\n",
       "     Research  \n",
       "102         0  \n",
       "348         0  \n",
       "270         1  \n",
       "106         1  \n",
       "71          1  \n",
       "188         1  \n",
       "20          1  \n",
       "102         0  \n",
       "121         1  \n",
       "214         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_sample(X, y, random_state=42)[0][:10]  # X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06274253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Chance of Admit ",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "603efc76-8883-469f-a750-9050d61d4406",
       "rows": [
        [
         "102",
         "0.62"
        ],
        [
         "348",
         "0.57"
        ],
        [
         "270",
         "0.72"
        ],
        [
         "106",
         "0.87"
        ],
        [
         "71",
         "0.96"
        ],
        [
         "188",
         "0.93"
        ],
        [
         "20",
         "0.64"
        ],
        [
         "102",
         "0.62"
        ],
        [
         "121",
         "0.94"
        ],
        [
         "214",
         "0.94"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "102    0.62\n",
       "348    0.57\n",
       "270    0.72\n",
       "106    0.87\n",
       "71     0.96\n",
       "188    0.93\n",
       "20     0.64\n",
       "102    0.62\n",
       "121    0.94\n",
       "214    0.94\n",
       "Name: Chance of Admit , dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_sample(X, y, random_state=42)[1][:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
