{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f5a705",
   "metadata": {},
   "source": [
    "# Random Forest Regressor from Scratch\n",
    "***\n",
    "## Table of Contents\n",
    "1. [Introduction](#1-introduction)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac53a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Dict, Optional, Any\n",
    "from numpy.typing import NDArray\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e555617",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "This notebook is an extension of [Decision Tree Regressor from Scratch](https://github.com/tsu76i/DS-playground/blob/main/2.%20Building%20ML%20Models%20From%20Scratch/2.3%20CART/decision_tree_regressor.ipynb).\n",
    "\n",
    "Random forests are an ensemble learning technique that combines multiple decision trees, each trained on a random subset of the data (with replacement) and a random subset of features at each split. The final prediction is made by aggregating the results of all trees(**majority vote** for classification, **average** for regression). Compared to decision trees, this approach provides better accuracy, reduced overfitting and more stable predictions, though at the cost of increased computational complexity and reduced interpretability. This method introduces two key randomisation techniques during the training process:\n",
    "\n",
    "1. **Bootstrap Sampling**: Each tree is trained on a bootstrapped dataset, which is a random sample of the original dataset created *with replacement*. This ensures diversity among the trees.\n",
    "2. **Feature Randomisation**: At each split in a tree, a random subset of features is considered rather than evaluating all features. This prevents dominant features from appearing in every tree and further promotes diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f53cde",
   "metadata": {},
   "source": [
    "## 2. Loading Data\n",
    "Retrieved from [GitHub - YBI Foundation](https://github.com/YBI-Foundation/Dataset/blob/main/Admission%20Chance.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "094c43aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Serial No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GRE Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TOEFL Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "University Rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": " SOP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LOR ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CGPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Chance of Admit ",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "523d6009-7e0b-46d4-a1d7-8ba3fe1c5435",
       "rows": [
        [
         "0",
         "1",
         "337",
         "118",
         "4",
         "4.5",
         "4.5",
         "9.65",
         "1",
         "0.92"
        ],
        [
         "1",
         "2",
         "324",
         "107",
         "4",
         "4.0",
         "4.5",
         "8.87",
         "1",
         "0.76"
        ],
        [
         "2",
         "3",
         "316",
         "104",
         "3",
         "3.0",
         "3.5",
         "8.0",
         "1",
         "0.72"
        ],
        [
         "3",
         "4",
         "322",
         "110",
         "3",
         "3.5",
         "2.5",
         "8.67",
         "1",
         "0.8"
        ],
        [
         "4",
         "5",
         "314",
         "103",
         "2",
         "2.0",
         "3.0",
         "8.21",
         "0",
         "0.65"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No  GRE Score  TOEFL Score  University Rating   SOP  LOR   CGPA  \\\n",
       "0          1        337          118                  4   4.5   4.5  9.65   \n",
       "1          2        324          107                  4   4.0   4.5  8.87   \n",
       "2          3        316          104                  3   3.0   3.5  8.00   \n",
       "3          4        322          110                  3   3.5   2.5  8.67   \n",
       "4          5        314          103                  2   2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/YBI-Foundation/Dataset/refs/heads/main/Admission%20Chance.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e86b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (400, 8)\n",
      "Target shape: (400,)\n",
      "Features: \n",
      "['Serial No', 'GRE Score', 'TOEFL Score', 'University Rating', ' SOP', 'LOR ', 'CGPA', 'Research']\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "feature_names = df.columns[:-1].tolist()  # All columns except the last one\n",
    "\n",
    "# Check the shape of the data\n",
    "print(f'Features shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')\n",
    "print(f'Features: \\n{feature_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d3128",
   "metadata": {},
   "source": [
    "## 3. Train Test Split\n",
    "Train test split is a fundamental model validation technique in machine learning. It divides a dataset into two separate portions: a **training set** used to train a model, and a **testing set** used to evaluate how well the model can perform on unseen data. \n",
    "\n",
    "The typical split ratio is 80% for training and 20% for testing, though this can vary (70/30 or 90/10 are also common). The key principle is that the test set must remain completely separated during model training process, and should never be used to make decisions about the model or tune parameters. \n",
    "\n",
    "The split is usually done randomly to ensure both sets are representative of the overall dataset, and many libraries (such as scikit-learn) provide build-in functions that handle this process automatically while maintaining proper randomisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f086f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X: pd.DataFrame, y: pd.Series, test_size: float = 0.2,\n",
    "                     random_state: int = None) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Split arrays or matrices into random train and test subsets.\n",
    "\n",
    "    Args:\n",
    "        X: Input features, a 2D array with rows (samples) and columns (features).\n",
    "        y: Target values/labels, a 1D array with rows (samples).\n",
    "        test_size: Proportion of the dataset to include in the test split. Must be between 0.0 and 1.0. default = 0.2\n",
    "        random_state: Seed for the random number generator to ensure reproducible results. default = None\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - X_train: Training set features.\n",
    "            - X_test: Testing set features.\n",
    "            - y_train: Training set target values.\n",
    "            - y_test: Testing set target values.\n",
    "    \"\"\"\n",
    "    # Set a random seed if it exists\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Create a list of numbers from 0 to len(X)\n",
    "    indices = np.arange(len(X))\n",
    "\n",
    "    # Shuffle the indices\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Define the size of our test data from len(X)\n",
    "    test_size = int(test_size * len(X))\n",
    "\n",
    "    # Generate indices for test and train data\n",
    "    test_indices: NDArray[np.int64] = indices[:test_size]\n",
    "    train_indices: NDArray[np.int64] = indices[test_size:]\n",
    "\n",
    "    # Return: X_train, X_test, y_train, y_test\n",
    "    return X.iloc[train_indices], X.iloc[test_indices], y.iloc[train_indices], y.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50bd02",
   "metadata": {},
   "source": [
    "## 4. Loss Functions for Regression\n",
    "### Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31955702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(y: pd.Series) -> float:\n",
    "    return np.var(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765129d5",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE) For LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d13cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y: pd.Series) -> float:\n",
    "    mean = np.mean(y)\n",
    "    return np.mean((y - mean) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b18b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance: 0.02029\n",
      "MSE: 0.02029\n"
     ]
    }
   ],
   "source": [
    "print(f\"Variance: {variance(y):.5f}\")\n",
    "print(f\"MSE: {mse(y):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca55ad1",
   "metadata": {},
   "source": [
    "## 5. Information Gain\n",
    "Information Gain is a metric used to measure the effectiveness of a feature in splitting a dataset into subsets that are more pure concerning the target variable. It quantifies the reduction in variance or MSE, and a higher information gain indicates a better feature for making splits.\n",
    "\n",
    "\\begin{align*}\n",
    "IG(S, A) = H(S) - \\sum_{i=1}^{n} \\dfrac{|S_i|}{|S|}H(S_{i})\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $H(S)$: Variance (or MSE) of the original dataset $S$.\n",
    "- $S_{i}$: Subset of $S$ created by splitting on feature $A$ for the $i_{th}$ value or range of the feature.\n",
    "- $\\dfrac{|S_i|}{|S|}$: Proportion of samples in subset $S_{i}$.\n",
    "- $H(S_{i})$: Variance (or MSE) of subset $S_{i}$.\n",
    "\n",
    "\n",
    "\n",
    "The following `information_gain` function calculates the difference between the metric for the parent node and the weighted average of the metrics for the child nodes (left and right splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "017fbecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(y: pd.Series, y_left: pd.Series, y_right: pd.Series,\n",
    "                     metric: str = 'variance') -> float:\n",
    "    \"\"\"\n",
    "    Calculate the information gain for regression.\n",
    "\n",
    "    Args:\n",
    "        y: Target variables of the parent node.\n",
    "        y_left: Target variables of the left child node after the split.\n",
    "        y_right: Target variables of the right child node after the split.\n",
    "        metric: Splitting criterion, either 'variance' or 'mse'. Defaults to 'variance'.\n",
    "\n",
    "    Returns:\n",
    "        Information gain resulting from the split.\n",
    "    \"\"\"\n",
    "    if metric == 'variance':\n",
    "        parent_metric = variance(y)\n",
    "        left_metric = variance(y_left)\n",
    "        right_metric = variance(y_right)\n",
    "    else:  # metric == \"mse\"\n",
    "        parent_metric = mse(y)\n",
    "        left_metric = mse(y_left)\n",
    "        right_metric = mse(y_right)\n",
    "\n",
    "    weighted_metric = (\n",
    "        len(y_left) / len(y) * left_metric\n",
    "        + len(y_right) / len(y) * right_metric\n",
    "    )\n",
    "    return parent_metric - weighted_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cc087",
   "metadata": {},
   "source": [
    "## 6. Bootstrapping\n",
    "Bootstrapping is a statistical resampling method that involves sampling data points with replacement. In creating a new dataset (**bootstrap sample**) from the original dataset, some data points may appear multiple times, while others may be excluded. Though individual data points may repeat, the size of bootstrap sample $n$ is typically the same as the original dataset. This method ensures variability among datasets, which helps reduce overfitting when used in ensemble learning.\n",
    "\n",
    "For a dataset with $n$ examples, each sample has a $1 - \\left( 1 - \\dfrac{1}{n} \\right)^{n}$ chance of being selected at least once in the bootstrap sample. As $n$ becomes large, this value approaches $1-\\text{e}^{-1} \\approx 0.632$. Hence, about 63.2% of the original dataset is expected to appear in any given bootstrap sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8e6b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(X: pd.DataFrame, y: pd.Series, n_samples: Optional[int] = None,\n",
    "                     random_state: Optional[int] = None) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Generate a bootstrap sample from the dataset.\n",
    "\n",
    "    Args:\n",
    "        X: Input features.\n",
    "        y: Target labels.\n",
    "        n_samples: Samples to draw (default: dataset size).\n",
    "        random_state: Random seed.\n",
    "\n",
    "    Returns:\n",
    "        Bootstrapped (X, y) tuple.\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    if n_samples is None:\n",
    "        n_samples = len(X)\n",
    "    indices = np.random.randint(0, len(X), size=n_samples)\n",
    "    return X.iloc[indices], y.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f9e89da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Serial No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GRE Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TOEFL Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "University Rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": " SOP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LOR ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CGPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "021e95f6-7983-4aab-aa09-b73507879457",
       "rows": [
        [
         "102",
         "103",
         "314",
         "106",
         "2",
         "4.0",
         "3.5",
         "8.25",
         "0"
        ],
        [
         "348",
         "349",
         "302",
         "99",
         "1",
         "2.0",
         "2.0",
         "7.25",
         "0"
        ],
        [
         "270",
         "271",
         "306",
         "105",
         "2",
         "2.5",
         "3.0",
         "8.22",
         "1"
        ],
        [
         "106",
         "107",
         "329",
         "111",
         "4",
         "4.5",
         "4.5",
         "9.18",
         "1"
        ],
        [
         "71",
         "72",
         "336",
         "112",
         "5",
         "5.0",
         "5.0",
         "9.76",
         "1"
        ],
        [
         "188",
         "189",
         "331",
         "115",
         "5",
         "4.5",
         "3.5",
         "9.36",
         "1"
        ],
        [
         "20",
         "21",
         "312",
         "107",
         "3",
         "3.0",
         "2.0",
         "7.9",
         "1"
        ],
        [
         "102",
         "103",
         "314",
         "106",
         "2",
         "4.0",
         "3.5",
         "8.25",
         "0"
        ],
        [
         "121",
         "122",
         "334",
         "119",
         "5",
         "4.5",
         "4.5",
         "9.48",
         "1"
        ],
        [
         "214",
         "215",
         "331",
         "117",
         "4",
         "4.5",
         "5.0",
         "9.42",
         "1"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>349</td>\n",
       "      <td>302</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>271</td>\n",
       "      <td>306</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>329</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>336</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>189</td>\n",
       "      <td>331</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>312</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>122</td>\n",
       "      <td>334</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215</td>\n",
       "      <td>331</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No  GRE Score  TOEFL Score  University Rating   SOP  LOR   CGPA  \\\n",
       "102        103        314          106                  2   4.0   3.5  8.25   \n",
       "348        349        302           99                  1   2.0   2.0  7.25   \n",
       "270        271        306          105                  2   2.5   3.0  8.22   \n",
       "106        107        329          111                  4   4.5   4.5  9.18   \n",
       "71          72        336          112                  5   5.0   5.0  9.76   \n",
       "188        189        331          115                  5   4.5   3.5  9.36   \n",
       "20          21        312          107                  3   3.0   2.0  7.90   \n",
       "102        103        314          106                  2   4.0   3.5  8.25   \n",
       "121        122        334          119                  5   4.5   4.5  9.48   \n",
       "214        215        331          117                  4   4.5   5.0  9.42   \n",
       "\n",
       "     Research  \n",
       "102         0  \n",
       "348         0  \n",
       "270         1  \n",
       "106         1  \n",
       "71          1  \n",
       "188         1  \n",
       "20          1  \n",
       "102         0  \n",
       "121         1  \n",
       "214         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_sample(X, y, random_state=42)[0][:10]  # X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06274253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Chance of Admit ",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "cc2ea972-387d-404d-8c3c-9b00791db5db",
       "rows": [
        [
         "102",
         "0.62"
        ],
        [
         "348",
         "0.57"
        ],
        [
         "270",
         "0.72"
        ],
        [
         "106",
         "0.87"
        ],
        [
         "71",
         "0.96"
        ],
        [
         "188",
         "0.93"
        ],
        [
         "20",
         "0.64"
        ],
        [
         "102",
         "0.62"
        ],
        [
         "121",
         "0.94"
        ],
        [
         "214",
         "0.94"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "102    0.62\n",
       "348    0.57\n",
       "270    0.72\n",
       "106    0.87\n",
       "71     0.96\n",
       "188    0.93\n",
       "20     0.64\n",
       "102    0.62\n",
       "121    0.94\n",
       "214    0.94\n",
       "Name: Chance of Admit , dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_sample(X, y, random_state=42)[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87d4f0",
   "metadata": {},
   "source": [
    "## 7. Identifying the Best Split\n",
    "This function identifies the best feature and threshold to split the data using the specified metric (Variance or MSE).\n",
    "\n",
    "Steps are:\n",
    "\n",
    "1. Select some features randomly (Recommended: `sqrt` for classification, `log2` for regression).\n",
    "\n",
    "2. For each selected feature, iterate over all unique thresholds.\n",
    "\n",
    "3. Split the data into left and right subsets based on the threshold (skip invalid ones).\n",
    "\n",
    "4. Compute the variance/MSE for both subsets and calculate Information Gain.\n",
    "\n",
    "5. If the newly computed `info_gain` > `best_info_gain`, then update `best_info_gain` with the new information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab809c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X: pd.DataFrame, y: pd.Series, metric: str = 'variance', feature_names=None, max_features=None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Find the best split for a dataset for regression.\n",
    "\n",
    "    Args:\n",
    "        X: Input features.\n",
    "        y: Target variables.\n",
    "        metric: Splitting criterion, either 'variance' or 'mse'. Defaults to 'variance'.\n",
    "        feature_names: List of feature names. If None, indices are used. Defaults to None.\n",
    "        max_features: Number of features to consider at each split. None(log2(total_n_features)) or int(<=total_n_features). Defaults to None.\n",
    "    Returns:\n",
    "        Dictionary containing the best split with keys:\n",
    "            - 'feature_index': Index of the feature used for the split.\n",
    "            - 'feature_name': Name or index of the feature.\n",
    "            - 'threshold' : Threshold value for the split.\n",
    "    \"\"\"\n",
    "    if feature_names is None and hasattr(X, 'columns'):\n",
    "        feature_names = X.columns.tolist()\n",
    "\n",
    "    # Convert X if DataFrame\n",
    "    if hasattr(X, 'to_numpy'):\n",
    "        X = X.to_numpy()\n",
    "\n",
    "    best_info_gain = float('-inf')\n",
    "    best_split = None\n",
    "    total_n_features = X.shape[1]\n",
    "\n",
    "    if isinstance(max_features, int):  # if max_features is int\n",
    "        selected_n_features = max_features if max_features <= total_n_features else total_n_features\n",
    "    else:  # Default = log2(total_n_features)\n",
    "        selected_n_features = int(np.log2(total_n_features))\n",
    "\n",
    "    selected_features_idx = np.random.choice(\n",
    "        a=total_n_features, size=selected_n_features, replace=False)\n",
    "\n",
    "    # Iterate over randomly selected features.\n",
    "    for feature in selected_features_idx:\n",
    "        # Iterate over all unique thresholds for each random feature.\n",
    "        thresholds = np.unique(X[:, feature])\n",
    "        for threshold in thresholds:\n",
    "            # Split the data into left and right subsets based on the threshold.\n",
    "            left_mask = X[:, feature] <= threshold\n",
    "            right_mask = X[:, feature] > threshold\n",
    "\n",
    "            # Skip invalid splits.\n",
    "            if sum(left_mask) == 0 or sum(right_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            # Compute IG.\n",
    "            info_gain = information_gain(\n",
    "                y, y[left_mask], y[right_mask], metric)\n",
    "\n",
    "            # Update `best_info_gain` if `info_gain` > `best_info_gain`.\n",
    "            if info_gain > best_info_gain:\n",
    "                best_info_gain = info_gain\n",
    "                best_split = {\n",
    "                    'feature_index': int(feature),\n",
    "                    'feature_name': feature_names[feature] if feature_names is not None else feature,\n",
    "                    'threshold': float(threshold),\n",
    "                }\n",
    "\n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74527315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Split: {'feature_index': 3, 'feature_name': 'University Rating', 'threshold': 3.0}\n"
     ]
    }
   ],
   "source": [
    "split = best_split(X, y, metric='variance', feature_names=feature_names)\n",
    "print('Best Split:', split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2532957",
   "metadata": {},
   "source": [
    "## 8. Building the Decision Tree\n",
    "This function resursively creates the tree structure as a nested dictionary with conditions (`feature` and `threshold`) and leaf nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90ac3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X: pd.DataFrame, y: pd.Series, max_depth: int = None,\n",
    "               depth: int = 0, metric: str = 'variance', feature_names: List[str | int] = None, max_features=None) -> Dict[\n",
    "        str, Any]:\n",
    "    \"\"\"\n",
    "    Build a decision tree using recursive splitting.\n",
    "\n",
    "    Args:\n",
    "        X: Input features(pd.DataFrame).\n",
    "        y: Labels (pd.Series).\n",
    "        max_depth: Maximum depth of the tree. Defaults to None (unlimited depth).\n",
    "        depth: Current depth of the tree. Used internally for recursion. Defaults to 0.\n",
    "        metric: Splitting criterion, either 'variance' or 'mse'. Defaults to 'variance'.\n",
    "        feature_names: List of feature names. If None, indices are used. Defaults to None.\n",
    "        max_features: Number of features to consider at each split. None(√total_n_features) or int(<=total_n_features). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        - Nested dictionary representing the tree structure.\n",
    "        - Nodes contain keys: 'type', 'feature', 'threshold', 'left', 'right'.\n",
    "        - Leaf nodes contain keys: 'type', 'value'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert DataFrames to NumPy arrays\n",
    "    if hasattr(X, 'to_numpy'):\n",
    "        X = X.to_numpy()\n",
    "    if hasattr(y, 'to_numpy'):\n",
    "        y = y.to_numpy().flatten()  # Ensure 1D array\n",
    "\n",
    "    # Stop the recursion if all labels are identical or the maximum depth is reached.\n",
    "    if len(set(y)) == 1 or (max_depth is not None and depth == max_depth):\n",
    "        return {'type': 'leaf', 'value': np.mean(y)}\n",
    "\n",
    "    # Find the best split.\n",
    "    split = best_split(X, y, metric, feature_names, max_features)\n",
    "    if not split:\n",
    "        return {'type': 'leaf', 'value': np.mean(y)}\n",
    "\n",
    "    # Split the data into left and right subsets.\n",
    "    # Use feature_index for calculations.\n",
    "    left_mask = X[:, split['feature_index']] <= split['threshold']\n",
    "    right_mask = X[:, split['feature_index']] > split['threshold']\n",
    "\n",
    "    # Recursively build the left and right subtrees.\n",
    "    left_tree = build_tree(X[left_mask], y[left_mask],\n",
    "                           max_depth, depth + 1, metric, feature_names, max_features)\n",
    "    right_tree = build_tree(X[right_mask], y[right_mask],\n",
    "                            max_depth, depth + 1, metric, feature_names, max_features)\n",
    "\n",
    "    # Return the tree structure as a nested dictionary.\n",
    "    return {\n",
    "        'type': 'node',\n",
    "        'feature': split['feature_name'],\n",
    "        'threshold': split['threshold'],\n",
    "        'left': left_tree,\n",
    "        'right': right_tree,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe75f8c2",
   "metadata": {},
   "source": [
    "## 9. Building Random Forest\n",
    "We now create `build_random_forest` function that iterates bootstrapping samples and building trees `n_estimators` times. To reduce execution speed, parallel tree construction is implemented (with all CPU cores used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef61314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_forest(X_train: pd.DataFrame, y_train: pd.Series, n_estimators: int,\n",
    "                        n_jobs: int = -1, max_depth: int = 15) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Optimised random forest builder using parallel processing\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training labels\n",
    "        n_estimators: Number of trees\n",
    "        n_jobs: Number of CPU cores to use (-1 = all cores)\n",
    "        max_depth: Maximum tree depth\n",
    "\n",
    "    Returns:\n",
    "        List of decision trees\n",
    "    \"\"\"\n",
    "    # Build single tree\n",
    "    def _build_single_tree(i):\n",
    "        X_boot, y_boot = bootstrap_sample(X_train, y_train, random_state=i)\n",
    "        return build_tree(X_boot, y_boot, max_depth=max_depth,\n",
    "                          metric='variance', feature_names=feature_names)\n",
    "\n",
    "    # Parallel execution\n",
    "    forest = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_build_single_tree)(i)\n",
    "        for i in range(n_estimators)\n",
    "    )\n",
    "\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5549f39",
   "metadata": {},
   "source": [
    "## 10. Traversing the Tree for Prediction\n",
    "This function traverses the tree to make predictions by following the tree from the root to a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bf154c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_tree(x: pd.DataFrame, tree: Dict[str, Any],\n",
    "                  feature_names: List[str | int] = None, max_features=None) -> float:\n",
    "    \"\"\"\n",
    "    Traverse a decision tree to make a prediction for a single sample.\n",
    "\n",
    "    Args:\n",
    "        x: Single sample.\n",
    "        tree: Decision tree structure.\n",
    "        feature_names: List of feature names. Needed for name-to-index mapping. Defaults to None.\n",
    "        max_features: Number of features to consider at each split. None(√total_n_features) or int(<=total_n_features). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Predicted label.\n",
    "    \"\"\"\n",
    "    if tree['type'] == 'leaf':\n",
    "        return tree['value']\n",
    "\n",
    "    # Resolve feature index if feature_names is provided\n",
    "    feature_index = feature_names.index(\n",
    "        tree['feature']) if feature_names is not None else tree['feature']\n",
    "\n",
    "    if x[feature_index] <= tree['threshold']:\n",
    "        return traverse_tree(x, tree['left'], feature_names, max_features)\n",
    "    else:\n",
    "        return traverse_tree(x, tree['right'], feature_names, max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd84d7e",
   "metadata": {},
   "source": [
    "## 11. Predictions\n",
    "This function predicts labels for all samples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65919ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X: pd.DataFrame, tree: Dict[str, Any],\n",
    "            feature_names: List[str | int] = None) -> float | NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Predict labels for the given dataset using a decision tree classifier.\n",
    "\n",
    "    Args:\n",
    "        X: Input features.\n",
    "        tree: Decision tree structure.\n",
    "        feature_names : List of feature names. Needed for name-to-index mapping. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Predicted labels (1D array for multiple samples or a single label for one sample).\n",
    "    \"\"\"\n",
    "    # Convert DataFrames to NumPy arrays\n",
    "    if hasattr(X, 'to_numpy'):\n",
    "        X = X.to_numpy()\n",
    "\n",
    "    if len(X.shape) == 1:  # If a single sample is provided\n",
    "        return traverse_tree(X, tree, feature_names)\n",
    "    return np.array([traverse_tree(x, tree, feature_names) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0045d8",
   "metadata": {},
   "source": [
    "After all predictions have been made for the `n_estimators`, we will the average value to determine the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d7f49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_average(forest: List[Dict[str, Any]], X: pd.DataFrame,\n",
    "                    feature_names: List[str] = None) -> List[float]:\n",
    "    all_preds = []\n",
    "    for tree in forest:\n",
    "        preds = predict(X, tree, feature_names)\n",
    "        all_preds.append(preds)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_means = np.mean(all_preds, axis=0)\n",
    "    return all_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a663d5f",
   "metadata": {},
   "source": [
    "## 12. Evaluation Metrics\n",
    "### Mean Squared Error (MSE)\n",
    "Mean Squared Error measures the average squared difference between predicted ($\\hat y$) and actual ($y$) values. Large errors are penalised heavily. Smaller MSE indicates better predictions.\n",
    "\n",
    "\\begin{align*}\n",
    "MSE = \\dfrac{1}{n} \\sum_{i=1}^{n}(\\hat y_{i} = y_{i})^2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "037555ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSE(y_true: pd.Series, y_pred: NDArray[np.float64]) -> float:\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa80b90",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error (RMSE)\n",
    "Square root of MSE. It provides error in the same unit as the target variable ($y$) and easier to interpret.\n",
    "\n",
    "\\begin{align*}\n",
    "RMSE = \\sqrt{(MSE)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a76e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_RMSE(y_true: pd.Series, y_pred: NDArray[np.float64]) -> float:\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c91b0",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "Mean Absolute Error measures the average absolute difference between predicted ($\\hat y$) and actual ($y$) values. It is less sensitive to outliers than MSE. Smaller MAE indicates better predictions.\n",
    "\n",
    "\\begin{align*}\n",
    "MAE = \\dfrac{1}{n} \\sum_{i=1}^{n}|\\hat y_{i} = y_{i}|\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af01feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MAE(y_true: pd.Series, y_pred: NDArray[np.float64]) -> float:\n",
    "    return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9c317",
   "metadata": {},
   "source": [
    "<a id=\"r-squared\"></a>\n",
    "### R-Squared($R^2$)\n",
    "\n",
    "R-squared indicated the proportion of variance in the dependent variable that is predictable from the independent variables. Value ranges from 0 to 1. Closer to 1 indicates a better fit.\n",
    "\n",
    "\n",
    "\n",
    "Residual Sum of Squares ($SS_{residual}$): \n",
    "\\begin{align*}\n",
    "SS_{residual} = \\sum_{i=1}^{n} (y_{i} - \\hat y_{i})^{2}\n",
    "\\end{align*}\n",
    "\n",
    "Total Sum of Squares ($SS_{total}$): \n",
    "\\begin{align*}\n",
    "SS_{total} = \\sum_{i=1}^{n} (y_{i} - \\bar y_{i})^{2}\n",
    "\\end{align*}\n",
    "\n",
    "$R^2$ is computed as:\n",
    "\n",
    "\\begin{align*}\n",
    "\n",
    "R^2 = 1 - \\dfrac{SS_{residual}}{SS_{total}} = 1 - \\dfrac{\\sum_{i=1}^{n} (y_{i} - \\hat y_{i})^{2}}{\\sum_{i=1}^{n} (y_{i} - \\bar y_{i})^{2}}\n",
    "\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "\n",
    "$y$: Actual target values.\n",
    "\n",
    "$\\bar y$: Mean of the actual target values.\n",
    "\n",
    "$\\hat y$: Precicted target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f228c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r2(y_true: pd.Series, y_pred: NDArray[np.float64]) -> float:\n",
    "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "    r2 = 1 - (ss_residual / ss_total)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06c6b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true: pd.Series, y_pred: NDArray[np.float64]) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculate and return evaluation metrics for a regression model, including MSE, RMSE, MAE, and R-squared.\n",
    "\n",
    "     Args:\n",
    "        y_true): True labels.\n",
    "        y_pred: Predicted labels.\n",
    "        class_names: List of class names. Defaults to None.\n",
    "    Returns:\n",
    "        - mse: Mean Squared Error (MSE), indicating the average of the squared differences between predicted and true values.\n",
    "        - rmse: Root Mean Squared Error (RMSE), indicating the standard deviation of the residuals.\n",
    "        - mae: Mean Absolute Error (MAE), representing the average absolute difference between predicted and true values.\n",
    "        - r2: R-squared (coefficient of determination), showing the proportion of variance in the dependent variable that is predictable from the independent variable(s).\n",
    "    \"\"\"\n",
    "    mse = calculate_MSE(y_true, y_pred)\n",
    "    rmse = calculate_RMSE(y_true, y_pred)\n",
    "    mae = calculate_MAE(y_true, y_pred)\n",
    "    r2 = calculate_r2(y_true, y_pred)\n",
    "    return mse, rmse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f56d4bc",
   "metadata": {},
   "source": [
    "## 13. Encapsulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80d331cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRandomForestRegressor:\n",
    "    def __init__(self, n_estimators: int = 100, max_depth: int = 15, min_samples_leaf: int = 1,\n",
    "                 min_samples_split=2, metric: str = 'variance', max_features: Optional[int] = None,\n",
    "                 random_state: Optional[int] = None, n_jobs: int = -1) -> None:\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.metric = metric\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.forest = None\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def variance(self, y: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the variance.\n",
    "\n",
    "        Args:\n",
    "            y: Series of values.\n",
    "\n",
    "        Returns:\n",
    "            Variance value.\n",
    "        \"\"\"\n",
    "        return np.var(y) if len(y) > 0 else 0\n",
    "\n",
    "    def mse(self, y: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the mean squared error.\n",
    "\n",
    "        Args:\n",
    "            y: Series of values.\n",
    "\n",
    "        Returns:\n",
    "            Mean squared error value.\n",
    "        \"\"\"\n",
    "        return np.mean((y - np.mean(y)) ** 2) if len(y) > 0 else 0\n",
    "\n",
    "    def _information_gain(self, y: pd.Series, y_left: pd.Series, y_right: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Compute the information gain of a split.\n",
    "\n",
    "        Args:\n",
    "            y: Values of the parent node.\n",
    "            y_left: Values of the left child node.\n",
    "            y_right: Values of the right child node.\n",
    "\n",
    "        Returns:\n",
    "            Information gain from the split.\n",
    "        \"\"\"\n",
    "        if self.metric == 'variance':\n",
    "            parent_metric = self.variance(y)\n",
    "            left_metric = self.variance(y_left)\n",
    "            right_metric = self.variance(y_right)\n",
    "        else:  # metric == \"mse\"\n",
    "            parent_metric = self.mse(y)\n",
    "            left_metric = self.mse(y_left)\n",
    "            right_metric = self.mse(y_right)\n",
    "\n",
    "        weighted_metric: float = (\n",
    "            len(y_left) / len(y) * left_metric\n",
    "            + len(y_right) / len(y) * right_metric\n",
    "        )\n",
    "        return parent_metric - weighted_metric\n",
    "\n",
    "    def _bootstrap_sample(self, X: pd.DataFrame, y: pd.Series, n_samples: Optional[int] = None,\n",
    "                          random_state: Optional[int] = None) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Generate a bootstrap sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            X: Input features.\n",
    "            y: Target labels.\n",
    "            n_samples: Samples to draw (default: dataset size).\n",
    "            random_state: Random seed.\n",
    "\n",
    "        Returns:\n",
    "            Bootstrapped (X, y) tuple.\n",
    "        \"\"\"\n",
    "        rng = np.random.RandomState(random_state)\n",
    "        if n_samples is None:\n",
    "            n_samples = len(X)\n",
    "        indices = rng.randint(0, len(X), size=n_samples)\n",
    "        return X.iloc[indices], y.iloc[indices]\n",
    "\n",
    "    def _best_split(self, X: NDArray[np.float64], y: NDArray[np.float64]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Find the best split for a dataset.\n",
    "\n",
    "        Args:\n",
    "            X: Input features (DataFrame of shape [n_samples, total_n_features]).\n",
    "            y: Labels (Series of shape [n_samples]).\n",
    "            metric: Splitting criterion, either \"gini\" or \"entropy\". Defaults to 'gini'.\n",
    "            feature_names: List of feature names. If None, indices are used. Defaults to None.\n",
    "            max_features: Number of features to consider at each split. None(logs(total_n_features)) or int(<=total_n_features). Defaults to None.\n",
    "        Returns:\n",
    "            Dictionary containing the best split with keys:\n",
    "                - 'feature_index' : Index of the feature used for the split.\n",
    "                - 'feature_name': Name or index of the feature.\n",
    "                - 'threshold' : Threshold value for the split.\n",
    "        \"\"\"\n",
    "\n",
    "        best_info_gain = float('-inf')\n",
    "        best_split = None\n",
    "        total_n_features = X.shape[1]\n",
    "\n",
    "        if isinstance(self.max_features, int):  # if max_features is int\n",
    "            selected_n_features = self.max_features if self.max_features <= total_n_features else total_n_features\n",
    "        else:  # Default = log2(total_n_features)\n",
    "            # selected_n_features = int(np.log2(total_n_features))\n",
    "            selected_n_features = int(np.log2(total_n_features))\n",
    "\n",
    "        selected_features_idx = np.random.choice(\n",
    "            a=total_n_features, size=selected_n_features, replace=False)\n",
    "\n",
    "        # Iterate over randomly selected features.\n",
    "        for feature in selected_features_idx:\n",
    "            # Iterate over all unique thresholds for each random feature.\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                # Split the data into left and right subsets based on the threshold.\n",
    "                left_mask = X[:, feature] <= threshold\n",
    "                right_mask = X[:, feature] > threshold\n",
    "\n",
    "                # Skip invalid splits.\n",
    "                if sum(left_mask) < self.min_samples_leaf or sum(right_mask) < self.min_samples_leaf:\n",
    "                    continue\n",
    "\n",
    "                # Compute IG.\n",
    "                info_gain = self._information_gain(\n",
    "                    y, y[left_mask], y[right_mask])\n",
    "\n",
    "                # Update `best_info_gain` if `info_gain` > `best_info_gain`.\n",
    "                if info_gain > best_info_gain:\n",
    "                    best_info_gain = info_gain\n",
    "                    best_split = {\n",
    "                        'feature_index': feature,\n",
    "                        'feature_name': self.feature_names[feature] if self.feature_names is not None else feature,\n",
    "                        'threshold': threshold,\n",
    "                    }\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def _build_tree(self, X: pd.DataFrame, y: pd.Series, depth: int = 0) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Recursively build a decision tree.\n",
    "\n",
    "        Args:\n",
    "            X: Input features.\n",
    "            y: Target labels.\n",
    "            depth: Current tree depth.\n",
    "\n",
    "        Returns:\n",
    "            Tree structure dictionary.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        X_np = X.to_numpy() if hasattr(X, 'to_numpy') else np.array(X)\n",
    "        y_np = y.to_numpy().flatten() if hasattr(\n",
    "            y, 'to_numpy') else np.array(y).flatten()\n",
    "\n",
    "        # Stopping conditions\n",
    "        if len(np.unique(y_np)) == 1 or (self.max_depth is not None and depth == self.max_depth):\n",
    "            return {'type': 'leaf', 'value': np.mean(y)}\n",
    "\n",
    "        if len(y) < self.min_samples_leaf:\n",
    "            return {'type': 'leaf', 'value': np.mean(y)}\n",
    "\n",
    "        # Find best split\n",
    "        split = self._best_split(X_np, y_np)\n",
    "        if not split:\n",
    "            return {'type': 'leaf', 'value': np.mean(y)}\n",
    "\n",
    "        # Apply split\n",
    "        feature_idx = split['feature_index']\n",
    "        left_mask = X_np[:, feature_idx] <= split['threshold']\n",
    "        right_mask = X_np[:, feature_idx] > split['threshold']\n",
    "\n",
    "        # Recursive tree building\n",
    "        left_tree = self._build_tree(\n",
    "            X.iloc[left_mask] if hasattr(X, 'iloc') else X[left_mask],\n",
    "            y.iloc[left_mask] if hasattr(y, 'iloc') else y[left_mask],\n",
    "            depth + 1\n",
    "        )\n",
    "        right_tree = self._build_tree(\n",
    "            X.iloc[right_mask] if hasattr(X, 'iloc') else X[right_mask],\n",
    "            y.iloc[right_mask] if hasattr(y, 'iloc') else y[right_mask],\n",
    "            depth + 1\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'type': 'node',\n",
    "            'feature': split['feature_name'],\n",
    "            'threshold': split['threshold'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        \"\"\"\n",
    "        Train the random forest on input data.\n",
    "\n",
    "        Args:\n",
    "            X: Training features.\n",
    "            y: Training labels.\n",
    "        \"\"\"\n",
    "        # Store feature names\n",
    "        if hasattr(X, 'columns'):\n",
    "            self.feature_names = X.columns.tolist()\n",
    "\n",
    "        # Set random seeds for reproducibility\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        seeds = np.random.randint(0, 10000, size=self.n_estimators)\n",
    "\n",
    "        # Build trees in parallel\n",
    "        self.forest = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._build_single_tree)(X, y, seed)\n",
    "            for seed in seeds\n",
    "        )\n",
    "\n",
    "    def _build_single_tree(self, X: pd.DataFrame, y: pd.Series,\n",
    "                           seed: int) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Build a single decision tree with bootstrap sampling.\n",
    "        \"\"\"\n",
    "        X_boot, y_boot = self._bootstrap_sample(X, y, random_state=seed)\n",
    "        return self._build_tree(X_boot, y_boot)\n",
    "\n",
    "    def _traverse_tree(self, x: np.ndarray,\n",
    "                       tree: Dict[str, Any]) -> float:\n",
    "        \"\"\"\n",
    "        Traverse a tree to make a prediction for a single sample.\n",
    "\n",
    "        Args:\n",
    "            x: Input sample (1D array).\n",
    "            tree: Decision tree structure.\n",
    "\n",
    "        Returns:\n",
    "            Predicted label.\n",
    "        \"\"\"\n",
    "        if tree['type'] == 'leaf':\n",
    "            return tree['value']\n",
    "\n",
    "        # Resolve feature index\n",
    "        if self.feature_names is not None:\n",
    "            feature_index = self.feature_names.index(tree['feature'])\n",
    "        else:\n",
    "            feature_index = tree['feature']  # Assume integer index\n",
    "\n",
    "        if x[feature_index] <= tree['threshold']:\n",
    "            return self._traverse_tree(x, tree['left'])\n",
    "        else:\n",
    "            return self._traverse_tree(x, tree['right'])\n",
    "\n",
    "    def predict(self,\n",
    "                X: pd.DataFrame | NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "        \"\"\"\n",
    "        Predict labels for input data using majority voting.\n",
    "\n",
    "        Args:\n",
    "            X: Input features (DataFrame or array)\n",
    "\n",
    "        Returns:\n",
    "            Predicted labels (1D array)\n",
    "        \"\"\"\n",
    "        if self.forest is None:\n",
    "            raise RuntimeError(\"Model not trained. Call fit() first.\")\n",
    "\n",
    "        # Convert to numpy array\n",
    "        X_np = X.to_numpy() if hasattr(X, 'to_numpy') else np.array(X)\n",
    "\n",
    "        # Single sample case\n",
    "        if len(X_np.shape) == 1:\n",
    "            return np.mean([self._traverse_tree(X_np, tree) for tree in self.forest])\n",
    "\n",
    "        # Batch predictions\n",
    "        all_preds = [[self._traverse_tree(x, tree) for x in X_np]\n",
    "                     for tree in self.forest\n",
    "                     ]\n",
    "        all_means = np.mean(all_preds, axis=0)\n",
    "        return all_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b20a7999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (Custom): 0.0039\n",
      "RMSE (Custom): 0.0628\n",
      "MAE (Custom): 0.0433\n",
      "R-Squared (Custom): 0.8473\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the decision tree\n",
    "tree = CustomRandomForestRegressor(\n",
    "    n_estimators=100, n_jobs=-1, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = tree.predict(X_test)\n",
    "mse_custom, rmse_custom, mae_custom, r2_custom = evaluate(y_test, y_pred)\n",
    "print(f'MSE (Custom): {mse_custom:.4f}')\n",
    "print(f'RMSE (Custom): {rmse_custom:.4f}')\n",
    "print(f'MAE (Custom): {mae_custom:.4f}')\n",
    "print(f'R-Squared (Custom): {r2_custom:.4f}')\n",
    "print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1607438",
   "metadata": {},
   "source": [
    "## 13. Comparison with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2894cfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (SK): 0.0006\n",
      "MSE (Custom): 0.0039\n",
      "----------\n",
      "RMSE (SK): 0.0240\n",
      "RMSE (Custom): 0.0628\n",
      "----------\n",
      "MAE (SK): 0.0166\n",
      "MAE (Custom): 0.0433\n",
      "----------\n",
      "R-Squared (SK): 0.9777\n",
      "R-Squared (Custom): 0.8473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "regressor = RandomForestRegressor(\n",
    "    n_estimators=100\n",
    ")\n",
    "regressor.fit(X, y)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = regressor.predict(X_test)\n",
    "mse_sk = mean_squared_error(y_test, y_pred)\n",
    "rmse_sk = np.sqrt(mse_sk)\n",
    "mae_sk = mean_absolute_error(y_test, y_pred)\n",
    "r2_sk = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MSE (SK): {mse_sk:.4f}')\n",
    "print(f'MSE (Custom): {mse_custom:.4f}')\n",
    "print('----------')\n",
    "print(f'RMSE (SK): {rmse_sk:.4f}')\n",
    "print(f'RMSE (Custom): {rmse_custom:.4f}')\n",
    "print('----------')\n",
    "print(f'MAE (SK): {mae_sk:.4f}')\n",
    "print(f'MAE (Custom): {mae_custom:.4f}')\n",
    "print('----------')\n",
    "print(f'R-Squared (SK): {r2_sk:.4f}')\n",
    "print(f'R-Squared (Custom): {r2_custom:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
