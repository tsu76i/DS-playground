{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714c8447",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor from Scratch\n",
    "***\n",
    "## Table of Contents\n",
    "1. Load Data\n",
    "2. Train Test Split\n",
    "3. Loss Functions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf8a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92df9ce",
   "metadata": {},
   "source": [
    "Decision trees and regression trees are collectively referred to as **CART**, which stands for **Classification and Regression Trees**.\n",
    "\n",
    "- **Decision Trees** are used for classification tasks, where the target variable is *categorical*.\n",
    "\n",
    "- **Regression Trees** are used for regression tasks, where the target variable is *continuous*.\n",
    "\n",
    "CART is a popular algorithm that can handle both types of tasks by optimising for different criteria:\n",
    "\n",
    "- For classification, CART minimises classification error, Gini impurity, or entropy.\n",
    "\n",
    "- For regression, CART minimises the variance, mean squared error (MSE) or mean absolute error (MAE).\n",
    "\n",
    "Both types of trees follow the same core idea of splitting the data based on conditions to create homogeneous subsets, but their objectives differ depending on the problem type.\n",
    "In this notebook, we will build a predictive model using Regression Trees on the admission chance dataset from YBI Foundation's GitHub repository.\n",
    "\n",
    "### 1. Structure\n",
    "\n",
    "- **Nodes**: Represent features or decisions.\n",
    "\n",
    "- **Edges**: Represent conditions or thresholds.\n",
    "\n",
    "- **Leaves**: Represent outcomes or class labels (in classification) or predicted values (in regression).\n",
    "\n",
    "### 2. Construction\n",
    "\n",
    "- Begins with the root node (the entire dataset).\n",
    "\n",
    "- Splits the data based on feature thresholds that maximise the information gain (derived from Gini impurity, entropy, MSE or variance reduction).\n",
    "\n",
    "- Recursively continues until a stopping condition is met (e.g., maximum depth, minimum samples per leaf, or pure nodes).\n",
    "\n",
    "### 3. Advantages\n",
    "\n",
    "- Intuitive and easy to interpret.\n",
    "\n",
    "- Handles both numerical and categorical data.\n",
    "\n",
    "- Non-parametric and robust to outliers.\n",
    "\n",
    "### 4. Limitations\n",
    "\n",
    "- Prone to overfitting, especially with deep trees.\n",
    "\n",
    "- Sensitive to slight changes in the data (high variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f43ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37855c",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "Retrieved from [GitHub - YBI Foundation](https://github.com/YBI-Foundation/Dataset/blob/main/Admission%20Chance.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8cfc91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Serial No",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GRE Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TOEFL Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "University Rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": " SOP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LOR ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CGPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Chance of Admit ",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "088a866d-f6a8-433c-9599-ad5b8eee4a0c",
       "rows": [
        [
         "0",
         "1",
         "337",
         "118",
         "4",
         "4.5",
         "4.5",
         "9.65",
         "1",
         "0.92"
        ],
        [
         "1",
         "2",
         "324",
         "107",
         "4",
         "4.0",
         "4.5",
         "8.87",
         "1",
         "0.76"
        ],
        [
         "2",
         "3",
         "316",
         "104",
         "3",
         "3.0",
         "3.5",
         "8.0",
         "1",
         "0.72"
        ],
        [
         "3",
         "4",
         "322",
         "110",
         "3",
         "3.5",
         "2.5",
         "8.67",
         "1",
         "0.8"
        ],
        [
         "4",
         "5",
         "314",
         "103",
         "2",
         "2.0",
         "3.0",
         "8.21",
         "0",
         "0.65"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No  GRE Score  TOEFL Score  University Rating   SOP  LOR   CGPA  \\\n",
       "0          1        337          118                  4   4.5   4.5  9.65   \n",
       "1          2        324          107                  4   4.0   4.5  8.87   \n",
       "2          3        316          104                  3   3.0   3.5  8.00   \n",
       "3          4        322          110                  3   3.5   2.5  8.67   \n",
       "4          5        314          103                  2   2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/YBI-Foundation/Dataset/refs/heads/main/Admission%20Chance.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fcabfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (400, 8)\n",
      "Target shape: (400,)\n",
      "Features: \n",
      "['Serial No', 'GRE Score', 'TOEFL Score', 'University Rating', ' SOP', 'LOR ', 'CGPA', 'Research']\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "feature_names = df.columns[:-1].tolist()  # All columns except the last one\n",
    "target_name = df.columns[-1]  # The last column name\n",
    "\n",
    "# Check the shape of the data\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Features: \\n{feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf2f38b",
   "metadata": {},
   "source": [
    "## 2. Train Test Split\n",
    "Train test split is a fundamental model validation technique in machine learning. It divides a dataset into two separate portions: a **training set** used to train a model, and a **testing set** used to evaluate how well the model can perform on unseen data. \n",
    "\n",
    "The typical split ratio is 80% for training and 20% for testing, though this can vary (70/30 or 90/10 are also common). The key principle is that the test set must remain completely separated during model training process, and should never be used to make decisions about the model or tune parameters. \n",
    "\n",
    "The split is usually done randomly to ensure both sets are representative of the overall dataset, and many libraries (such as scikit-learn) provide build-in functions that handle this process automatically while maintaining proper randomisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fdba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X: np.ndarray, y: np.ndarray, test_size: float = 0.2,\n",
    "                     random_state: int = None) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split arrays or matrices into random train and test subsets.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Input features, a 2D array with rows (samples) and columns (features).\n",
    "        y (np.ndarray): Target values/labels, a 1D array with rows (samples).\n",
    "        test_size (float): Proportion of the dataset to include in the test split. Must be between 0.0 and 1.0. default = 0.2\n",
    "        random_state (int): Seed for the random number generator to ensure reproducible results. default = None\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        A tuple containing:\n",
    "            - X_train (np.ndarray): Training set features.\n",
    "            - X_test (np.ndarray): Testing set features.\n",
    "            - y_train (np.ndarray): Training set target values.\n",
    "            - y_test (np.ndarray): Testing set target values.\n",
    "    \"\"\"\n",
    "    # Set a random seed if it exists\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Create a list of numbers from 0 to len(X)\n",
    "    indices = np.arange(len(X))\n",
    "\n",
    "    # Shuffle the indices\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Define the size of our test data from len(X)\n",
    "    test_size = int(test_size * len(X))\n",
    "\n",
    "    # Generate indices for test and train data\n",
    "    test_indices: list[int] = indices[:test_size]\n",
    "    train_indices: list[int] = indices[test_size:]\n",
    "\n",
    "    # Return: X_train, X_test, y_train, y_test\n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb85ad",
   "metadata": {},
   "source": [
    "## 3. Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0a871e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
