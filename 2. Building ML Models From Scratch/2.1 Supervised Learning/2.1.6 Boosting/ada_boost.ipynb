{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f66f2663",
   "metadata": {},
   "source": [
    "# Adaptive Boosting from Scratch\n",
    "***\n",
    "## Table of Contents\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1587216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from numpy.typing import NDArray\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29553c26",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Adaptive Boosting (AdaBoost) is a foundational ensemble learning algorithm designed to improve the accuracy of machine learning models by combining multiple **weak classifiers** (often decision stumps - decision trees with a single split) into a single **strong classifier**. Althought AdaBoost is primarily for binary classification, it has been extended to handle multiclass problems and regression tasks in some variants. However, its core mechanism and main use case remain in binary classification.\n",
    "\n",
    "### Advantages:\n",
    "- Turn weak models into a strong classifier.\n",
    "- Less overfitting.\n",
    "- No need for parameter tuning.\n",
    "\n",
    "### Limitations:\n",
    "- Sensitive to outliers as misclassified samples get higher weights.\n",
    "- Primarily for binary classification.\n",
    "\n",
    "### Steps:\n",
    "1. Initialise weights.\n",
    "2. For each boosting round (M iterations),\n",
    "    - Train a weak lerner (decision stump).\n",
    "    - Compute weighted error.\n",
    "    - Calculate lerner weights $\\alpha$.\n",
    "    - Update sample weights.\n",
    "    - Repeat for the maximum number of iterations or until weighted error is sufficiently low.\n",
    "3. Predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e1022b",
   "metadata": {},
   "source": [
    "## 2. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74e4048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "y = np.where(y == 0, -1, 1)     # AdaBoost expects labels as -1 and +1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1394850d",
   "metadata": {},
   "source": [
    "## 3. Initialising Weights\n",
    "All training samples are initialised with equal weight:\n",
    "\n",
    "\\begin{align*}\n",
    "    w_i = \\dfrac{1}{N}\n",
    "\\end{align*}\n",
    "\n",
    "where $N$ is the number of samples. For $N = 5$, the initial weights of the sample will be:\n",
    "\n",
    "\\begin{align*}\n",
    "    w_i = \\dfrac{1}{5} = 0.2\n",
    "\\end{align*}\n",
    "\n",
    "The `np.full` function from NumPy library can generate an array of the specified length with every entry set to the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0075d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_weights(n_samples: int) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Initialise all sample weights equally.\n",
    "    \"\"\"\n",
    "    return np.full(n_samples, 1 / n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3676a3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For N = 5: [0.2 0.2 0.2 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "print(f'For N = 5: {initialise_weights(5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f604e6",
   "metadata": {},
   "source": [
    "## 4. Finding the Best Stump"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
