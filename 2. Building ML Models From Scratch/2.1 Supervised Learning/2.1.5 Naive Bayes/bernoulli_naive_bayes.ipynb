{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961620d0",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes Classifier from Scratch\n",
    "***\n",
    "## Table of Contents\n",
    "1. [Introduction](#1-introduction)\n",
    "    - [Bayes' Theorem](#bayes-theorem)\n",
    "2. [Loading Data](#2-loading-data)\n",
    "3. [Prior Probability](#3-prior-probability)\n",
    "4. [Likelihood for Bernoulli NB](#4-likelihood-for-bernoulli-nb)\n",
    "5. [Posterior Probability for Bernoulli NB](#5-posterior-probability-for-bernoulli-nb)\n",
    "6. [Prediction](#6-prediction)\n",
    "7. [Evaluation Metrics](#7-evaluation-metrics)\n",
    "    - [Binary Confusion Matrix](#binary-confusion-matrix)\n",
    "    - [Multi-Class Confusion Matrix](#multi-class-confusion-matrix)\n",
    "    - [Accuracy](#accuracy)\n",
    "    - [Precision](#precision)\n",
    "    - [Recall](#recall)\n",
    "    - [F1-Score](#f1-score)\n",
    "8. [Encapsulation](#8-encapsulation)\n",
    "9. [Comparison with Scikit-Learn](#9-comparison-with-scikit-learn)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5163acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, List, Dict\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de76c55c",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Naive Bayes classifiers are probabilistic classification models based on Bayes' Theorem, assuming conditional independence between features given the class labels or values. Naive Bayes is a general framework; the specific variant should be chosen based on the nature of your data:\n",
    "\n",
    "- **Categorical Naive Bayes**\n",
    "\n",
    "    - **Features**: Categorical labels (e.g., colours, countries, product types).\n",
    "\n",
    "    - **Use Case**: Classification with discrete, categorically distributed features.\n",
    "\n",
    "- **Multinomial Naive Bayes**\n",
    "\n",
    "    - **Features**: Counts or frequencies (e.g., word occurrences, event counts).\n",
    "\n",
    "    - **Use** **Case**: Text classification, document classification, or any scenario where features are discrete counts.\n",
    "\n",
    "- **Gaussian Naive Bayes**\n",
    "\n",
    "    - **Features**: Continuous data (e.g., measurements, sensor readings).\n",
    "\n",
    "    - **Use Case**: Classification with numerical features assumed to follow a Gaussian distribution.\n",
    "\n",
    "- **Bernoulli Naive Bayes**\n",
    "\n",
    "    - **Features**: Binary features (e.g., True/False, 0/1).\n",
    "\n",
    "    - **Use Case**: Text classification (presence/absence of words), binary feature spaces.\n",
    "\n",
    "\n",
    "\n",
    "### Bayes' Theorem\n",
    "Bayes' theorem describes the probability of a class $C_{i}$ given a set of features $X = (x_{1}, x_{2},\\ldots,x_{N})$:\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}|X) = \\dfrac{P(X|C_{i}) \\cdot P(C_{i})}{P(X)}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $P(C_{i}|X)$: Posterior probability of class $C_{i}$ given features $X$.\n",
    "- $P(X|C_{i})$: Likelihood of features $X$ given class $C_{i}$.\n",
    "- $P(C_{i})$: Prior probability of class $C_{i}$.\n",
    "- $P(X)$: Probability of features $X$ (acts as a normalising constant).\n",
    "\n",
    "Bernoulli Naive Bayes assumes features $X = (x_{1}, x_{2},\\ldots,x_{N})$ are conditionally independent given the class $C_{i}$, thus the likelihood is expressed as:\n",
    "\n",
    "\\begin{align*}\n",
    "P(X|C_{i}) = P(x_{1}, x_{2}, \\dots, x_{N}|C_{i}) = \\prod_{j=1}^{N}P(x_{j}|C_{i})\n",
    "\\end{align*}\n",
    "\n",
    "Replacing $P(X|C_{i})$ in Bayes' theorem, the equation becomes:\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}|X) = \\dfrac{P(C_{i}) \\cdot \\prod_{j=1}^{N} P(x_{j}|C_{i})}{P(X)}\n",
    "\\end{align*}\n",
    "\n",
    "Since $P(X)$ is constant for all classes,\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}|X) \\propto P(C_{i}) \\cdot \\prod_{j=1}^{N} P(x_{j}|C_{i})\n",
    "\\end{align*}\n",
    "\n",
    "The symbol $\\propto$ denotes proportionality, meaning we ignore the denominator $P(X)$ when comparing probabilities across classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83bc3e",
   "metadata": {},
   "source": [
    "## 2. Loading Data\n",
    "Retrieved from [Kaggle - Simple Weather Forecast](https://www.kaggle.com/datasets/dheemanthbhat/simple-weather-forecast?select=weather_forecast.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9507301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Outlook",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Temperature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Humidity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Windy",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Play",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "9c8f1382-691f-4363-90fb-df29ca453f59",
       "rows": [
        [
         "0",
         "Sunny",
         "Hot",
         "High",
         "Weak",
         "No"
        ],
        [
         "1",
         "Sunny",
         "Hot",
         "High",
         "Strong",
         "No"
        ],
        [
         "2",
         "Overcast",
         "Hot",
         "High",
         "Weak",
         "Yes"
        ],
        [
         "3",
         "Rain",
         "Mild",
         "High",
         "Weak",
         "Yes"
        ],
        [
         "4",
         "Rain",
         "Cool",
         "Normal",
         "Weak",
         "Yes"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook Temperature Humidity   Windy Play\n",
       "0     Sunny         Hot     High    Weak   No\n",
       "1     Sunny         Hot     High  Strong   No\n",
       "2  Overcast         Hot     High    Weak  Yes\n",
       "3      Rain        Mild     High    Weak  Yes\n",
       "4      Rain        Cool   Normal    Weak  Yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../_datasets/weather_forecast.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d9ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Play', axis=1)\n",
    "y = df['Play']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cab8b2",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes requires features to have binary values, so we need to one-hot encode all categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76aeda7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Outlook_Overcast",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Outlook_Rain",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Outlook_Sunny",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Temperature_Cool",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Temperature_Hot",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Temperature_Mild",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Humidity_High",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Humidity_Normal",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Windy_Strong",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Windy_Weak",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "206c54b2-6dcf-40e7-92a7-b33934624fc9",
       "rows": [
        [
         "0",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "1",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False",
         "True",
         "False"
        ],
        [
         "2",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "3",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "True",
         "False",
         "False",
         "True"
        ],
        [
         "4",
         "False",
         "True",
         "False",
         "True",
         "False",
         "False",
         "False",
         "True",
         "False",
         "True"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook_Overcast</th>\n",
       "      <th>Outlook_Rain</th>\n",
       "      <th>Outlook_Sunny</th>\n",
       "      <th>Temperature_Cool</th>\n",
       "      <th>Temperature_Hot</th>\n",
       "      <th>Temperature_Mild</th>\n",
       "      <th>Humidity_High</th>\n",
       "      <th>Humidity_Normal</th>\n",
       "      <th>Windy_Strong</th>\n",
       "      <th>Windy_Weak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outlook_Overcast  Outlook_Rain  Outlook_Sunny  Temperature_Cool  \\\n",
       "0             False         False           True             False   \n",
       "1             False         False           True             False   \n",
       "2              True         False          False             False   \n",
       "3             False          True          False             False   \n",
       "4             False          True          False              True   \n",
       "\n",
       "   Temperature_Hot  Temperature_Mild  Humidity_High  Humidity_Normal  \\\n",
       "0             True             False           True            False   \n",
       "1             True             False           True            False   \n",
       "2             True             False           True            False   \n",
       "3            False              True           True            False   \n",
       "4            False             False          False             True   \n",
       "\n",
       "   Windy_Strong  Windy_Weak  \n",
       "0         False        True  \n",
       "1          True       False  \n",
       "2         False        True  \n",
       "3         False        True  \n",
       "4         False        True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_binary = pd.get_dummies(X, drop_first=False)\n",
    "X_binary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7b0e6",
   "metadata": {},
   "source": [
    "We will also convert `y` into a binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3a6b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Play",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "15ee7246-c24e-4389-b147-28bf1b66e8f8",
       "rows": [
        [
         "0",
         "0"
        ],
        [
         "1",
         "0"
        ],
        [
         "2",
         "1"
        ],
        [
         "3",
         "1"
        ],
        [
         "4",
         "1"
        ],
        [
         "5",
         "0"
        ],
        [
         "6",
         "1"
        ],
        [
         "7",
         "0"
        ],
        [
         "8",
         "1"
        ],
        [
         "9",
         "1"
        ],
        [
         "10",
         "1"
        ],
        [
         "11",
         "1"
        ],
        [
         "12",
         "1"
        ],
        [
         "13",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 14
       }
      },
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     0\n",
       "6     1\n",
       "7     0\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    0\n",
       "Name: Play, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary = pd.Series(np.where(y == 'Yes', 1, 0), index=y.index, name='Play')\n",
    "y_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814b485",
   "metadata": {},
   "source": [
    "## 3. Prior Probability\n",
    "Class $C_{i}$ (`y_binary`) has two boolean variables: `1`, and `0` (`1` = 'Yes', `0` = 'No' in `y`):\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}=1) = \\dfrac{\\text{Count(1)}}{\\text{Total Count}}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}=\\text{0}) = \\dfrac{\\text{Count(0)}}{\\text{Total Count}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe471909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 14\n",
      "Counts: {1: 9, 0: 5}\n"
     ]
    }
   ],
   "source": [
    "print(f'Total count: {len(df)}')\n",
    "print(f'Counts: {y_binary.value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd22a8",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "P(1) = \\dfrac{9}{14} = 0.6429\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "P(0) = \\dfrac{5}{14} = 0.3571\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ced868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_priors(y: pd.Series) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Calculate prior probabilities for each class in the target variable.\n",
    "\n",
    "    Args:\n",
    "        y: Target variable containing class labels (0/1).\n",
    "\n",
    "    Returns:\n",
    "        Prior probabilities for each class.\n",
    "    \"\"\"\n",
    "    return y.value_counts(normalize=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ba668c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.6428571428571429, 0: 0.35714285714285715}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_priors(y_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e3dbf",
   "metadata": {},
   "source": [
    "## 4. Likelihood for Bernoulli NB\n",
    "For a feature vector $X = (x_{1}, x_{2},\\ldots,x_{N})$ and class $C_{i}$, the likelihood is expressed as:\n",
    "\n",
    "\\begin{align*}\n",
    "P(X|C_{i}) = P(x_{1}, x_{2}, \\dots, x_{N}|C_{i}) = \\prod_{j=1}^{N}P(x_{j}|C_{i})\n",
    "\\end{align*}\n",
    "\n",
    "where each $P(x_{j}|C_{i})$ follows a **Bernoulli distribution**:\n",
    "\n",
    "\\begin{align*}\n",
    "\n",
    "P(x_{j}|C_{i}) = \n",
    "  \\begin{cases}\n",
    "    p_{ij}     & \\text{if $x_{j} = 1$} \\\\\n",
    "    1 - p_{ij} & \\text{if $x_{j} = 0$}\n",
    "  \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "Here, $p_{ij}$ is the probability that feature $j$ is $1$ in class $C_{i}$:\n",
    "\n",
    "\\begin{align*}\n",
    "p_{ij} = \\dfrac{\\text{Count(${x_{j}}$ = 1|${C_{i}}$)} + \\alpha}{\\text{Count(${C_{i}}$)} + 2 \\alpha}\n",
    "\\end{align*}\n",
    "\n",
    "where $\\alpha$ is the Laplace smoothing parameter to avoid zero probabilities (default $\\alpha$ = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "500f018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihoods(X: pd.DataFrame, y: pd.Series,\n",
    "                          alpha: float = 1.0) -> Dict[str, Dict[int, Dict[int, float]]]:\n",
    "    \"\"\"\n",
    "    Calculate conditional probabilities for Bernoulli Naive Bayes.\n",
    "\n",
    "    Args:\n",
    "        X: Binary feature matrix (DataFrame with 0/1 values)\n",
    "        y: Target variable (Series of class labels in 0/1)\n",
    "        alpha: Smoothing parameter for Laplace smoothing (default=1.0)\n",
    "\n",
    "    Returns:\n",
    "        Nested dictionary with structure:\n",
    "        {feature_name: {class_label: {feature_value: probability}}}\n",
    "    \"\"\"\n",
    "    likelihoods = {}\n",
    "\n",
    "    for feature in X.columns:\n",
    "        likelihoods[feature] = {}\n",
    "\n",
    "        for class_label in y.unique():\n",
    "            c = int(class_label)\n",
    "            class_mask = (y == c)\n",
    "            class_subset = X.loc[class_mask, feature]\n",
    "            total_in_class = class_mask.sum()  # Number of samples in class\n",
    "\n",
    "            # Count occurrences of 1s (0s will be total - count_1)\n",
    "            count_1 = class_subset.sum()\n",
    "            count_0 = total_in_class - count_1\n",
    "\n",
    "            # Apply Laplace smoothing for binary features\n",
    "            # Denominator: total_in_class + 2 * alpha (for two possible values)\n",
    "            prob_1 = (count_1 + alpha) / (total_in_class + 2 * alpha)\n",
    "            prob_0 = (count_0 + alpha) / (total_in_class + 2 * alpha)\n",
    "\n",
    "            # Store probabilities for both values\n",
    "            likelihoods[feature][c] = {\n",
    "                0: round(float(prob_0), 4),\n",
    "                1: round(float(prob_1), 4)\n",
    "            }\n",
    "\n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e5a262b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Outlook_Overcast': {0: {0: 0.8571, 1: 0.1429}, 1: {0: 0.5455, 1: 0.4545}},\n",
       " 'Outlook_Rain': {0: {0: 0.5714, 1: 0.4286}, 1: {0: 0.6364, 1: 0.3636}},\n",
       " 'Outlook_Sunny': {0: {0: 0.4286, 1: 0.5714}, 1: {0: 0.7273, 1: 0.2727}},\n",
       " 'Temperature_Cool': {0: {0: 0.7143, 1: 0.2857}, 1: {0: 0.6364, 1: 0.3636}},\n",
       " 'Temperature_Hot': {0: {0: 0.5714, 1: 0.4286}, 1: {0: 0.7273, 1: 0.2727}},\n",
       " 'Temperature_Mild': {0: {0: 0.5714, 1: 0.4286}, 1: {0: 0.5455, 1: 0.4545}},\n",
       " 'Humidity_High': {0: {0: 0.2857, 1: 0.7143}, 1: {0: 0.6364, 1: 0.3636}},\n",
       " 'Humidity_Normal': {0: {0: 0.7143, 1: 0.2857}, 1: {0: 0.3636, 1: 0.6364}},\n",
       " 'Windy_Strong': {0: {0: 0.4286, 1: 0.5714}, 1: {0: 0.6364, 1: 0.3636}},\n",
       " 'Windy_Weak': {0: {0: 0.5714, 1: 0.4286}, 1: {0: 0.3636, 1: 0.6364}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_likelihoods(X_binary, y_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0be33",
   "metadata": {},
   "source": [
    "## 5. Posterior Probability for Bernoulli NB\n",
    "As we discussed [above](#1-introduction), the formula of posterior probability is:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}|X) \\propto P(C_{i}) \\prod_{j=1}^{N} P(x_{j}|C_{i})\n",
    "\\end{align*}\n",
    "\n",
    "Following a Bernoulli distribution and knowing that $C_{i}$ is a boolean value (0 or 1), we will use log probabilities to prevent overflow:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{log } P(C_{i}|X) = \\text{log } P(C_{i}) + \\sum_{j=1}^{N} [x_{j} \\log{p_{ij}} + (1-x_{j}) \\log{(1-p_{ij})}]\n",
    "\\end{align*}\n",
    "\n",
    "In the following code, `.get(category, 1e-9)` tries to retrieve the probability for the specific value category from this dictionary. If the category was not seen in the training data for this class (i.e., it's missing from the dictionary), it returns a very small default value (1e-9) instead of raising an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "517a734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posterior(x: Dict[str, int], priors: Dict[int, float], likelihoods: Dict[str, Dict[int, Dict[int, float]]],\n",
    "                        X_columns: List[str], classes: List[int]) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Calculate log-posterior probabilities for all classes given a sample.\n",
    "\n",
    "    Args:\n",
    "        x: Input sample as dictionary {feature: value}.\n",
    "        priors: Prior probabilities from calculate_priors().\n",
    "        likelihoods: Conditional probabilities from calculate_likelihoods().\n",
    "        X_columns: List of feature names.\n",
    "        classes: List of possible class labels (0/1).\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping each class to its log-posterior probability.\n",
    "    \"\"\"\n",
    "\n",
    "    log_posteriors = {}\n",
    "    for c in classes:\n",
    "        log_proba = np.log(priors[c])  # Log of prior\n",
    "        for feature in X_columns:  # Sum of the likelihood for each x given c\n",
    "            y_value = x[feature]\n",
    "            # Avoid log(0) if the feature does not exist\n",
    "            proba = likelihoods[feature][c].get(y_value, 1e-9)\n",
    "            log_proba += np.log(proba)\n",
    "        log_posteriors[int(c)] = round(float(log_proba), 4)\n",
    "    return log_posteriors  # log-posterior probabilities for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ad429cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -6.4139, 1: -8.0838}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_posterior(X_binary.iloc[0], calculate_priors(\n",
    "    y_binary), calculate_likelihoods(X_binary, y_binary), X_binary.columns, y_binary.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46cb58f",
   "metadata": {},
   "source": [
    "## 6. Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d941e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X: pd.DataFrame, y: pd.Series) -> List[int]:\n",
    "    \"\"\"\n",
    "    Predict class labels using Bernoulli Naive Bayes.\n",
    "\n",
    "    Args:\n",
    "        X: Feature matrix.\n",
    "        y: Target variable.\n",
    "\n",
    "    Returns:\n",
    "        Predicted class labels.\n",
    "    \"\"\"\n",
    "    priors = calculate_priors(y)\n",
    "    likelihoods = calculate_likelihoods(X, y)\n",
    "    classes = y.unique()\n",
    "    X_columns = X.columns\n",
    "\n",
    "    predictions = []\n",
    "    for row in X.itertuples(index=False):\n",
    "        posterior = calculate_posterior(\n",
    "            row._asdict(), priors, likelihoods, X_columns, classes)\n",
    "        predictions.append(max(posterior, key=posterior.get))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9597eee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_binary, y_binary)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08cbe5",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics\n",
    "### Binary Confusion Matrix\n",
    "In a confusion matrix, the terms True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN) describe the classification performance for binary classification. \n",
    "\n",
    "|                     | Predicted Negative  | Predicted Positive  |\n",
    "| ------------------- | ------------------- | ------------------- |\n",
    "| **Actual Negative** | True Negative (TN)  | False Positive (FP) |\n",
    "| **Actual Positive** | False Negative (FN) | True Positive (TP)  |\n",
    "\n",
    "\n",
    "1. True Positive (TP): The number of instances correctly predicted as positive (e.g., a disease correctly identified).\n",
    "\n",
    "2. True Negative (TN): The number of instances correctly predicted as negative (e.g., no disease correctly identified).\n",
    "\n",
    "3. False Positive (FP): The number of instances incorrectly predicted as positive (e.g., predicting disease when there isn't any).\n",
    "\n",
    "4. False Negative (FN): The number of instances incorrectly predicted as negative (e.g., missing a disease when it exists).\n",
    "\n",
    "### Multi-Class Confusion Matrix\n",
    "For multi-class classification, the concepts can be extended by treating one class as the \"positive\" class and all others as \"negative\" classes in a one-vs-all approach. Rows represent the actual classes (true labels), and columns represent the predicted classes. For a class $C$,\n",
    "1. True Positive (TP): The count in the diagonal cell corresponding to class $C$ ($\\text{matrix} [C][C]$).\n",
    "2. False Positive (FP): The sum of the column for class $C$, excluding the diagonal ($\\sum(\\text{matrix} [:, C]) - \\text{matrix} [C][C]$).\n",
    "3. False Negative (FN): The sum of the row for class $C$, excluding the diagonal ($\\sum(\\text{matrix} [C, :]) - \\text{matrix} [C][C]$).\n",
    "4. True Negative (TN): All other cells not in the row or column for class $C$ ($\\text{total} - (FP + FN + TP)$).\n",
    "\n",
    "|                  | Predicted Class 0 | Predicted Class 1 | Predicted Class 2 |\n",
    "| ---------------- | ----------------- | ----------------- | ----------------- |\n",
    "| **True Class 0** | 5                 | 2                 | 0                 |\n",
    "| **True Class 1** | 1                 | 6                 | 1                 |\n",
    "| **True Class 2** | 0                 | 2                 | 7                 |\n",
    "\n",
    "\n",
    "For Class 0:\n",
    "- TP = 5 (diagonal element for Class 0)\n",
    "- FP = 1 (sum of column 0 minus TP: 1 + 0)\n",
    "- FN = 2 (sum of row 0 minus TP: 2 + 0)\n",
    "- TN = 6 + 1 + 2 + 7 = 16 (all other cells not in row 0 or column 0)\n",
    "\n",
    "For Class 1:\n",
    "- TP = 6 (diagonal element for Class 1)\n",
    "- FP = 4 (sum of column 1 minus TP: 2 + 2)\n",
    "- FN = 2 (sum of row 1 minus TP: 1 + 1)\n",
    "- TN = 5 + 0 + 0 + 7 = 12 (all other cells not in row 1 or column 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba32f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true: pd.Series, y_pred: List[str],\n",
    "                     class_names: List[str] = None) -> Tuple[NDArray[np.int64], List[str]]:\n",
    "    \"\"\"\n",
    "    Calculate the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "        class_names: List of class names. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: \n",
    "        - Confusion matrix.\n",
    "        - List of class names.\n",
    "    \"\"\"\n",
    "    # Encode labels as integers\n",
    "    unique_classes = np.unique(y_true)\n",
    "    if class_names is None:\n",
    "        class_names = [str(cls) for cls in unique_classes]\n",
    "    class_to_index = {cls: i for i, cls in enumerate(unique_classes)}\n",
    "\n",
    "    n_classes = len(unique_classes)\n",
    "    matrix = np.zeros((n_classes, n_classes), dtype=int)\n",
    "\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_idx = class_to_index[true]\n",
    "        pred_idx = class_to_index[pred]\n",
    "        matrix[true_idx][pred_idx] += 1\n",
    "\n",
    "    return matrix, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e4d03",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Accuracy is the most common evaluation metric for classification problems, representing the percentage of correct predictions out of total predictions. It provides a simple measure of how often the classifier makes correct predictions across all classes.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Accuracy} = \\dfrac{\\text{True Positives (TP)} + \\text{True Negatives (TN)}}{\\text{Total Samples}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efa0d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true: pd.Series, y_pred: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of predictions by comparing true and predicted labels.\n",
    "\n",
    "    Args:\n",
    "        y_true: Ground truth target values. Contains the actual class labels for each sample.\n",
    "        y_pred: Estimated target as returned by a classifier. Contains the predicted class labels for each sample.\n",
    "    Returns:\n",
    "        Classification accuracy (0.0 to 1.0).\n",
    "    \"\"\"\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828add26",
   "metadata": {},
   "source": [
    "### Precision\n",
    "Precision measures the proportion of true positive predictions out of all positive predictions made by the classifier.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Precision} = \\dfrac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Positives (FP)}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cce71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true: pd.Series, y_pred: List[str]) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Calculate precision for each class.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        Precision values for each class.\n",
    "    \"\"\"\n",
    "    cm, _ = confusion_matrix(y_true, y_pred)\n",
    "    return np.diag(cm) / (np.sum(cm, axis=0) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2b5d6",
   "metadata": {},
   "source": [
    "### Recall\n",
    "Recall measures the proportion of true positive predications out of all actual positive cases.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Recall} = \\dfrac{\\text{True Positives (TP)} }{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3093e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true: pd.Series, y_pred: List[str]) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Calculate recall for each class.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        Recall values for each class.\n",
    "    \"\"\"\n",
    "    cm, _ = confusion_matrix(y_true, y_pred)\n",
    "    return np.diag(cm) / (np.sum(cm, axis=1) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd87af",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "The F1-Score is the harmonic mean of precision and recall.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{F1-Score} = 2 \\times \\dfrac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdce5767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true: pd.Series, y_pred: List[str]) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Calculate F1-score for each class.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        F1-scores for each class.\n",
    "    \"\"\"\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * (prec * rec) / (prec + rec + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1c25a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true: pd.Series, y_pred: List[str],\n",
    "             class_names: List[str] = None) -> Tuple[float, float, float, float, NDArray[np.int64]]:\n",
    "    \"\"\"\n",
    "    Calculate evaluation metrics including accuracy, precision, recall, and F1-score for each class.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "        class_names: List of class names. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple:\n",
    "        - Overall accuracy.\n",
    "        - Average precision.\n",
    "        - Average recall.\n",
    "        - Average F1-score.\n",
    "        - Confusion matrix.\n",
    "    \"\"\"\n",
    "    cm, class_names = confusion_matrix(y_true, y_pred, class_names)\n",
    "    acc = accuracy(y_true, y_pred)\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    # print(\"Class\\tPrecision\\tRecall\\tF1-Score\")\n",
    "    # for i, class_name in enumerate(class_names):\n",
    "    #     print(f\"{class_name}\\t{prec[i]:.4f}\\t\\t{rec[i]:.4f}\\t{f1[i]:.4f}\")\n",
    "    return acc, np.mean(prec), np.mean(rec), np.mean(f1), cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a610b39",
   "metadata": {},
   "source": [
    "## 8. Encapsulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49d2b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBernoulliNB:\n",
    "    \"\"\"\n",
    "    Bernoulli Naive Bayes classifier for boolean features.\n",
    "\n",
    "    This implementation handles boolean features after label encoding.\n",
    "    Uses Laplace smoothing to handle underflow.\n",
    "\n",
    "    Attributes:\n",
    "        alpha (float): Smoothing parameter (default=1.0).\n",
    "        priors_ (Dict[int, float]): Class prior probabilities.\n",
    "        likelihoods_ (Dict[str, Dict[int, Dict[int, float]]]): Feature likelihood probabilities.\n",
    "        classes_ (NDArray[np.int64]): Unique class labels.\n",
    "        feature_names_ (List[str]): Feature names from training data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha: float = 1.0) -> None:\n",
    "        \"\"\"\n",
    "        Initialise Bernoulli Naive Bayes classifier.\n",
    "\n",
    "        Args:\n",
    "            alpha: Smoothing parameter for Laplace smoothing (default=1.0).\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.priors_ = None\n",
    "        self.likelihoods_ = None\n",
    "        self.classes_ = None\n",
    "        self.feature_names_ = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        \"\"\"\n",
    "        Fit the model to the training data.\n",
    "\n",
    "        Args:\n",
    "            X: Training data (integer).\n",
    "            y: Target values (class labels in integer).\n",
    "\n",
    "        Computes:\n",
    "            - Class prior probabilities (priors_).\n",
    "            - Feature likelihood probabilities (likelihoods_).\n",
    "        \"\"\"\n",
    "        # Validate binary features\n",
    "        if not X.isin([0, 1]).all().all():\n",
    "            raise ValueError(\"All features must be binary (0/1)\")\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.feature_names_ = X.columns.to_list()\n",
    "        self.priors_ = self._calculate_priors(y)\n",
    "        self.likelihoods_ = self._calculate_likelihoods(X, y)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> List[int]:\n",
    "        \"\"\"\n",
    "        Predict class labels using Categorical Naive Bayes.\n",
    "\n",
    "        Args:\n",
    "            X: Feature matrix.\n",
    "\n",
    "        Returns:\n",
    "            Predicted class labels.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If model hasn't been fitted.\n",
    "        \"\"\"\n",
    "        if self.priors_ is None or self.likelihoods_ is None:\n",
    "            raise ValueError('Model not fitted. Call .fit() first.')\n",
    "\n",
    "        predictions = []\n",
    "        for row in X.itertuples(index=False):\n",
    "            log_posteriors = self._calculate_posteriors(row._asdict())\n",
    "            predictions.append(max(log_posteriors, key=log_posteriors.get))\n",
    "        return predictions\n",
    "\n",
    "    def _calculate_priors(self, y: pd.Series) -> Dict[int, float]:\n",
    "        \"\"\"\n",
    "        Calculate prior probabilities for each class in the target variable.\n",
    "\n",
    "        Args:\n",
    "            y: Target variable containing class labels (0/1).\n",
    "\n",
    "        Returns:\n",
    "            Prior probabilities for each class.\n",
    "        \"\"\"\n",
    "        return y.value_counts(normalize=True).to_dict()\n",
    "\n",
    "    def _calculate_likelihoods(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, Dict[int, Dict[int, float]]]:\n",
    "        \"\"\"\n",
    "        Calculate conditional probabilities for feature values given each class.\n",
    "\n",
    "        Args:\n",
    "            X: Feature matrix (DataFrame with binary columns)\n",
    "            y: Target variable (Series of binary class labels)\n",
    "\n",
    "        Returns:\n",
    "            Nested dictionary with structure:\n",
    "            {feature_name: {class_label: {feature_value: probability}}}\n",
    "        \"\"\"\n",
    "        likelihoods = {}\n",
    "\n",
    "        for feature in self.feature_names_:\n",
    "            likelihoods[feature] = {}\n",
    "\n",
    "            for class_label in self.classes_:\n",
    "                c = int(class_label)\n",
    "                class_mask = (y == c)\n",
    "                class_subset = X.loc[class_mask, feature]\n",
    "                total_in_class = class_mask.sum()  # Number of samples in class\n",
    "\n",
    "                # Count occurrences of 1s (0s will be total - count_1)\n",
    "                count_1 = class_subset.sum()\n",
    "                count_0 = total_in_class - count_1\n",
    "\n",
    "                # Apply Laplace smoothing for binary features\n",
    "                # Denominator: total_in_class + 2 * alpha (for two possible values)\n",
    "                prob_1 = (count_1 + self.alpha) / \\\n",
    "                    (total_in_class + 2 * self.alpha)\n",
    "                prob_0 = (count_0 + self.alpha) / \\\n",
    "                    (total_in_class + 2 * self.alpha)\n",
    "\n",
    "                # Store probabilities for both values\n",
    "                likelihoods[feature][c] = {\n",
    "                    0: round(float(prob_0), 4),\n",
    "                    1: round(float(prob_1), 4)\n",
    "                }\n",
    "\n",
    "        return likelihoods\n",
    "\n",
    "    def _calculate_posteriors(self, x: Dict[str, int]) -> Dict[int, float]:\n",
    "        \"\"\"\n",
    "        Calculate log-posterior probabilities for all classes given a sample.\n",
    "        Args:\n",
    "            x: Input sample as dictionary {feature: value}.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary mapping each class to its log-posterior probability.\n",
    "        \"\"\"\n",
    "        log_posteriors = {}\n",
    "        for c in self.classes_:\n",
    "            log_proba = np.log(self.priors_[c])  # Log of prior\n",
    "            for feature in self.feature_names_:  # Sum of the likelihood for x given c\n",
    "                category = x[feature]\n",
    "                # Avoid log(0) if the feature does not exist\n",
    "                proba = self.likelihoods_[feature][c].get(category, 1e-9)\n",
    "                log_proba += np.log(proba)\n",
    "            log_posteriors[c] = round(log_proba, 4)\n",
    "        return log_posteriors  # log-posterior probabilities for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a494b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9286\n",
      "Precision: 0.9500\n",
      "Recall: 0.9000\n",
      "F1-Score: 0.9181\n",
      "Confusion Matrix:\n",
      "[[4 1]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "model = CustomBernoulliNB()\n",
    "model.fit(X_binary, y_binary)\n",
    "\n",
    "y_pred = model.predict(X_binary)\n",
    "acc, prec, rec, f1, cm = evaluate(y_binary, y_pred)\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "print(f'Precision: {prec:.4f}')\n",
    "print(f'Recall: {rec:.4f}')\n",
    "print(f'F1-Score: {f1:.4f}')\n",
    "print(f'Confusion Matrix:\\n{cm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be3057",
   "metadata": {},
   "source": [
    "## 9. Comparison with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a8df5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0 1 1 1 1 1 0 1 1 1 1 1 0]\n",
      "Accuracy: 0.9286\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.95      0.90      0.92        14\n",
      "weighted avg       0.94      0.93      0.93        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(X_binary, y_binary)\n",
    "\n",
    "y_pred = model.predict(X_binary)\n",
    "accuracy = model.score(X_binary, y_binary)\n",
    "print(f'Predictions: {y_pred}')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Classification report:\\n{classification_report(y_binary, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
