{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9fbd05",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes Classifier from Scratch\n",
    "***\n",
    "## Table of Contents\n",
    "1. [Introduction](#1-introduction)\n",
    "    - [Bayes' Theorem](#bayes-theorem)\n",
    "2. [Loading Data](#2-loading-data)\n",
    "3. [Prior Probability](#3-prior-probability)\n",
    "4. [Likelihood for Gaussian NB](#4-likelihood-for-gaussian-nb)\n",
    "5. [Posterior Probability for Gaussian NB](#5-posterior-probability-for-gaussian-nb)\n",
    "6. [Prediction](#6-prediction)\n",
    "7. [Evaluation Metrics](#7-evaluation-metrics)\n",
    "    - [Binary Confusion Matrix](#binary-confusion-matrix)\n",
    "    - [Multi-Class Confusion Matrix](#multi-class-confusion-matrix)\n",
    "    - [Accuracy](#accuracy)\n",
    "    - [Precision](#precision)\n",
    "    - [Recall](#recall)\n",
    "    - [F1-Score](#f1-score)\n",
    "8. [Train Test Split](#8-train-test-split)\n",
    "9. [Encapsulation](#9-encapsulation)\n",
    "10. [Comparison with Scikit-Learn](#10-comparison-with-scikit-learn)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6a60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "from sklearn.datasets import load_iris\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f59cd",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Naive Bayes classifiers are probabilistic classification models based on Bayes' Theorem, assuming conditional independence between features given the class labels or values. Naive Bayes is a general framework; the specific variant should be chosen based on the nature of your data:\n",
    "\n",
    "- **Categorical Naive Bayes**\n",
    "\n",
    "    - **Features**: Categorical labels (e.g., colours, countries, product types).\n",
    "\n",
    "    - **Use Case**: Classification with discrete, categorically distributed features.\n",
    "\n",
    "- **Multinomial Naive Bayes**\n",
    "\n",
    "    - **Features**: Counts or frequencies (e.g., word occurrences, event counts).\n",
    "\n",
    "    - **Use** **Case**: Text classification, document classification, or any scenario where features are discrete counts.\n",
    "\n",
    "- **Gaussian Naive Bayes**\n",
    "\n",
    "    - **Features**: Continuous data (e.g., measurements, sensor readings).\n",
    "\n",
    "    - **Use Case**: Classification with numerical features assumed to follow a Gaussian distribution.\n",
    "\n",
    "- **Bernoulli Naive Bayes**\n",
    "\n",
    "    - **Features**: Binary features (e.g., True/False, 0/1).\n",
    "\n",
    "    - **Use Case**: Text classification (presence/absence of words), binary feature spaces.\n",
    "\n",
    "\n",
    "\n",
    "### Bayes' Theorem\n",
    "Bayes' theorem describes the probability of a class $C_{i}$ given a set of features $X = (x_{1}, x_{2},\\ldots,x_{N})$:\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}|X) = \\dfrac{P(X|C_{i}) \\cdot P(C_{i})}{P(X)}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $P(C_{i}|X)$: Posterior probability of class $C_{i}$ given features $X$.\n",
    "- $P(X|C_{i})$: Likelihood of features $X$ given class $C_{i}$.\n",
    "- $P(C_{i})$: Prior probability of class $C_{i}$.\n",
    "- $P(X)$: Evidence (normalising constant, same for all classes)\n",
    "\n",
    "Gaussian Naive Bayes assumes features $X = (x_{1}, x_{2},\\ldots,x_{N})$ are conditionally independent given the class $C_{i}$ and features follow a Gaussian (normal) distribution within each class. Therefore, the likelihood is expressed as:\n",
    "\n",
    "\\begin{align*}\n",
    "P(x_j|C_i) = \\frac{1}{\\sqrt{2\\pi\\sigma_{ij}^2}} \\exp\\left(-\\frac{(x_j - \\mu_{ij})^2}{2\\sigma_{ij}^2}\\right)\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "\n",
    "$\\mu_{ij}$ = Mean of feature $x_j$ in class $C_i$.\n",
    "\n",
    "$\\sigma_{ij}^2$ = Variance of feature $x_j$ in class $C_i$\n",
    "\n",
    "\n",
    "Replacing $P(X|C_{i})$ in Bayes' theorem, the equation becomes:\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}|X) = \\dfrac{P(C_{i}) \\cdot \\prod_{j=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma_{ij}^2}} \\exp\\left(-\\frac{(x_j - \\mu_{ij})^2}{2\\sigma_{ij}^2}\\right)}{P(X)}\n",
    "\\end{align*}\n",
    "\n",
    "Since $P(X)$ is constant for all classes,\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}|X) \\propto P(C_{i}) \\cdot \\prod_{j=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma_{ij}^2}} \\exp\\left(-\\frac{(x_j - \\mu_{ij})^2}{2\\sigma_{ij}^2}\\right)\n",
    "\\end{align*}\n",
    "\n",
    "The symbol $\\propto$ denotes proportionality, meaning we ignore the denominator $P(X)$ when comparing probabilities across classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8aed94",
   "metadata": {},
   "source": [
    "## 2. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc2e8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sepal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sepal width (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal width (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "species",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2e366d41-008a-434c-8d39-8cd6467612ae",
       "rows": [
        [
         "0",
         "5.1",
         "3.5",
         "1.4",
         "0.2",
         "0"
        ],
        [
         "1",
         "4.9",
         "3.0",
         "1.4",
         "0.2",
         "0"
        ],
        [
         "2",
         "4.7",
         "3.2",
         "1.3",
         "0.2",
         "0"
        ],
        [
         "3",
         "4.6",
         "3.1",
         "1.5",
         "0.2",
         "0"
        ],
        [
         "4",
         "5.0",
         "3.6",
         "1.4",
         "0.2",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   species  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['species'] = iris.target\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4c071c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "petal width (cm)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0416b4b7-309a-42b4-b7af-6f9cdecc3525",
       "rows": [
        [
         "count",
         "150.0"
        ],
        [
         "mean",
         "1.1993333333333336"
        ],
        [
         "std",
         "0.7622376689603465"
        ],
        [
         "min",
         "0.1"
        ],
        [
         "25%",
         "0.3"
        ],
        [
         "50%",
         "1.3"
        ],
        [
         "75%",
         "1.8"
        ],
        [
         "max",
         "2.5"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "count    150.000000\n",
       "mean       1.199333\n",
       "std        0.762238\n",
       "min        0.100000\n",
       "25%        0.300000\n",
       "50%        1.300000\n",
       "75%        1.800000\n",
       "max        2.500000\n",
       "Name: petal width (cm), dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "X.iloc[:, 3].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a7e4e",
   "metadata": {},
   "source": [
    "## 3. Prior Probability\n",
    "Class $C_{i}$ (`y`) has three discrete integer variables: `0`, `1` and `2`:\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}=0) = \\dfrac{\\text{Count(0)}}{\\text{Total Count}}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}=1) = \\dfrac{\\text{Count(1)}}{\\text{Total Count}}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}=2) = \\dfrac{\\text{Count(2)}}{\\text{Total Count}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e5e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 150\n",
      "Counts: {0: 50, 1: 50, 2: 50}\n"
     ]
    }
   ],
   "source": [
    "print(f'Total count: {len(df)}')\n",
    "print(f'Counts: {y.value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84ad31",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "P(0) = \\dfrac{50}{150} = P(1) = P(2)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a19edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_priors(y: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate prior probabilities for each class in the target variable.\n",
    "\n",
    "    Args:\n",
    "        y: Target variable containing class labels (strings).\n",
    "\n",
    "    Returns:\n",
    "        Prior probabilities for each class.\n",
    "    \"\"\"\n",
    "    return y.value_counts(normalize=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b6c812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_priors(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a52b0",
   "metadata": {},
   "source": [
    "## 4. Likelihood for Gaussian NB\n",
    "For continuous features, $P(x_{j}|C_{i})$ uses the **Gaussian probability density function**:\n",
    "\n",
    "\\begin{align*}\n",
    "P(x_j|C_i) = \\frac{1}{\\sqrt{2\\pi\\sigma_{ij}^2}} \\exp\\left(-\\frac{(x_j - \\mu_{ij})^2}{2\\sigma_{ij}^2}\\right)\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "\n",
    "$\\mu_{ij}$ = Mean of feature $x_j$ in class $C_i$.\n",
    "\n",
    "$\\sigma_{ij}^2$ = Variance of feature $x_j$ in class $C_i$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a8a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihoods(X: pd.DataFrame, y: pd.Series, epsilon: float = 1e-9) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate Gaussian likelihood probabilities for each feature in a dataset per class.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        X: Feature matrix.\n",
    "        y: Class labels corresponding to each sample in X.\n",
    "        epsilon: Small value added to variances to prevent division by zero (default = 1e-9).\n",
    "\n",
    "    Returns:\n",
    "        Gaussian likelihood probability.\n",
    "\n",
    "    Notes:\n",
    "        - The calculation uses the Gaussian probability density function.\n",
    "        - Variances are calculated with ddof=0 (population variance).\n",
    "        - The function groups data by class to compute class-specific parameters.\n",
    "    \"\"\"\n",
    "    means_per_class = X.groupby(y).mean()\n",
    "    variances_per_class = X.groupby(y).var(ddof=0) + epsilon\n",
    "\n",
    "    likelihoods = X.copy()\n",
    "\n",
    "    for cls in y.unique():\n",
    "        cls_idx = y[y == cls].index\n",
    "        cls_X = X.loc[cls_idx]\n",
    "        cls_mean = means_per_class.loc[cls]\n",
    "        cls_var = variances_per_class.loc[cls]\n",
    "\n",
    "        exponent = -0.5 * ((cls_X - cls_mean) ** 2 / cls_var)\n",
    "        constant = 1 / np.sqrt(2 * np.pi * cls_var)\n",
    "        likelihoods.loc[cls_idx] = round(constant * np.exp(exponent), 4)\n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f326212e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sepal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sepal width (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal width (cm)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "8f1d3533-94ef-463d-a63b-fd48da43c935",
       "rows": [
        [
         "0",
         "1.1025",
         "1.0437",
         "2.1744",
         "3.4698"
        ],
        [
         "1",
         "1.0917",
         "0.5548",
         "2.1744",
         "3.4698"
        ],
        [
         "2",
         "0.7783",
         "0.8839",
         "1.4886",
         "3.4698"
        ],
        [
         "3",
         "0.581",
         "0.7256",
         "2.2645",
         "3.4698"
        ],
        [
         "4",
         "1.1431",
         "0.9571",
         "2.1744",
         "3.4698"
        ],
        [
         "5",
         "0.6044",
         "0.482",
         "0.8901",
         "1.2863"
        ],
        [
         "6",
         "0.581",
         "1.0602",
         "2.1744",
         "3.3446"
        ],
        [
         "7",
         "1.1431",
         "1.0602",
         "2.2645",
         "3.4698"
        ],
        [
         "8",
         "0.2531",
         "0.3951",
         "2.1744",
         "3.4698"
        ],
        [
         "9",
         "1.0917",
         "0.7256",
         "2.2645",
         "1.4363"
        ],
        [
         "10",
         "0.6044",
         "0.8175",
         "2.2645",
         "3.4698"
        ],
        [
         "11",
         "0.9604",
         "1.0602",
         "1.6814",
         "3.4698"
        ],
        [
         "12",
         "0.9604",
         "0.5548",
         "2.1744",
         "1.4363"
        ],
        [
         "13",
         "0.1477",
         "0.5548",
         "0.2528",
         "1.4363"
        ],
        [
         "14",
         "0.0859",
         "0.3327",
         "0.7265",
         "3.4698"
        ],
        [
         "15",
         "0.1582",
         "0.0371",
         "2.2645",
         "1.2863"
        ],
        [
         "16",
         "0.6044",
         "0.482",
         "1.4886",
         "1.2863"
        ],
        [
         "17",
         "1.1025",
         "1.0437",
         "2.1744",
         "3.3446"
        ],
        [
         "18",
         "0.1582",
         "0.6504",
         "0.8901",
         "3.3446"
        ],
        [
         "19",
         "1.1025",
         "0.6504",
         "2.2645",
         "3.3446"
        ],
        [
         "20",
         "0.6044",
         "1.0602",
         "0.8901",
         "3.4698"
        ],
        [
         "21",
         "1.1025",
         "0.8175",
         "2.2645",
         "1.2863"
        ],
        [
         "22",
         "0.581",
         "0.9571",
         "0.0627",
         "3.4698"
        ],
        [
         "23",
         "1.1025",
         "1.003",
         "0.8901",
         "0.1974"
        ],
        [
         "24",
         "0.9604",
         "1.0602",
         "0.0904",
         "3.4698"
        ],
        [
         "25",
         "1.1431",
         "0.5548",
         "1.6814",
         "3.4698"
        ],
        [
         "26",
         "1.1431",
         "1.0602",
         "1.6814",
         "1.2863"
        ],
        [
         "27",
         "0.9796",
         "1.0437",
         "2.2645",
         "3.4698"
        ],
        [
         "28",
         "0.9796",
         "1.0602",
         "2.1744",
         "3.4698"
        ],
        [
         "29",
         "0.7783",
         "0.8839",
         "1.6814",
         "3.4698"
        ],
        [
         "30",
         "0.9604",
         "0.7256",
         "1.6814",
         "3.4698"
        ],
        [
         "31",
         "0.6044",
         "1.0602",
         "2.2645",
         "1.2863"
        ],
        [
         "32",
         "0.9796",
         "0.2139",
         "2.2645",
         "1.4363"
        ],
        [
         "33",
         "0.4197",
         "0.1281",
         "2.1744",
         "3.4698"
        ],
        [
         "34",
         "1.0917",
         "0.7256",
         "2.2645",
         "3.4698"
        ],
        [
         "35",
         "1.1431",
         "0.8839",
         "0.7265",
         "3.4698"
        ],
        [
         "36",
         "0.4197",
         "1.0437",
         "1.4886",
         "3.4698"
        ],
        [
         "37",
         "1.0917",
         "0.9571",
         "2.1744",
         "1.4363"
        ],
        [
         "38",
         "0.2531",
         "0.5548",
         "1.4886",
         "3.4698"
        ],
        [
         "39",
         "1.1025",
         "1.0602",
         "2.2645",
         "3.4698"
        ],
        [
         "40",
         "1.1431",
         "1.0437",
         "1.4886",
         "3.3446"
        ],
        [
         "41",
         "0.3995",
         "0.0116",
         "1.4886",
         "3.3446"
        ],
        [
         "42",
         "0.2531",
         "0.8839",
         "1.4886",
         "3.4698"
        ],
        [
         "43",
         "1.1431",
         "1.0437",
         "1.6814",
         "0.0121"
        ],
        [
         "44",
         "1.1025",
         "0.6504",
         "0.0904",
         "1.2863"
        ],
        [
         "45",
         "0.9604",
         "0.5548",
         "2.1744",
         "3.3446"
        ],
        [
         "46",
         "1.1025",
         "0.6504",
         "1.6814",
         "3.4698"
        ],
        [
         "47",
         "0.581",
         "0.8839",
         "2.1744",
         "3.4698"
        ],
        [
         "48",
         "0.8017",
         "0.8175",
         "2.2645",
         "3.4698"
        ],
        [
         "49",
         "1.1431",
         "1.003",
         "2.1744",
         "3.4698"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 150
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1025</td>\n",
       "      <td>1.0437</td>\n",
       "      <td>2.1744</td>\n",
       "      <td>3.4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0917</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>2.1744</td>\n",
       "      <td>3.4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.8839</td>\n",
       "      <td>1.4886</td>\n",
       "      <td>3.4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>2.2645</td>\n",
       "      <td>3.4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1431</td>\n",
       "      <td>0.9571</td>\n",
       "      <td>2.1744</td>\n",
       "      <td>3.4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.6238</td>\n",
       "      <td>1.2455</td>\n",
       "      <td>0.5933</td>\n",
       "      <td>0.8831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.5708</td>\n",
       "      <td>0.4151</td>\n",
       "      <td>0.4383</td>\n",
       "      <td>1.3179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.6276</td>\n",
       "      <td>1.2455</td>\n",
       "      <td>0.5933</td>\n",
       "      <td>1.4606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.5241</td>\n",
       "      <td>0.5130</td>\n",
       "      <td>0.7025</td>\n",
       "      <td>0.8831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.3488</td>\n",
       "      <td>1.2455</td>\n",
       "      <td>0.5186</td>\n",
       "      <td>1.0387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0               1.1025            1.0437             2.1744            3.4698\n",
       "1               1.0917            0.5548             2.1744            3.4698\n",
       "2               0.7783            0.8839             1.4886            3.4698\n",
       "3               0.5810            0.7256             2.2645            3.4698\n",
       "4               1.1431            0.9571             2.1744            3.4698\n",
       "..                 ...               ...                ...               ...\n",
       "145             0.6238            1.2455             0.5933            0.8831\n",
       "146             0.5708            0.4151             0.4383            1.3179\n",
       "147             0.6276            1.2455             0.5933            1.4606\n",
       "148             0.5241            0.5130             0.7025            0.8831\n",
       "149             0.3488            1.2455             0.5186            1.0387\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_likelihoods(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca256f2b",
   "metadata": {},
   "source": [
    "## 5. Posterior Probability for Gaussian NB\n",
    "As we discussed [above](#1-introduction), the formula of posterior probability is:\n",
    "\n",
    "\\begin{align*}\n",
    "P(C_{i}|X) = P(C_{i}) \\cdot \\prod_{j=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma_{ij}^2}} \\exp\\left(-\\frac{(x_j - \\mu_{ij})^2}{2\\sigma_{ij}^2}\\right)\n",
    "\\end{align*}\n",
    "\n",
    "To avoid underflow and simplify calculations, we use the log-posterior:\n",
    "\n",
    "\\begin{align*}\n",
    "\\log{P(C_{i}|X)}  = \\log{P(C_{i})} + \\sum_{j=1}^{N} \\left[ -\\frac{1}{2} \\log{(2\\pi\\sigma_{ij}^2) - \\dfrac{(x_{j}-\\mu_{ij})^2}{2\\sigma_{ij}^2}}\n",
    "\\right] \n",
    "\\end{align*}\n",
    "\n",
    "- $\\mu_{ij}$ and $\\sigma_{ij}^2$ are estimated from training data per class.\n",
    "- Priors $P(C_{i})$ are typically empirical class frequencies.\n",
    "- Evidence $P(X)$ is ignored during classification (does not effect `.max()` or `.argmax()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c3930cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_posteriors(sample: pd.Series, priors: Dict[str, float],\n",
    "                             y: pd.Series, epsilon: float = 1e-9) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate log-posterior probabilities for a single sample across all classes using Gaussian Naive Bayes.\n",
    "\n",
    "    Args:\n",
    "        sample: Feature vector of a single sample.\n",
    "        priors: Dictionary of prior probabilities per class.\n",
    "        y: Series of class labels corresponding to training data.\n",
    "        epsilon: Small value added to variances for numerical stability (default=1e-9).\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping each class label to its log-posterior probability for the sample.\n",
    "\n",
    "    Notes:\n",
    "        - The function computes class-wise means and variances from the training data labels `y` and features.\n",
    "        - Uses the Gaussian probability density function in log space for likelihood calculation.\n",
    "        - Assumes features are conditionally independent given the class.\n",
    "    \"\"\"\n",
    "    means_per_class = X.groupby(y).mean()\n",
    "    variances_per_class = X.groupby(y).var(ddof=0) + epsilon\n",
    "\n",
    "    log_posteriors = {}\n",
    "\n",
    "    for cls in priors.keys():\n",
    "        # Start with log prior\n",
    "        log_posterior = np.log(priors[cls])\n",
    "\n",
    "        for feature in sample.index:\n",
    "            mean = means_per_class.loc[cls, feature]\n",
    "            var = variances_per_class.loc[cls, feature]\n",
    "            x = sample[feature]\n",
    "\n",
    "            # Gaussian log PDF calculation\n",
    "            log_pdf = -0.5 * (np.log(2 * np.pi * var) +\n",
    "                              ((x - mean) ** 2) / var)\n",
    "            log_posterior += log_pdf\n",
    "\n",
    "        log_posteriors[cls] = float(log_posterior)\n",
    "\n",
    "    return log_posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6402f790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0626580653811608, 1: -40.07797768635478, 2: -56.84265441519815}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_log_posteriors(X.iloc[0], calculate_priors(\n",
    "    y), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a028cb3d",
   "metadata": {},
   "source": [
    "## 6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100f4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y) -> List[int]:\n",
    "    \"\"\"\n",
    "    Predicts class labels using Gaussian Naive Bayes.\n",
    "\n",
    "    Args:\n",
    "        X: Features.\n",
    "        y: Target labels corresponding to document rows.\n",
    "\n",
    "    Returns:\n",
    "        Predicted class labels for each row in X.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    priors = calculate_priors(y)\n",
    "    for i in range(len(X)):\n",
    "        log_posteriors = calculate_log_posteriors(X.iloc[i], priors, y)\n",
    "        predictions.append(max(log_posteriors, key=log_posteriors.get))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa510707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X, y)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a2e00",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics\n",
    "### Binary Confusion Matrix\n",
    "In a confusion matrix, the terms True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN) describe the classification performance for binary classification. \n",
    "\n",
    "|                     | Predicted Negative  | Predicted Positive  |\n",
    "| ------------------- | ------------------- | ------------------- |\n",
    "| **Actual Negative** | True Negative (TN)  | False Positive (FP) |\n",
    "| **Actual Positive** | False Negative (FN) | True Positive (TP)  |\n",
    "\n",
    "\n",
    "1. True Positive (TP): The number of instances correctly predicted as positive (e.g., a disease correctly identified).\n",
    "\n",
    "2. True Negative (TN): The number of instances correctly predicted as negative (e.g., no disease correctly identified).\n",
    "\n",
    "3. False Positive (FP): The number of instances incorrectly predicted as positive (e.g., predicting disease when there isn't any).\n",
    "\n",
    "4. False Negative (FN): The number of instances incorrectly predicted as negative (e.g., missing a disease when it exists).\n",
    "\n",
    "### Multi-Class Confusion Matrix\n",
    "For multi-class classification, the concepts can be extended by treating one class as the \"positive\" class and all others as \"negative\" classes in a one-vs-all approach. Rows represent the actual classes (true labels), and columns represent the predicted classes. For a class $C$,\n",
    "1. True Positive (TP): The count in the diagonal cell corresponding to class $C$ ($\\text{matrix} [C][C]$).\n",
    "2. False Positive (FP): The sum of the column for class $C$, excluding the diagonal ($\\sum(\\text{matrix} [:, C]) - \\text{matrix} [C][C]$).\n",
    "3. False Negative (FN): The sum of the row for class $C$, excluding the diagonal ($\\sum(\\text{matrix} [C, :]) - \\text{matrix} [C][C]$).\n",
    "4. True Negative (TN): All other cells not in the row or column for class $C$ ($\\text{total} - (FP + FN + TP)$).\n",
    "\n",
    "|                  | Predicted Class 0 | Predicted Class 1 | Predicted Class 2 |\n",
    "| ---------------- | ----------------- | ----------------- | ----------------- |\n",
    "| **True Class 0** | 5                 | 2                 | 0                 |\n",
    "| **True Class 1** | 1                 | 6                 | 1                 |\n",
    "| **True Class 2** | 0                 | 2                 | 7                 |\n",
    "\n",
    "\n",
    "For Class 0:\n",
    "- TP = 5 (diagonal element for Class 0)\n",
    "- FP = 1 (sum of column 0 minus TP: 1 + 0)\n",
    "- FN = 2 (sum of row 0 minus TP: 2 + 0)\n",
    "- TN = 6 + 1 + 2 + 7 = 16 (all other cells not in row 0 or column 0)\n",
    "\n",
    "For Class 1:\n",
    "- TP = 6 (diagonal element for Class 1)\n",
    "- FP = 4 (sum of column 1 minus TP: 2 + 2)\n",
    "- FN = 2 (sum of row 1 minus TP: 1 + 1)\n",
    "- TN = 5 + 0 + 0 + 7 = 12 (all other cells not in row 1 or column 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8883f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true: pd.Series, y_pred: List[str],\n",
    "                     class_names: List[str] = None) -> Tuple[NDArray[np.int64], List[str]]:\n",
    "    \"\"\"\n",
    "    Calculate the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "        class_names: List of class names. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: \n",
    "        - Confusion matrix.\n",
    "        - List of class names.\n",
    "    \"\"\"\n",
    "    # Encode labels as integers\n",
    "    unique_classes = np.unique(y_true)\n",
    "    if class_names is None:\n",
    "        class_names = [str(cls) for cls in unique_classes]\n",
    "    class_to_index = {cls: i for i, cls in enumerate(unique_classes)}\n",
    "\n",
    "    n_classes = len(unique_classes)\n",
    "    matrix = np.zeros((n_classes, n_classes), dtype=int)\n",
    "\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_idx = class_to_index[true]\n",
    "        pred_idx = class_to_index[pred]\n",
    "        matrix[true_idx][pred_idx] += 1\n",
    "\n",
    "    return matrix, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407fa1e2",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Accuracy is the most common evaluation metric for classification problems, representing the percentage of correct predictions out of total predictions. It provides a simple measure of how often the classifier makes correct predictions across all classes.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Accuracy} = \\dfrac{\\text{True Positives (TP)} + \\text{True Negatives (TN)}}{\\text{Total Samples}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "781fa0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true: pd.Series, y_pred: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of predictions by comparing true and predicted labels.\n",
    "\n",
    "    Args:\n",
    "        y_true: Ground truth target values. Contains the actual class labels for each sample.\n",
    "        y_pred: Estimated target as returned by a classifier. Contains the predicted class labels for each sample.\n",
    "    Returns:\n",
    "        Classification accuracy (0.0 to 1.0).\n",
    "    \"\"\"\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c3568f",
   "metadata": {},
   "source": [
    "### Precision\n",
    "Precision measures the proportion of true positive predictions out of all positive predictions made by the classifier.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Precision} = \\dfrac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Positives (FP)}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8c7a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true: pd.Series, y_pred: List[str]) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Calculate precision for each class.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        Precision values for each class.\n",
    "    \"\"\"\n",
    "    cm, _ = confusion_matrix(y_true, y_pred)\n",
    "    return np.diag(cm) / (np.sum(cm, axis=0) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1651195",
   "metadata": {},
   "source": [
    "### Recall\n",
    "Recall measures the proportion of true positive predications out of all actual positive cases.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Recall} = \\dfrac{\\text{True Positives (TP)} }{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53764f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true: pd.Series, y_pred: List[str]) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Calculate recall for each class.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        Recall values for each class.\n",
    "    \"\"\"\n",
    "    cm, _ = confusion_matrix(y_true, y_pred)\n",
    "    return np.diag(cm) / (np.sum(cm, axis=1) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce631db2",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "The F1-Score is the harmonic mean of precision and recall.\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{F1-Score} = 2 \\times \\dfrac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6a19d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true: pd.Series, y_pred: List[str]) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Calculate F1-score for each class.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        F1-scores for each class.\n",
    "    \"\"\"\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * (prec * rec) / (prec + rec + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcc3cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true: pd.Series, y_pred: List[str],\n",
    "             class_names: List[str] = None) -> Tuple[float, float, float, float, NDArray[np.int64]]:\n",
    "    \"\"\"\n",
    "    Calculate evaluation metrics including accuracy, precision, recall, and F1-score for each class.\n",
    "\n",
    "    Args:\n",
    "        y_true: True labels.\n",
    "        y_pred: Predicted labels.\n",
    "        class_names: List of class names. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple:\n",
    "        - Overall accuracy.\n",
    "        - Average precision.\n",
    "        - Average recall.\n",
    "        - Average F1-score.\n",
    "        - Confusion matrix.\n",
    "    \"\"\"\n",
    "    cm, class_names = confusion_matrix(y_true, y_pred, class_names)\n",
    "    acc = accuracy(y_true, y_pred)\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    # print(\"Class\\tPrecision\\tRecall\\tF1-Score\")\n",
    "    # for i, class_name in enumerate(class_names):\n",
    "    #     print(f\"{class_name}\\t{prec[i]:.4f}\\t\\t{rec[i]:.4f}\\t{f1[i]:.4f}\")\n",
    "    return acc, np.mean(prec), np.mean(rec), np.mean(f1), cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c406b2c1",
   "metadata": {},
   "source": [
    "## 8. Train Test Split\n",
    "Train test split is a fundamental model validation technique in machine learning. It divides a dataset into two separate portions: a **training set** used to train a model, and a **testing set** used to evaluate how well the model can perform on unseen data. \n",
    "\n",
    "The typical split ratio is 80% for training and 20% for testing, though this can vary (70/30 or 90/10 are also common). The key principle is that the test set must remain completely separated during model training process, and should never be used to make decisions about the model or tune parameters. \n",
    "\n",
    "The split is usually done randomly to ensure both sets are representative of the overall dataset, and many libraries (such as scikit-learn) provide build-in functions that handle this process automatically while maintaining proper randomisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3c7b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X: pd.DataFrame, y: pd.Series, test_size: float = 0.2,\n",
    "                     random_state: int = None) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Split arrays or matrices into random train and test subsets.\n",
    "\n",
    "    Args:\n",
    "        X: Input features, a 2D array with rows (samples) and columns (features).\n",
    "        y: Target values/labels, a 1D array with rows (samples).\n",
    "        test_size: Proportion of the dataset to include in the test split. Must be between 0.0 and 1.0. default = 0.2\n",
    "        random_state: Seed for the random number generator to ensure reproducible results. default = None\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - X_train: Training set features.\n",
    "            - X_test: Testing set features.\n",
    "            - y_train: Training set target values.\n",
    "            - y_test: Testing set target values.\n",
    "    \"\"\"\n",
    "    # Set a random seed if it exists\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Create a list of numbers from 0 to len(X)\n",
    "    indices = np.arange(len(X))\n",
    "\n",
    "    # Shuffle the indices\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Define the size of our test data from len(X)\n",
    "    test_size = int(test_size * len(X))\n",
    "\n",
    "    # Generate indices for test and train data\n",
    "    test_indices: NDArray[np.int64] = indices[:test_size]\n",
    "    train_indices: NDArray[np.int64] = indices[test_size:]\n",
    "\n",
    "    # Return: X_train, X_test, y_train, y_test\n",
    "    return X.iloc[train_indices], X.iloc[test_indices], y.iloc[train_indices], y.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa55327",
   "metadata": {},
   "source": [
    "## 9. Encapsulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10297945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGaussianNB:\n",
    "    \"\"\"\n",
    "    Gaussian Naive Bayes classifier implementation.\n",
    "\n",
    "    Attributes:\n",
    "        epsilon (float): Smoothing parameter for variance\n",
    "        priors_ (Dict[str, float]): Prior probabilities per class\n",
    "        means_ (pd.DataFrame): Feature means per class\n",
    "        variances_ (pd.DataFrame): Feature variances per class\n",
    "        classes_ (List[str]): Unique class labels\n",
    "        feature_names_ (pd.Index): Feature names from training data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon: float = 1e-9) -> None:\n",
    "        \"\"\"\n",
    "        Initialise Gaussian Naive Bayes classifier.\n",
    "\n",
    "        Args:\n",
    "            epsilon: Smoothing parameter for variance (default = 1e-9)\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon\n",
    "        self.priors_ = None\n",
    "        self.means_ = None\n",
    "        self.variances_ = None\n",
    "        self.classes_ = None\n",
    "        self.feature_names_ = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        \"\"\"\n",
    "        Train Gaussian Naive Bayes model.\n",
    "\n",
    "        Args:\n",
    "            X: Feature matrix.\n",
    "            y: Target class labels.\n",
    "        \"\"\"\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        self.feature_names_ = X.columns\n",
    "        self.classes_ = y.unique().tolist()\n",
    "        self.priors_ = self._calculate_priors(y)\n",
    "        self.means_, self.variances_ = self._calculate_params(X, y)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> List[str]:\n",
    "        \"\"\"\n",
    "        Predict class labels for input samples.\n",
    "\n",
    "        Args:\n",
    "            X: Feature matrix to predict.\n",
    "\n",
    "        Returns:\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.feature_names_)\n",
    "        else:\n",
    "            X = X.reindex(columns=self.feature_names_, fill_value=0)\n",
    "\n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            sample = X.iloc[i]\n",
    "            log_posteriors = self._calculate_log_posteriors(sample)\n",
    "            predictions.append(max(log_posteriors, key=log_posteriors.get))\n",
    "        return predictions\n",
    "\n",
    "    def _calculate_priors(self, y: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate prior probabilities for each class.\n",
    "\n",
    "        Args:\n",
    "            y: Target class labels.\n",
    "\n",
    "        Returns:\n",
    "            Prior probabilities for each class.\n",
    "        \"\"\"\n",
    "        return y.value_counts(normalize=True).to_dict()\n",
    "\n",
    "    def _calculate_params(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Compute Gaussian parameters (mean and variance) per class.\n",
    "\n",
    "        Args:\n",
    "            X: Feature matrix.\n",
    "            y: Target class labels.\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (means, variances) DataFrames.\n",
    "        \"\"\"\n",
    "        means = X.groupby(y).mean()\n",
    "        variances = X.groupby(y).var(ddof=0) + self.epsilon\n",
    "        return means, variances\n",
    "\n",
    "    def _calculate_log_posteriors(self, sample: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate log-posterior probabilities for a single sample.\n",
    "\n",
    "        Args:\n",
    "            sample: Feature vector of a single sample\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of log-posterior probabilities per class\n",
    "        \"\"\"\n",
    "        log_posteriors = {}\n",
    "\n",
    "        for cls in self.classes_:\n",
    "            # Start with log prior\n",
    "            log_posterior = np.log(self.priors_[cls])\n",
    "\n",
    "            # Vectorised log-likelihood calculation\n",
    "            mean_vec = self.means_.loc[cls].values\n",
    "            var_vec = self.variances_.loc[cls].values\n",
    "            x_vec = sample.values\n",
    "\n",
    "            # Gaussian log PDF: -1/2*[log(2πσ²) + (x-μ)²/σ²]\n",
    "            log_pdf = -1/2 * (np.log(2 * np.pi * var_vec) +\n",
    "                              ((x_vec - mean_vec) ** 2) / var_vec)\n",
    "            log_posterior += np.sum(log_pdf)\n",
    "\n",
    "            log_posteriors[cls] = log_posterior\n",
    "\n",
    "        return log_posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c97099b",
   "metadata": {},
   "source": [
    "Let's check the performance on the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d615908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Entire Dataset): 0.9333\n",
      "Precision (Entire Dataset): 0.9372\n",
      "Recall (Entire Dataset): 0.9333\n",
      "F1-Score (Entire Dataset): 0.9331\n",
      "Confusion Matrix (Entire Dataset):\n",
      "[[50  0  0]\n",
      " [ 0 48  2]\n",
      " [ 0  8 42]]\n"
     ]
    }
   ],
   "source": [
    "model = CustomGaussianNB(epsilon=1.0)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "acc, prec, rec, f1, cm = evaluate(y, y_pred)\n",
    "print(f'Accuracy (Entire Dataset): {acc:.4f}')\n",
    "print(f'Precision (Entire Dataset): {prec:.4f}')\n",
    "print(f'Recall (Entire Dataset): {rec:.4f}')\n",
    "print(f'F1-Score (Entire Dataset): {f1:.4f}')\n",
    "print(f'Confusion Matrix (Entire Dataset):\\n{cm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2b6d9",
   "metadata": {},
   "source": [
    "Train the model on 80% of the dataset, then evaluate its performance on the remaining 20% (the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85d6440d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 1.0000\n",
      "Precision (Test): 1.0000\n",
      "Recall (Test): 1.0000\n",
      "F1-Score (Test): 1.0000\n",
      "Confusion Matrix (Test):\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialise and train\n",
    "model = CustomGaussianNB(epsilon=1e-9)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "acc, prec, rec, f1, cm = evaluate(y_test, y_pred)\n",
    "print(f'Accuracy (Test): {acc:.4f}')\n",
    "print(f'Precision (Test): {prec:.4f}')\n",
    "print(f'Recall (Test): {rec:.4f}')\n",
    "print(f'F1-Score (Test): {f1:.4f}')\n",
    "print(f'Confusion Matrix (Test):\\n{cm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f1bcd",
   "metadata": {},
   "source": [
    "## 10. Comparison with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fd64876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "Accuracy: 1.0000\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Predictions: {y_pred}')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Classification report:\\n{classification_report(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
