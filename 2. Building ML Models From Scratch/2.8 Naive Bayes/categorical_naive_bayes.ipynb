{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12858d89",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier from Scratch\n",
    "***\n",
    "## Table of Contents\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e83ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe5a4c",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Naive Bayes classifiers are probabilistic classification models based on Bayes' Theorem, assuming conditional independence between features given the class labels or values. Naive Bayes is a general framework; the specific variant should be chosen based on the nature of your data:\n",
    "\n",
    "- **Multinomial Naïve Bayes**: Assumes features follow multinomial distributions; ideal when features are **discrete** values.\n",
    "\n",
    "- **Gaussian Naïve Bayes**: Assumes features follow a Gaussian (normal) distribution; used for **continuous** features. Fits the model by calculating the mean and standard deviation for each class.\n",
    "\n",
    "- **Bernoulli Naïve Bayes**: Works with **binary** features (e.g., True/False, 0/1).\n",
    "\n",
    "\n",
    "### Bayes' Theorem\n",
    "Bayes' theorem describes the probability of a class $C$ given a set of features $X = (x_{1}, x_{2},\\ldots,x_{n})$:\n",
    "\n",
    "\\begin{align*}\n",
    "P(C|X) = \\dfrac{P(X|C) \\cdot P(C)}{P(X)}\n",
    "\\end{align*}\n",
    "\n",
    "where:\n",
    "- $P(C|X)$: Posterior probability of class $C$ given features $X$.\n",
    "- $P(X|C)$: Likelihood of features $X$ given class $C$.\n",
    "- $P(C)$: Prior probability of class $C$.\n",
    "- $P(X)$: Probability of features $X$ (acts as a normalising constant).\n",
    "\n",
    "Naive Bayes assumes features $X = (x_{1}, x_{2},\\ldots,x_{n})$ are conditionally independent given the class $C$, thus the likelihood is expressed as:\n",
    "\\begin{align*}\n",
    "P(X|C) = P(x_{1}, x_{2}, \\dots, x_{n}|C) = \\prod_{i=1}^{n}P(x_{i}|C)\n",
    "\\end{align*}\n",
    "\n",
    "Replacing $P(X|C)$ in Bayes' theorem, the equation becomes:\n",
    "\n",
    "\\begin{align*}\n",
    "P(C|X) = \\dfrac{P(C) \\cdot \\prod_{i=1}^{n} P(x_{i}|C)}{P(X)}\n",
    "\\end{align*}\n",
    "\n",
    "Since $P(X)$ is constant for all classes,\n",
    "\n",
    "\\begin{align*}\n",
    "P(C|X) \\propto P(C) \\cdot \\prod_{i=1}^{n} P(x_{i}|C)\n",
    "\\end{align*}\n",
    "\n",
    "The symbol $\\propto$ denotes proportionality, meaning we ignore the denominator $P(X)$ when comparing probabilities across classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe05ae",
   "metadata": {},
   "source": [
    "## 2. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e00c823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Outlook",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Temperature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Humidity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Windy",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Play",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a0f89059-abba-4212-8a91-04773c5508cb",
       "rows": [
        [
         "0",
         "Sunny",
         "Hot",
         "High",
         "Weak",
         "No"
        ],
        [
         "1",
         "Sunny",
         "Hot",
         "High",
         "Strong",
         "No"
        ],
        [
         "2",
         "Overcast",
         "Hot",
         "High",
         "Weak",
         "Yes"
        ],
        [
         "3",
         "Rain",
         "Mild",
         "High",
         "Weak",
         "Yes"
        ],
        [
         "4",
         "Rain",
         "Cool",
         "Normal",
         "Weak",
         "Yes"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook Temperature Humidity   Windy Play\n",
       "0     Sunny         Hot     High    Weak   No\n",
       "1     Sunny         Hot     High  Strong   No\n",
       "2  Overcast         Hot     High    Weak  Yes\n",
       "3      Rain        Mild     High    Weak  Yes\n",
       "4      Rain        Cool   Normal    Weak  Yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../_datasets/weather_forecast.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb633f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Play', axis=1)\n",
    "y = df['Play']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddda1d2",
   "metadata": {},
   "source": [
    "## 3. Prior Probability\n",
    "Class $C$ (`y`) has only two discrete variables: `Yes` and `No`:\n",
    "\n",
    "\\begin{align*}\n",
    "P(C=\\text{'Yes'}) = \\dfrac{\\text{Count(Yes)}}{\\text{Total Count}}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "P(C=\\text{'No'}) = \\dfrac{\\text{Count(No)}}{\\text{Total Count}}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae02a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 14\n",
      "Counts\": {'Yes': 9, 'No': 5}\n"
     ]
    }
   ],
   "source": [
    "print(f'Total count: {len(df)}')\n",
    "print(f'Counts\": {y.value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ffb3cd",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "P(\\text{'Yes'}) = \\dfrac{9}{14} = 0.6429\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\text{'No'}) = \\dfrac{5}{14} = 0.3571\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12118d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_priors(y):\n",
    "    return y.value_counts(normalize=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d32d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Yes': 0.6428571428571429, 'No': 0.35714285714285715}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_priors(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7e540a",
   "metadata": {},
   "source": [
    "## 4. Likelihood\n",
    "\n",
    "The likelihood quantifies how well parameter $\\theta$ explain the observed data. It is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta|x) = f(x|\\theta)\n",
    "\\end{align*}\n",
    "\n",
    "where $f$ is the probability density/mass function.\n",
    "\n",
    "For each feature value and class, we calculate:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\text{Feature = value|Class})\n",
    "\\end{align*}\n",
    "\n",
    "For example:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\text{Outlook = 'Sunny'|Play = 'Yes'}) = \\dfrac{\\text{Count(Outlook = 'Sunny'|Play = 'Yes')} + \\alpha}{\\text{Count(Play = 'Yes)} + n \\cdot \\alpha}\n",
    "\\end{align*}\n",
    "\n",
    "where $n$ is the number of features and $\\alpha$ is the smoothing parameter to handle zero probabilities (**Laplace Smoothing**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceff3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihoods(X, y, alpha=1.0):\n",
    "    likelihoods = {}\n",
    "    for feature in X.columns:  # For each column of X\n",
    "        likelihoods[feature] = {}\n",
    "        # Unique feature values in each column\n",
    "        unique_features = X[feature].unique()\n",
    "\n",
    "        for c in y.unique():  # Unique target values of y\n",
    "            class_subset = X[y == c]\n",
    "            total = len(class_subset)  # Count(C)\n",
    "            \n",
    "            # Count frequencies (e.g., {'Sunny':3, 'Rain':2} for class 'No')\n",
    "            value_counts = class_subset[feature].value_counts()\n",
    "\n",
    "            # All features values are included, even if missing in subset\n",
    "            value_counts = value_counts.reindex(unique_features, fill_value=0)\n",
    "            probas = (value_counts + alpha) / (total + len(value_counts) * alpha)\n",
    "\n",
    "            likelihoods[feature][c] = probas.to_dict()\n",
    "    return likelihoods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7414db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Outlook': {'No': {'Sunny': 0.5, 'Overcast': 0.125, 'Rain': 0.375},\n",
       "  'Yes': {'Sunny': 0.25,\n",
       "   'Overcast': 0.4166666666666667,\n",
       "   'Rain': 0.3333333333333333}},\n",
       " 'Temperature': {'No': {'Hot': 0.375, 'Mild': 0.375, 'Cool': 0.25},\n",
       "  'Yes': {'Hot': 0.25,\n",
       "   'Mild': 0.4166666666666667,\n",
       "   'Cool': 0.3333333333333333}},\n",
       " 'Humidity': {'No': {'High': 0.7142857142857143, 'Normal': 0.2857142857142857},\n",
       "  'Yes': {'High': 0.36363636363636365, 'Normal': 0.6363636363636364}},\n",
       " 'Windy': {'No': {'Weak': 0.42857142857142855, 'Strong': 0.5714285714285714},\n",
       "  'Yes': {'Weak': 0.6363636363636364, 'Strong': 0.36363636363636365}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_likelihoods(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6115f54",
   "metadata": {},
   "source": [
    "## 5. Posterior Probability\n",
    "As we discussed [above](#1-introduction), the formula of posterior probability is:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "P(C|X) \\propto P(C) \\prod_{i=1}^{n} P(x_{i}|C)\n",
    "\\end{align*}\n",
    "\n",
    "To prevent underflow, we use log probabilities:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{log } P(C|X) = \\text{log } P(C) + \\sum_{i=1}^{n} \\text{log } P(x_{i}|C)\n",
    "\\end{align*}\n",
    "\n",
    "In the following code, `.get(category, 1e-9)` tries to retrieve the probability for the specific value category from this dictionary. If the category was not seen in the training data for this class (i.e., it's missing from the dictionary), it returns a very small default value (1e-9) instead of raising an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10df8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posterior(x, priors, likelihoods, X_columns, classes):\n",
    "    log_posteriors = {}\n",
    "    for c in classes:\n",
    "        log_proba = np.log(priors[c]) # Log of prior\n",
    "        for feature in X_columns: # Sum of the likelihood for each x given c\n",
    "            category = x[feature]\n",
    "            proba = likelihoods[feature][c].get(category, 1e-9) # Avoid log(0) if the feature does not exist\n",
    "            log_proba += np.log(proba)\n",
    "        log_posteriors[c] = log_proba\n",
    "    return log_posteriors # log-posterior probabilities for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e7261fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No': np.float64(-3.8873659477612463), 'Yes': np.float64(-4.6780075099403575)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_posterior(X.iloc[0], calculate_priors(y), calculate_likelihoods(X, y), X.columns, y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27707c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
